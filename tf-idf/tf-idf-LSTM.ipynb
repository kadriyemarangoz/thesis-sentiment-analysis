{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['tweets','duygu','preprocessing']\n",
    "#df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "\n",
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avea yüzünden turkcell in interneti sorunlu di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell bana trip atıyor resmen alt tarafı bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkcell'le ciddi düşünüyorum. ne bilim bana ö...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sevgi̇li̇m turkcell yeni̇ hat aldiğim i̇çi̇n 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turkcell 4.5 g istemiyorum ben ya 3g bile çalı...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>turkcell salla kazan 10 gb nasıl bitecek la bu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>@kaan_terzioglu turkcell e hic bir borcum olma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>turkcell yine çekmiyor. aldıkları para boşuna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>30 tlik fatura yüzünden hattımı aramalara kapa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell 1g ile cepten internet keyfi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     avea yüzünden turkcell in interneti sorunlu di...     1\n",
       "1     turkcell bana trip atıyor resmen alt tarafı bi...     0\n",
       "2     turkcell'le ciddi düşünüyorum. ne bilim bana ö...     1\n",
       "3     sevgi̇li̇m turkcell yeni̇ hat aldiğim i̇çi̇n 1...     1\n",
       "4     turkcell 4.5 g istemiyorum ben ya 3g bile çalı...     0\n",
       "...                                                 ...   ...\n",
       "9121     turkcell salla kazan 10 gb nasıl bitecek la bu     1\n",
       "9122  @kaan_terzioglu turkcell e hic bir borcum olma...     0\n",
       "9123      turkcell yine çekmiyor. aldıkları para boşuna     0\n",
       "9124  30 tlik fatura yüzünden hattımı aramalara kapa...     0\n",
       "9125              turkcell 1g ile cepten internet keyfi     1\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf (X_train,y_train,X_test,y_test):\n",
    "    #Create a tokenizer, configured to only take into account the 20 most common words çok küçük olursa kelimeleri \n",
    "    #kaybederiz underfit yaparız\n",
    "    tokenizer = Tokenizer(num_words=1000) #en yaygın kaç kelimeyi dikkate alacağı. Belirtilecek en iyi kelime sayısı #1000 yapan da var\n",
    "    tokenizer.fit_on_texts(X_train) #keras tokenizer ile metni dictionary haline getiriyor.\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train) #kelimelerin dictionarydeki karşılığı \n",
    "    #[[2, 1, 3], [2, 1], [4, 1], [5, 6]] şekline getiriliyor. 2-machine 1- learning 3-Knowledge \n",
    "    word_index = tokenizer.word_index #dictionarydeki kelimelerin sayısal karşılığı 'unk': 1, 'ürün': 2,\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)): #len(sequences_X_train) ile kaç tane [[2,3,4],[2,6]] var bulunuyor burda 2\n",
    "        numberofwords=len(sequences_X_train[review_number]) #[2,3,4] içinde kaç tane şey var 3 burda\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords #tüm kelimelere bakıp en uzun olanı buluyor\n",
    "\n",
    "    vocabulary=[]\n",
    "    for key in word_index.keys():\n",
    "        vocabulary.append(key)\n",
    "\n",
    "    pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
    "                     ('tfid', TfidfTransformer())]).fit(X_train)\n",
    "\n",
    "    res = dict(zip(vocabulary, pipe['tfid'].idf_))\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length) #ikili boyutlu matrise çevirip her cümelnin uzunluğunu eşit yapıyor.\n",
    "    #En uzun cümle uzunluğuna tamamlanıyor.[[2 1 3] [0 2 1]] alt alta gelecek şekilde en uzun 6 ise 6x6 matris oluyor\n",
    "    y_train = np.asarray(y_train) #tek boyutlu bir matris oluyor [1 1 0 ... 0 1 0] gibi\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test) #train için yapılan gibi dictionary alınıyor\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length) #en uzun olana göre pad sequence yapılıyor\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    unique_words = len(word_index) #word_index ile unique olan kelimeler alınıyor 0 dan başladığı için bir arttırılıyor\n",
    "    total_words = unique_words + 1\n",
    "    \n",
    "    skipped_words = 0\n",
    "    embedding_dim = 1 #embedding dim vector size ile aynı \n",
    "    embedding_vector=0\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items(): #kelime ve kelimenin dictionarydeki karşılığı alınıyor\n",
    "        try:\n",
    "            embedding_vector = res[word] #kelimenin word2vec karşılığı vektör olarak\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector \n",
    "            \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "\n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.6953 - acc: 0.5096 - precision: 0.5093 - recall: 0.5893\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.6927 - acc: 0.5156 - precision: 0.5171 - recall: 0.5113\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.6936 - acc: 0.5065 - precision: 0.5071 - recall: 0.5521\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.6926 - acc: 0.5202 - precision: 0.5201 - recall: 0.5523\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.6923 - acc: 0.5182 - precision: 0.5185 - recall: 0.5441\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.6927 - acc: 0.5144 - precision: 0.5159 - recall: 0.5072\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.6921 - acc: 0.5161 - precision: 0.5160 - recall: 0.5613\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6918 - acc: 0.5204 - precision: 0.5193 - recall: 0.5812\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6925 - acc: 0.5161 - precision: 0.5173 - recall: 0.5188\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6919 - acc: 0.5225 - precision: 0.5202 - recall: 0.6094\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6921 - acc: 0.5111 - precision: 0.5122 - recall: 0.5183\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6918 - acc: 0.5234 - precision: 0.5252 - recall: 0.5135\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 17s 66ms/step - loss: 0.6913 - acc: 0.5260 - precision: 0.5253 - recall: 0.56452s -\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 17s 66ms/step - loss: 0.6915 - acc: 0.5272 - precision: 0.5286 - recall: 0.5251\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6918 - acc: 0.5194 - precision: 0.5188 - recall: 0.5684\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6913 - acc: 0.5182 - precision: 0.5192 - recall: 0.52421s - loss: 0.6912 - acc: 0.520\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6903 - acc: 0.5262 - precision: 0.5250 - recall: 0.5754\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6907 - acc: 0.5271 - precision: 0.5265 - recall: 0.5618\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 17s 68ms/step - loss: 0.6918 - acc: 0.5234 - precision: 0.5238 - recall: 0.5424\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 18s 68ms/step - loss: 0.6899 - acc: 0.5376 - precision: 0.5358 - recall: 0.5795\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6902 - acc: 0.5273 - precision: 0.5290 - recall: 0.5210\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6909 - acc: 0.5282 - precision: 0.5271 - recall: 0.5720\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 17s 66ms/step - loss: 0.6897 - acc: 0.5290 - precision: 0.5294 - recall: 0.5443\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6912 - acc: 0.5338 - precision: 0.5346 - recall: 0.5404\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6896 - acc: 0.5410 - precision: 0.5415 - recall: 0.5502\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6904 - acc: 0.5267 - precision: 0.5290 - recall: 0.5101\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.6898 - acc: 0.5405 - precision: 0.5411 - recall: 0.5485\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6894 - acc: 0.5344 - precision: 0.5374 - recall: 0.5115\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6900 - acc: 0.5220 - precision: 0.5225 - recall: 0.5383\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6898 - acc: 0.5362 - precision: 0.5354 - recall: 0.5652\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6906 - acc: 0.5334 - precision: 0.5334 - recall: 0.5531\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6900 - acc: 0.5251 - precision: 0.5279 - recall: 0.4984\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 17s 66ms/step - loss: 0.6903 - acc: 0.5287 - precision: 0.5300 - recall: 0.5283\n",
      "Epoch 00033: early stopping\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6879 - acc: 0.5455 - precision: 0.5622 - recall: 0.3139\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6948 - acc: 0.5167 - precision_1: 0.5152 - recall_1: 0.5309\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6938 - acc: 0.5064 - precision_1: 0.5054 - recall_1: 0.4945\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6935 - acc: 0.5046 - precision_1: 0.5037 - recall_1: 0.4674\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 18s 71ms/step - loss: 0.6929 - acc: 0.5158 - precision_1: 0.5152 - recall_1: 0.4950\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 16s 62ms/step - loss: 0.6928 - acc: 0.5142 - precision_1: 0.5133 - recall_1: 0.50351s - loss: 0.6928 - acc: 0.5152 - pr\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.6916 - acc: 0.5284 - precision_1: 0.5282 - recall_1: 0.5126\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6917 - acc: 0.5232 - precision_1: 0.5227 - recall_1: 0.5096\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6921 - acc: 0.5200 - precision_1: 0.5190 - recall_1: 0.5167\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6920 - acc: 0.5239 - precision_1: 0.5204 - recall_1: 0.5834\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6915 - acc: 0.5160 - precision_1: 0.5156 - recall_1: 0.4906\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6921 - acc: 0.5152 - precision_1: 0.5154 - recall_1: 0.46842s - loss: 0\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6910 - acc: 0.5238 - precision_1: 0.5240 - recall_1: 0.49622s - loss: 0\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6919 - acc: 0.5226 - precision_1: 0.5206 - recall_1: 0.54190s - loss: 0.6918 - acc: 0.5230 - precision_1: 0.5211 - recall_1: \n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6912 - acc: 0.5222 - precision_1: 0.5207 - recall_1: 0.5319\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6918 - acc: 0.5228 - precision_1: 0.5234 - recall_1: 0.4850\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6912 - acc: 0.5322 - precision_1: 0.5320 - recall_1: 0.5175\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 18s 71ms/step - loss: 0.6908 - acc: 0.5288 - precision_1: 0.5275 - recall_1: 0.5321\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6911 - acc: 0.5172 - precision_1: 0.5169 - recall_1: 0.4930\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6911 - acc: 0.5271 - precision_1: 0.5254 - recall_1: 0.5382\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6902 - acc: 0.5337 - precision_1: 0.5330 - recall_1: 0.5258\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6908 - acc: 0.5258 - precision_1: 0.5253 - recall_1: 0.5128\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6902 - acc: 0.5359 - precision_1: 0.5365 - recall_1: 0.51094s\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6887 - acc: 0.5400 - precision_1: 0.5421 - recall_1: 0.50131s - loss: 0.6893 - acc: 0.5388 - precis - ETA: 0s - loss: 0.6888 - acc: 0.5403 - precision_1: 0.5420 - re\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 16s 63ms/step - loss: 0.6901 - acc: 0.5298 - precision_1: 0.5288 - recall_1: 0.5267\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6885 - acc: 0.5376 - precision_1: 0.5396 - recall_1: 0.4977\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6900 - acc: 0.5385 - precision_1: 0.5385 - recall_1: 0.5240\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6899 - acc: 0.5334 - precision_1: 0.5347 - recall_1: 0.4982\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 18s 71ms/step - loss: 0.6897 - acc: 0.5309 - precision_1: 0.5287 - recall_1: 0.5494\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 18s 71ms/step - loss: 0.6894 - acc: 0.5352 - precision_1: 0.5365 - recall_1: 0.5021\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6900 - acc: 0.5275 - precision_1: 0.5265 - recall_1: 0.5236\n",
      "Epoch 00030: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6896 - acc: 0.5367 - precision_1: 0.5616 - recall_1: 0.4206\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 17s 68ms/step - loss: 0.6951 - acc: 0.5089 - precision_2: 0.5077 - recall_2: 0.50181s - loss: 0.6952 - acc:\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6933 - acc: 0.5113 - precision_2: 0.5109 - recall_2: 0.4628\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6933 - acc: 0.5214 - precision_2: 0.5201 - recall_2: 0.5177\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 18s 68ms/step - loss: 0.6920 - acc: 0.5220 - precision_2: 0.5206 - recall_2: 0.5226\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6926 - acc: 0.5087 - precision_2: 0.5074 - recall_2: 0.5001\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6924 - acc: 0.5176 - precision_2: 0.5167 - recall_2: 0.50280s - loss: 0.6924 - acc: 0.5191 - precision_2: 0\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.6923 - acc: 0.5153 - precision_2: 0.5155 - recall_2: 0.4623\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6919 - acc: 0.5156 - precision_2: 0.5137 - recall_2: 0.5358\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6922 - acc: 0.5193 - precision_2: 0.5196 - recall_2: 0.4755\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6913 - acc: 0.5231 - precision_2: 0.5216 - recall_2: 0.5250\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 19s 76ms/step - loss: 0.6924 - acc: 0.5121 - precision_2: 0.5111 - recall_2: 0.4967\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 20s 77ms/step - loss: 0.6918 - acc: 0.5159 - precision_2: 0.5151 - recall_2: 0.4960\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6909 - acc: 0.5242 - precision_2: 0.5240 - recall_2: 0.4991\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6916 - acc: 0.5220 - precision_2: 0.5203 - recall_2: 0.5277\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6918 - acc: 0.5163 - precision_2: 0.5148 - recall_2: 0.5187\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.6919 - acc: 0.5191 - precision_2: 0.5173 - recall_2: 0.5289\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6917 - acc: 0.5214 - precision_2: 0.5219 - recall_2: 0.4779\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6910 - acc: 0.5262 - precision_2: 0.5236 - recall_2: 0.5524\n",
      "Epoch 00018: early stopping\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6882 - acc: 0.5323 - precision_2: 0.5496 - recall_2: 0.4850\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 18s 72ms/step - loss: 0.6952 - acc: 0.5133 - precision_3: 0.5140 - recall_3: 0.5236\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6931 - acc: 0.5194 - precision_3: 0.5183 - recall_3: 0.5737\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6934 - acc: 0.5144 - precision_3: 0.5144 - recall_3: 0.5452\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6933 - acc: 0.5046 - precision_3: 0.5052 - recall_3: 0.5267\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6925 - acc: 0.5177 - precision_3: 0.5181 - recall_3: 0.5323\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6934 - acc: 0.5071 - precision_3: 0.5087 - recall_3: 0.4691\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6920 - acc: 0.5180 - precision_3: 0.5179 - recall_3: 0.5457\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6926 - acc: 0.5178 - precision_3: 0.5184 - recall_3: 0.5287\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 19s 72ms/step - loss: 0.6916 - acc: 0.5164 - precision_3: 0.5178 - recall_3: 0.5034\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6924 - acc: 0.5155 - precision_3: 0.5154 - recall_3: 0.5508\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6912 - acc: 0.5240 - precision_3: 0.5259 - recall_3: 0.5068\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.6911 - acc: 0.5244 - precision_3: 0.5238 - recall_3: 0.55591s - loss: 0.6911 - acc: 0.5234 - precision_3: 0.5230 - recall_3 - ETA: \n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6914 - acc: 0.5225 - precision_3: 0.5228 - recall_3: 0.5345\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 17s 67ms/step - loss: 0.6916 - acc: 0.5165 - precision_3: 0.5157 - recall_3: 0.5712\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6911 - acc: 0.5282 - precision_3: 0.5270 - recall_3: 0.5666\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 18s 72ms/step - loss: 0.6908 - acc: 0.5284 - precision_3: 0.5269 - recall_3: 0.5744\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6914 - acc: 0.5262 - precision_3: 0.5265 - recall_3: 0.5386\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6905 - acc: 0.5206 - precision_3: 0.5202 - recall_3: 0.5530\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6905 - acc: 0.5267 - precision_3: 0.5262 - recall_3: 0.5537\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 19s 72ms/step - loss: 0.6901 - acc: 0.5312 - precision_3: 0.5316 - recall_3: 0.5396\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 18s 72ms/step - loss: 0.6900 - acc: 0.5247 - precision_3: 0.5237 - recall_3: 0.5632\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6894 - acc: 0.5371 - precision_3: 0.5377 - recall_3: 0.54040s - loss: 0.6894 - acc: 0.5370 - precision_3: 0.5373 - recall_3: 0.\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6907 - acc: 0.5211 - precision_3: 0.5225 - recall_3: 0.51021s - loss: 0.6905 - ac\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6904 - acc: 0.5284 - precision_3: 0.5293 - recall_3: 0.5287\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 17s 64ms/step - loss: 0.6900 - acc: 0.5320 - precision_3: 0.5339 - recall_3: 0.5175\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6898 - acc: 0.5266 - precision_3: 0.5267 - recall_3: 0.5425\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6883 - acc: 0.5455 - precision_3: 0.5471 - recall_3: 0.53793s - loss: 0.6881 - acc: 0.5456 - precision_\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6890 - acc: 0.5428 - precision_3: 0.5437 - recall_3: 0.54230s - loss: 0.6890 - acc: 0.5418 - precis\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 16s 60ms/step - loss: 0.6896 - acc: 0.5260 - precision_3: 0.5270 - recall_3: 0.5241\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6900 - acc: 0.5343 - precision_3: 0.5357 - recall_3: 0.5277\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6898 - acc: 0.5355 - precision_3: 0.5374 - recall_3: 0.5219\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6903 - acc: 0.5262 - precision_3: 0.5280 - recall_3: 0.5117\n",
      "Epoch 00032: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6923 - acc: 0.5126 - precision_3: 0.5137 - recall_3: 0.1670\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 18s 71ms/step - loss: 0.6957 - acc: 0.5103 - precision_4: 0.5104 - recall_4: 0.5721\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6937 - acc: 0.5043 - precision_4: 0.5061 - recall_4: 0.4718\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6937 - acc: 0.5170 - precision_4: 0.5162 - recall_4: 0.5826\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6925 - acc: 0.5192 - precision_4: 0.5203 - recall_4: 0.5270\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6926 - acc: 0.5124 - precision_4: 0.5140 - recall_4: 0.5029\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6926 - acc: 0.5156 - precision_4: 0.5161 - recall_4: 0.5440\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 14s 54ms/step - loss: 0.6923 - acc: 0.5152 - precision_4: 0.5156 - recall_4: 0.5471\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6923 - acc: 0.5212 - precision_4: 0.5222 - recall_4: 0.5301\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 18s 69ms/step - loss: 0.6913 - acc: 0.5249 - precision_4: 0.5239 - recall_4: 0.5743\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6915 - acc: 0.5204 - precision_4: 0.5222 - recall_4: 0.5104\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6911 - acc: 0.5275 - precision_4: 0.5276 - recall_4: 0.5508\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6917 - acc: 0.5183 - precision_4: 0.5190 - recall_4: 0.5362\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6907 - acc: 0.5248 - precision_4: 0.5254 - recall_4: 0.5408\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6914 - acc: 0.5307 - precision_4: 0.5313 - recall_4: 0.5437\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6917 - acc: 0.5214 - precision_4: 0.5208 - recall_4: 0.5675\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 20s 76ms/step - loss: 0.6911 - acc: 0.5268 - precision_4: 0.5262 - recall_4: 0.5663\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6896 - acc: 0.5389 - precision_4: 0.5396 - recall_4: 0.5476\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 19s 76ms/step - loss: 0.6907 - acc: 0.5265 - precision_4: 0.5254 - recall_4: 0.5746\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6908 - acc: 0.5232 - precision_4: 0.5232 - recall_4: 0.5542\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6902 - acc: 0.5339 - precision_4: 0.5339 - recall_4: 0.5542\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 18s 70ms/step - loss: 0.6897 - acc: 0.5331 - precision_4: 0.5351 - recall_4: 0.5236\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6898 - acc: 0.5301 - precision_4: 0.5296 - recall_4: 0.5634\n",
      "Epoch 00022: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6874 - acc: 0.5465 - precision_4: 0.5379 - recall_4: 0.4944\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 19s 75ms/step - loss: 0.6974 - acc: 0.5029 - precision_5: 0.5029 - recall_5: 0.5251\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6932 - acc: 0.5127 - precision_5: 0.5129 - recall_5: 0.5134\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6930 - acc: 0.5187 - precision_5: 0.5180 - recall_5: 0.5441\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6932 - acc: 0.5171 - precision_5: 0.5193 - recall_5: 0.4652\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 19s 73ms/step - loss: 0.6930 - acc: 0.5158 - precision_5: 0.5172 - recall_5: 0.4798\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6926 - acc: 0.5192 - precision_5: 0.5198 - recall_5: 0.5073\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 19s 74ms/step - loss: 0.6924 - acc: 0.5225 - precision_5: 0.5244 - recall_5: 0.48661s - loss: 0.6921 - \n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 22s 84ms/step - loss: 0.6919 - acc: 0.5187 - precision_5: 0.5183 - recall_5: 0.53412s - loss: 0.6920 \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 21s 80ms/step - loss: 0.6922 - acc: 0.5171 - precision_5: 0.5178 - recall_5: 0.5027\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 21s 83ms/step - loss: 0.6921 - acc: 0.5188 - precision_5: 0.5181 - recall_5: 0.54244s - - ETA: 1s - loss: 0.6922 - ac\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 16s 64ms/step - loss: 0.6911 - acc: 0.5296 - precision_5: 0.5294 - recall_5: 0.53680s - loss: 0.6911 - acc: 0.5296 - precision_5: 0.5294 - recall_5: 0.53\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6914 - acc: 0.5199 - precision_5: 0.5200 - recall_5: 0.52174s -\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6910 - acc: 0.5228 - precision_5: 0.5220 - recall_5: 0.54551s - loss: 0.6912 - acc: 0.523\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6904 - acc: 0.5328 - precision_5: 0.5341 - recall_5: 0.51660s - loss: 0.6904 - acc: 0.5325 - precision_5: 0.5329 - recall_5: \n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 14s 54ms/step - loss: 0.6909 - acc: 0.5227 - precision_5: 0.5216 - recall_5: 0.5528\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.6913 - acc: 0.5251 - precision_5: 0.5253 - recall_5: 0.5260\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6909 - acc: 0.5261 - precision_5: 0.5270 - recall_5: 0.51271s - loss:\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6903 - acc: 0.5320 - precision_5: 0.5309 - recall_5: 0.5528\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6905 - acc: 0.5275 - precision_5: 0.5279 - recall_5: 0.5234\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6907 - acc: 0.5281 - precision_5: 0.5273 - recall_5: 0.5448\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6899 - acc: 0.5354 - precision_5: 0.5376 - recall_5: 0.5088\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6902 - acc: 0.5248 - precision_5: 0.5249 - recall_5: 0.5265\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6899 - acc: 0.5305 - precision_5: 0.5306 - recall_5: 0.5324\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6891 - acc: 0.5396 - precision_5: 0.5395 - recall_5: 0.5431\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6882 - acc: 0.5355 - precision_5: 0.5342 - recall_5: 0.5567\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6908 - acc: 0.5264 - precision_5: 0.5270 - recall_5: 0.5175\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6885 - acc: 0.5387 - precision_5: 0.5378 - recall_5: 0.5528\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6895 - acc: 0.5320 - precision_5: 0.5310 - recall_5: 0.5497\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6890 - acc: 0.5363 - precision_5: 0.5375 - recall_5: 0.52341s - loss:\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6886 - acc: 0.5335 - precision_5: 0.5334 - recall_5: 0.5387\n",
      "Epoch 00030: early stopping\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6932 - acc: 0.5235 - precision_5: 0.5610 - recall_5: 0.2022\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6963 - acc: 0.5073 - precision_6: 0.5075 - recall_6: 0.4950\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6942 - acc: 0.5068 - precision_6: 0.5068 - recall_6: 0.5050\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6930 - acc: 0.5196 - precision_6: 0.5194 - recall_6: 0.5237\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6937 - acc: 0.5044 - precision_6: 0.5044 - recall_6: 0.49912s - - ETA: 1s - loss: 0.6936 - acc: 0.5056 - precision_6: - ETA: 0s - loss: 0.6936 - acc: 0.5050 - precision_6: 0.5035 - reca\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6932 - acc: 0.5082 - precision_6: 0.5078 - recall_6: 0.5342\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6928 - acc: 0.5138 - precision_6: 0.5130 - recall_6: 0.54421s - loss: 0.6930 - acc: 0.5\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6925 - acc: 0.5085 - precision_6: 0.5086 - recall_6: 0.5013\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6924 - acc: 0.5218 - precision_6: 0.5215 - recall_6: 0.5286\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6915 - acc: 0.5245 - precision_6: 0.5243 - recall_6: 0.5274\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.6919 - acc: 0.5200 - precision_6: 0.5193 - recall_6: 0.5376\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.6924 - acc: 0.5119 - precision_6: 0.5119 - recall_6: 0.5118\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6927 - acc: 0.5085 - precision_6: 0.5078 - recall_6: 0.5542\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6921 - acc: 0.5229 - precision_6: 0.5251 - recall_6: 0.4792\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6918 - acc: 0.5192 - precision_6: 0.5174 - recall_6: 0.5732\n",
      "Epoch 00014: early stopping\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5143 - precision_6: 0.6066 - recall_6: 0.0811\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6938 - acc: 0.5135 - precision_7: 0.5134 - recall_7: 0.5104\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 14s 54ms/step - loss: 0.6941 - acc: 0.5040 - precision_7: 0.5036 - recall_7: 0.5223\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6930 - acc: 0.5151 - precision_7: 0.5145 - recall_7: 0.5262\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6918 - acc: 0.5196 - precision_7: 0.5194 - recall_7: 0.5179\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6929 - acc: 0.5072 - precision_7: 0.5066 - recall_7: 0.5313\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6927 - acc: 0.5166 - precision_7: 0.5169 - recall_7: 0.4996\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6925 - acc: 0.5161 - precision_7: 0.5154 - recall_7: 0.5308\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6918 - acc: 0.5177 - precision_7: 0.5162 - recall_7: 0.5535\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6921 - acc: 0.5175 - precision_7: 0.5183 - recall_7: 0.4901\n",
      "Epoch 00009: early stopping\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6915 - acc: 0.5186 - precision_7: 0.5140 - recall_7: 0.7598\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6954 - acc: 0.5066 - precision_8: 0.5051 - recall_8: 0.5101\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6930 - acc: 0.5174 - precision_8: 0.5157 - recall_8: 0.5255\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6930 - acc: 0.5170 - precision_8: 0.5154 - recall_8: 0.5223\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6927 - acc: 0.5170 - precision_8: 0.5177 - recall_8: 0.4569\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6926 - acc: 0.5122 - precision_8: 0.5112 - recall_8: 0.4926\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6922 - acc: 0.5197 - precision_8: 0.5196 - recall_8: 0.4855\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6922 - acc: 0.5179 - precision_8: 0.5188 - recall_8: 0.4537\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6923 - acc: 0.5213 - precision_8: 0.5207 - recall_8: 0.5016\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6925 - acc: 0.5146 - precision_8: 0.5137 - recall_8: 0.4943\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6917 - acc: 0.5245 - precision_8: 0.5240 - recall_8: 0.50451s - l\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6917 - acc: 0.5280 - precision_8: 0.5279 - recall_8: 0.5033\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6919 - acc: 0.5151 - precision_8: 0.5150 - recall_8: 0.4701\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6917 - acc: 0.5189 - precision_8: 0.5186 - recall_8: 0.4862\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6917 - acc: 0.5248 - precision_8: 0.5219 - recall_8: 0.5592\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.6917 - acc: 0.5235 - precision_8: 0.5246 - recall_8: 0.4718\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6914 - acc: 0.5211 - precision_8: 0.5183 - recall_8: 0.5556\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.6907 - acc: 0.5281 - precision_8: 0.5274 - recall_8: 0.5143\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 16s 60ms/step - loss: 0.6903 - acc: 0.5282 - precision_8: 0.5261 - recall_8: 0.5411\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6917 - acc: 0.5162 - precision_8: 0.5142 - recall_8: 0.5360\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6915 - acc: 0.5220 - precision_8: 0.5217 - recall_8: 0.4965\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6907 - acc: 0.5264 - precision_8: 0.5252 - recall_8: 0.5216\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6914 - acc: 0.5220 - precision_8: 0.5218 - recall_8: 0.4938\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6902 - acc: 0.5325 - precision_8: 0.5294 - recall_8: 0.56073s - loss: 0.6904 - acc: 0.5317  - E\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6901 - acc: 0.5287 - precision_8: 0.5276 - recall_8: 0.5228\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6903 - acc: 0.5279 - precision_8: 0.5273 - recall_8: 0.5121\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6900 - acc: 0.5225 - precision_8: 0.5204 - recall_8: 0.5380\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6895 - acc: 0.5320 - precision_8: 0.5303 - recall_8: 0.5368\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6903 - acc: 0.5264 - precision_8: 0.5269 - recall_8: 0.49081s - loss: 0.6898 - \n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6899 - acc: 0.5297 - precision_8: 0.5292 - recall_8: 0.5128\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.6903 - acc: 0.5304 - precision_8: 0.5300 - recall_8: 0.51 - 14s 56ms/step - loss: 0.6903 - acc: 0.5304 - precision_8: 0.5300 - recall_8: 0.5136\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6899 - acc: 0.5292 - precision_8: 0.5279 - recall_8: 0.5275\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6891 - acc: 0.5331 - precision_8: 0.5332 - recall_8: 0.5092\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6897 - acc: 0.5358 - precision_8: 0.5356 - recall_8: 0.5187\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6894 - acc: 0.5346 - precision_8: 0.5343 - recall_8: 0.5179\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6897 - acc: 0.5299 - precision_8: 0.5290 - recall_8: 0.5211\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6887 - acc: 0.5393 - precision_8: 0.5381 - recall_8: 0.5358\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6890 - acc: 0.5331 - precision_8: 0.5314 - recall_8: 0.5377\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6884 - acc: 0.5373 - precision_8: 0.5375 - recall_8: 0.5150\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6896 - acc: 0.5376 - precision_8: 0.5389 - recall_8: 0.5023\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6886 - acc: 0.5364 - precision_8: 0.5389 - recall_8: 0.4857\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6883 - acc: 0.5348 - precision_8: 0.5362 - recall_8: 0.49551s - loss: 0.6877 - acc: 0.5\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6892 - acc: 0.5383 - precision_8: 0.5396 - recall_8: 0.5043\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6888 - acc: 0.5276 - precision_8: 0.5278 - recall_8: 0.4977\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6883 - acc: 0.5409 - precision_8: 0.5424 - recall_8: 0.5062\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6890 - acc: 0.5321 - precision_8: 0.5334 - recall_8: 0.4913\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6896 - acc: 0.5321 - precision_8: 0.5327 - recall_8: 0.5018\n",
      "Epoch 00046: early stopping\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6899 - acc: 0.5329 - precision_8: 0.6010 - recall_8: 0.2671\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 14s 55ms/step - loss: 0.6968 - acc: 0.5007 - precision_9: 0.5012 - recall_9: 0.5084\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6926 - acc: 0.5088 - precision_9: 0.5082 - recall_9: 0.5726\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6937 - acc: 0.5100 - precision_9: 0.5109 - recall_9: 0.4919\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6924 - acc: 0.5141 - precision_9: 0.5144 - recall_9: 0.52181s - loss: 0.6923 - acc: 0\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6922 - acc: 0.5136 - precision_9: 0.5133 - recall_9: 0.5427\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6925 - acc: 0.5151 - precision_9: 0.5171 - recall_9: 0.47022s - loss: 0.6925 - ac - ETA: 1s - loss: 0.6925 - acc: 0.5163 \n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.6915 - acc: 0.5212 - precision_9: 0.5203 - recall_9: 0.5558\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6910 - acc: 0.5257 - precision_9: 0.5260 - recall_9: 0.5296\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.6919 - acc: 0.5151 - precision_9: 0.5172 - recall_9: 0.46923s - loss: 0.6915 - acc: 0.5173 - precision_9: 0.5205  - ETA: 3s - loss: 0.6912 - acc: 0.5182 - \n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6921 - acc: 0.5170 - precision_9: 0.5185 - recall_9: 0.4911\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6913 - acc: 0.5172 - precision_9: 0.5174 - recall_9: 0.5257\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6917 - acc: 0.5220 - precision_9: 0.5218 - recall_9: 0.53901s - loss: 0.6916 - ac\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.6919 - acc: 0.5184 - precision_9: 0.5178 - recall_9: 0.5485\n",
      "Epoch 00013: early stopping\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6913 - acc: 0.5504 - precision_9: 0.5600 - recall_9: 0.4336\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=1)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= tf_idf (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "\n",
    "    modelLSTM = Sequential()\n",
    "    modelLSTM.add(embedding_layer)\n",
    "    modelLSTM.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    modelLSTM.add(Dense(1, activation='sigmoid'))\n",
    "    modelLSTM.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelLSTM.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelLSTM.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.531338\n",
      "test precision: 0.556761\n",
      "test recall: 0.362485\n",
      "test f1_score: 0.407871\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
