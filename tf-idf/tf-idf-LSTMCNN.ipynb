{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['tweets','duygu','preprocessing']\n",
    "#df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "\n",
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canım turkcell?? neti bir kez bile kesmedi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell bana kazık atıyoo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkcell'li olan varsa söylesin çabuk fena bi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ulak'ta ilk ön siparişi turkcell verdi https:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turkcell'in sahur interneti iyi ki var</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>sedaya ingiltereden guzel ama yalniz kadinlar ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>sabri reyiz ile ilgili onlarca guzel reklam ce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>hayata gülümse diyor oç turkcell ne güzel süla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>@myygoddemi  yaşasın turkcell superonline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell yine sivri zekalığı ile ufak bir bütç...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0            canım turkcell?? neti bir kez bile kesmedi     1\n",
       "1                            turkcell bana kazık atıyoo     0\n",
       "2     turkcell'li olan varsa söylesin çabuk fena bi ...     1\n",
       "3     ulak'ta ilk ön siparişi turkcell verdi https:/...     1\n",
       "4                turkcell'in sahur interneti iyi ki var     1\n",
       "...                                                 ...   ...\n",
       "9121  sedaya ingiltereden guzel ama yalniz kadinlar ...     0\n",
       "9122  sabri reyiz ile ilgili onlarca guzel reklam ce...     0\n",
       "9123  hayata gülümse diyor oç turkcell ne güzel süla...     0\n",
       "9124          @myygoddemi  yaşasın turkcell superonline     1\n",
       "9125  turkcell yine sivri zekalığı ile ufak bir bütç...     1\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf (X_train,y_train,X_test,y_test):\n",
    "    #Create a tokenizer, configured to only take into account the 20 most common words çok küçük olursa kelimeleri \n",
    "    #kaybederiz underfit yaparız\n",
    "    tokenizer = Tokenizer(num_words=1000) #en yaygın kaç kelimeyi dikkate alacağı. Belirtilecek en iyi kelime sayısı #1000 yapan da var\n",
    "    tokenizer.fit_on_texts(X_train) #keras tokenizer ile metni dictionary haline getiriyor.\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train) #kelimelerin dictionarydeki karşılığı \n",
    "    #[[2, 1, 3], [2, 1], [4, 1], [5, 6]] şekline getiriliyor. 2-machine 1- learning 3-Knowledge \n",
    "    word_index = tokenizer.word_index #dictionarydeki kelimelerin sayısal karşılığı 'unk': 1, 'ürün': 2,\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)): #len(sequences_X_train) ile kaç tane [[2,3,4],[2,6]] var bulunuyor burda 2\n",
    "        numberofwords=len(sequences_X_train[review_number]) #[2,3,4] içinde kaç tane şey var 3 burda\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords #tüm kelimelere bakıp en uzun olanı buluyor\n",
    "\n",
    "    vocabulary=[]\n",
    "    for key in word_index.keys():\n",
    "        vocabulary.append(key)\n",
    "\n",
    "    pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
    "                     ('tfid', TfidfTransformer())]).fit(X_train)\n",
    "\n",
    "    res = dict(zip(vocabulary, pipe['tfid'].idf_))\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length) #ikili boyutlu matrise çevirip her cümelnin uzunluğunu eşit yapıyor.\n",
    "    #En uzun cümle uzunluğuna tamamlanıyor.[[2 1 3] [0 2 1]] alt alta gelecek şekilde en uzun 6 ise 6x6 matris oluyor\n",
    "    y_train = np.asarray(y_train) #tek boyutlu bir matris oluyor [1 1 0 ... 0 1 0] gibi\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test) #train için yapılan gibi dictionary alınıyor\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length) #en uzun olana göre pad sequence yapılıyor\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    unique_words = len(word_index) #word_index ile unique olan kelimeler alınıyor 0 dan başladığı için bir arttırılıyor\n",
    "    total_words = unique_words + 1\n",
    "    \n",
    "    skipped_words = 0\n",
    "    embedding_dim = 1 #embedding dim vector size ile aynı \n",
    "    embedding_vector=0\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items(): #kelime ve kelimenin dictionarydeki karşılığı alınıyor\n",
    "        try:\n",
    "            embedding_vector = res[word] #kelimenin word2vec karşılığı vektör olarak\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector \n",
    "            \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "\n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6944 - acc: 0.5131 - precision: 0.5109 - recall: 0.5313\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6926 - acc: 0.5204 - precision: 0.5185 - recall: 0.5239\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6911 - acc: 0.5288 - precision: 0.5270 - recall: 0.5301\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6908 - acc: 0.5272 - precision: 0.5259 - recall: 0.5191 1s -\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6900 - acc: 0.5301 - precision: 0.5279 - recall: 0.5393\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6895 - acc: 0.5370 - precision: 0.5350 - recall: 0.5403\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6887 - acc: 0.5368 - precision: 0.5343 - recall: 0.5481\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6881 - acc: 0.5433 - precision: 0.5398 - recall: 0.5657 3s - l -\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6888 - acc: 0.5411 - precision: 0.5359 - recall: 0.5887\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6870 - acc: 0.5404 - precision: 0.5379 - recall: 0.5494 0s - loss: 0.6863 - acc: 0.5426 - precisio - ETA: 0s - loss: 0.6871 - acc: 0.5402 - precision: 0.5365 - recall: \n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6865 - acc: 0.5434 - precision: 0.5394 - recall: 0.5718\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6859 - acc: 0.5477 - precision: 0.5431 - recall: 0.5809\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6863 - acc: 0.5478 - precision: 0.5461 - recall: 0.5469\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6844 - acc: 0.5488 - precision: 0.5452 - recall: 0.5687\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6839 - acc: 0.5525 - precision: 0.5484 - recall: 0.5777 3s - loss: 0.6829 - acc: 0.5522 - precision: 0.5457 - recall:  - ETA: 3s - loss: 0.6833 - ac - ETA: 1s\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6837 - acc: 0.5497 - precision: 0.5464 - recall: 0.5667\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6825 - acc: 0.5568 - precision: 0.5507 - recall: 0.5997\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6819 - acc: 0.5529 - precision: 0.5506 - recall: 0.5587\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6822 - acc: 0.5542 - precision: 0.5520 - recall: 0.5589 1s - loss: 0.6804 - acc: 0.561\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6811 - acc: 0.5519 - precision: 0.5479 - recall: 0.5762 1s - loss: 0.6809 - ac\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6797 - acc: 0.5601 - precision: 0.5555 - recall: 0.5858\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6794 - acc: 0.5586 - precision: 0.5553 - recall: 0.5726 0s - loss: 0.6793 - acc: 0.5588 - precision: 0.5558 - recall: 0.57\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6787 - acc: 0.5680 - precision: 0.5653 - recall: 0.5753\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6777 - acc: 0.5651 - precision: 0.5618 - recall: 0.5777 0s - loss: 0.6785 - acc: 0.5648 - precision: 0.5630 \n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6768 - acc: 0.5664 - precision: 0.5643 - recall: 0.5694\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6765 - acc: 0.5636 - precision: 0.5631 - recall: 0.5538\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6755 - acc: 0.5682 - precision: 0.5662 - recall: 0.5709 0s - loss: 0.6746 - acc: 0.5719 - prec\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6748 - acc: 0.5675 - precision: 0.5671 - recall: 0.5579\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6732 - acc: 0.5673 - precision: 0.5636 - recall: 0.5828\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6724 - acc: 0.5708 - precision: 0.5700 - recall: 0.5640 1s - loss: 0.6\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6706 - acc: 0.5768 - precision: 0.5760 - recall: 0.5706\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6692 - acc: 0.5754 - precision: 0.5771 - recall: 0.5533\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6680 - acc: 0.5788 - precision: 0.5787 - recall: 0.5687 3s - loss: 0.6700 - acc: 0.5\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6652 - acc: 0.5826 - precision: 0.5843 - recall: 0.5621\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6656 - acc: 0.5820 - precision: 0.5840 - recall: 0.5599\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6629 - acc: 0.5885 - precision: 0.5886 - recall: 0.5782 0s - loss: 0.6627 - acc: 0.5905 - precision: 0.5912 \n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6608 - acc: 0.5852 - precision: 0.5829 - recall: 0.5887\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6568 - acc: 0.5926 - precision: 0.5927 - recall: 0.5828\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6535 - acc: 0.5998 - precision: 0.6002 - recall: 0.5892\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6515 - acc: 0.5989 - precision: 0.5993 - recall: 0.5887\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6502 - acc: 0.6015 - precision: 0.5983 - recall: 0.6090 2s - loss: 0 - ETA: 0s - loss: 0.6513 - acc: 0.5985 - precision: 0\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6482 - acc: 0.6027 - precision: 0.6042 - recall: 0.5875 0s - loss: 0.6471 - acc: 0.6006 - \n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6445 - acc: 0.6087 - precision: 0.6095 - recall: 0.5973\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6408 - acc: 0.6152 - precision: 0.6155 - recall: 0.6068\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6340 - acc: 0.6163 - precision: 0.6156 - recall: 0.6124 0s - loss: 0.6350 - acc: 0.6165 - pr\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6330 - acc: 0.6177 - precision: 0.6148 - recall: 0.6229 0s - loss: 0.6306 - acc: 0.6187 - precision: 0.6171 \n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6280 - acc: 0.6277 - precision: 0.6278 - recall: 0.6207\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6264 - acc: 0.6246 - precision: 0.6221 - recall: 0.6283 1s - loss: 0\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6196 - acc: 0.6312 - precision: 0.6306 - recall: 0.6271\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6171 - acc: 0.6338 - precision: 0.6314 - recall: 0.6366 0s - loss: 0.6174 - acc: 0.6315 - pr\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7215 - acc: 0.5433 - precision: 0.5640 - recall: 0.5053\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6949 - acc: 0.5239 - precision_1: 0.5235 - recall_1: 0.5973\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6928 - acc: 0.5180 - precision_1: 0.5215 - recall_1: 0.5082\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6919 - acc: 0.5227 - precision_1: 0.5248 - recall_1: 0.5433 2s - loss: 0.6924  - ETA: 1s - loss: 0.6920 - acc: 0.5224 - precision_1: 0.5244 - recall_1: 0.54 - ETA: 1s - loss: 0.6919 - acc: 0.5232 \n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6907 - acc: 0.5307 - precision_1: 0.5327 - recall_1: 0.5474 0s - loss: 0.6907 - acc: 0.5287 - precis\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6905 - acc: 0.5299 - precision_1: 0.5341 - recall_1: 0.5133\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6902 - acc: 0.5306 - precision_1: 0.5307 - recall_1: 0.5789\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6888 - acc: 0.5357 - precision_1: 0.5364 - recall_1: 0.5687\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6895 - acc: 0.5339 - precision_1: 0.5363 - recall_1: 0.5428 1s - loss: 0.6891 \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6879 - acc: 0.5408 - precision_1: 0.5414 - recall_1: 0.5709\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6882 - acc: 0.5416 - precision_1: 0.5434 - recall_1: 0.5561\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6865 - acc: 0.5430 - precision_1: 0.5430 - recall_1: 0.5791\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6862 - acc: 0.5385 - precision_1: 0.5392 - recall_1: 0.5690\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6862 - acc: 0.5383 - precision_1: 0.5388 - recall_1: 0.5716 2s - loss: 0.6 - ETA: 0s - loss: 0.6864 - acc: 0.5389 - precis\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6857 - acc: 0.5365 - precision_1: 0.5365 - recall_1: 0.5774 1s - loss: 0.6876 - acc: 0.5321 - \n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6849 - acc: 0.5426 - precision_1: 0.5415 - recall_1: 0.5915\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 3s 14ms/step - loss: 0.6844 - acc: 0.5445 - precision_1: 0.5444 - recall_1: 0.5796\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6844 - acc: 0.5399 - precision_1: 0.5404 - recall_1: 0.5709\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6833 - acc: 0.5506 - precision_1: 0.5491 - recall_1: 0.5973\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6832 - acc: 0.5485 - precision_1: 0.5493 - recall_1: 0.5716\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6826 - acc: 0.5479 - precision_1: 0.5481 - recall_1: 0.5774\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6818 - acc: 0.5517 - precision_1: 0.5509 - recall_1: 0.5895\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6815 - acc: 0.5507 - precision_1: 0.5511 - recall_1: 0.5772\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6805 - acc: 0.5583 - precision_1: 0.5596 - recall_1: 0.5728\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6805 - acc: 0.5607 - precision_1: 0.5616 - recall_1: 0.5782\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6794 - acc: 0.5674 - precision_1: 0.5663 - recall_1: 0.5983\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6780 - acc: 0.5597 - precision_1: 0.5650 - recall_1: 0.5426\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6782 - acc: 0.5583 - precision_1: 0.5596 - recall_1: 0.5726\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6769 - acc: 0.5667 - precision_1: 0.5668 - recall_1: 0.5883\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6756 - acc: 0.5636 - precision_1: 0.5655 - recall_1: 0.5728\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6750 - acc: 0.5682 - precision_1: 0.5687 - recall_1: 0.5869\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6730 - acc: 0.5647 - precision_1: 0.5654 - recall_1: 0.5825 0s - loss: 0.6727 - acc: 0.5658 - precision_1: 0.5681 - recall_1 - ETA: 0s - loss: 0.6735 - acc: 0.5643 - precision_1: 0.5665 - recall\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6715 - acc: 0.5703 - precision_1: 0.5729 - recall_1: 0.5731\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6705 - acc: 0.5692 - precision_1: 0.5697 - recall_1: 0.5874\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6695 - acc: 0.5679 - precision_1: 0.5692 - recall_1: 0.5803 0s - loss: 0.6701 - acc: 0.5668 - precision_1: 0.569\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6671 - acc: 0.5738 - precision_1: 0.5789 - recall_1: 0.5612\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6637 - acc: 0.5809 - precision_1: 0.5796 - recall_1: 0.6077\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6608 - acc: 0.5848 - precision_1: 0.5850 - recall_1: 0.6012 0s - loss: 0.6607 - acc: 0.5871 - precisio\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6621 - acc: 0.5822 - precision_1: 0.5835 - recall_1: 0.5929 0s - loss: 0.6607 - acc: 0.5863 - precision_1: 0.5\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6584 - acc: 0.5841 - precision_1: 0.5832 - recall_1: 0.6072\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6555 - acc: 0.5924 - precision_1: 0.5933 - recall_1: 0.6033\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6541 - acc: 0.5931 - precision_1: 0.5962 - recall_1: 0.5922 0s - loss: 0.6539 - acc: 0.5930 - precision_1: 0.5937 - recall_1: \n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6523 - acc: 0.5915 - precision_1: 0.5925 - recall_1: 0.6024 4s - loss: 0.6457 - acc: 0.5771 - precision_1: 0.5794  - ETA: 4s - loss: 0.6487 - acc: 0.5807 - precision_1: 0.580 - ETA: 3s - loss: 0.6456 - acc: 0.5992 -  - ETA:  - ETA: 0s - loss: 0.6524 - acc: 0.5935 - precision_1: 0.5938 - recall_1\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6493 - acc: 0.5971 - precision_1: 0.5962 - recall_1: 0.6174\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6482 - acc: 0.5980 - precision_1: 0.5996 - recall_1: 0.6045 2s - loss: 0.6485 - acc: 0.6010 - precision_1: 0.6001 - recall_1:  - ETA\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6443 - acc: 0.5987 - precision_1: 0.5984 - recall_1: 0.6154\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6421 - acc: 0.6011 - precision_1: 0.6025 - recall_1: 0.6089\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6400 - acc: 0.6016 - precision_1: 0.6044 - recall_1: 0.6024\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6367 - acc: 0.6103 - precision_1: 0.6099 - recall_1: 0.6251 1s - loss: 0.6340 - acc: 0.6169 -  - ETA: 0s - loss: 0.6368 - acc: 0.6102 - precision_1: 0.6099 - recall_1: 0.62\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6301 - acc: 0.6163 - precision_1: 0.6158 - recall_1: 0.6312\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6303 - acc: 0.6156 - precision_1: 0.6176 - recall_1: 0.6196\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7455 - acc: 0.5170 - precision_1: 0.4903 - recall_1: 0.5893\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6941 - acc: 0.5181 - precision_2: 0.5163 - recall_2: 0.5919 2s - loss: 0.6952 - acc: 0.5188 - precision_2: 0.518 - ETA: 1s - loss:\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6923 - acc: 0.5237 - precision_2: 0.5237 - recall_2: 0.5375 3s - loss: 0.6952 - acc: 0\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6906 - acc: 0.5305 - precision_2: 0.5309 - recall_2: 0.5355\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6906 - acc: 0.5316 - precision_2: 0.5326 - recall_2: 0.5270  - ETA: 0s - loss: 0.6910 - acc: 0.5306 - precision_2: 0.5319 - \n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6903 - acc: 0.5338 - precision_2: 0.5334 - recall_2: 0.5501\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6899 - acc: 0.5323 - precision_2: 0.5309 - recall_2: 0.5669\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6891 - acc: 0.5383 - precision_2: 0.5406 - recall_2: 0.5180\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6892 - acc: 0.5342 - precision_2: 0.5344 - recall_2: 0.5396\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6887 - acc: 0.5376 - precision_2: 0.5358 - recall_2: 0.5710\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6872 - acc: 0.5440 - precision_2: 0.5443 - recall_2: 0.5484\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6855 - acc: 0.5484 - precision_2: 0.5473 - recall_2: 0.5671 4s - loss:\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6868 - acc: 0.5475 - precision_2: 0.5497 - recall_2: 0.5326 3s - loss: 0.6887 - acc: 0.5552 - \n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6848 - acc: 0.5502 - precision_2: 0.5511 - recall_2: 0.5486\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6840 - acc: 0.5468 - precision_2: 0.5463 - recall_2: 0.5601\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6834 - acc: 0.5417 - precision_2: 0.5397 - recall_2: 0.5751 3s - loss:\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6835 - acc: 0.5473 - precision_2: 0.5471 - recall_2: 0.5564\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6834 - acc: 0.5404 - precision_2: 0.5402 - recall_2: 0.5501\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6820 - acc: 0.5484 - precision_2: 0.5487 - recall_2: 0.5520 1s - loss: 0.6827 - acc: 0.5408 \n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6817 - acc: 0.5535 - precision_2: 0.5533 - recall_2: 0.5618\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6813 - acc: 0.5562 - precision_2: 0.5557 - recall_2: 0.5666\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6799 - acc: 0.5574 - precision_2: 0.5565 - recall_2: 0.5710\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6781 - acc: 0.5580 - precision_2: 0.5613 - recall_2: 0.5367\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6790 - acc: 0.5542 - precision_2: 0.5565 - recall_2: 0.5404\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6771 - acc: 0.5668 - precision_2: 0.5693 - recall_2: 0.5535 0s - loss: 0.6763 - acc: 0.5680 - prec\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6764 - acc: 0.5631 - precision_2: 0.5650 - recall_2: 0.5537\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6770 - acc: 0.5597 - precision_2: 0.5655 - recall_2: 0.5209 3s - los\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6754 - acc: 0.5633 - precision_2: 0.5634 - recall_2: 0.5674\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6738 - acc: 0.5661 - precision_2: 0.5687 - recall_2: 0.5516\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6717 - acc: 0.5702 - precision_2: 0.5758 - recall_2: 0.5377 0s - loss: 0.6720 - acc: 0.5720 - precision_2: 0.5767 - recall_2 - ETA: 0s - loss: 0.6721 - acc: 0.5721 - precision_2:\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6732 - acc: 0.5674 - precision_2: 0.5743 - recall_2: 0.5255\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6724 - acc: 0.5721 - precision_2: 0.5738 - recall_2: 0.5654\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6699 - acc: 0.5714 - precision_2: 0.5780 - recall_2: 0.5333 1s\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6690 - acc: 0.5791 - precision_2: 0.5840 - recall_2: 0.5540\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6693 - acc: 0.5738 - precision_2: 0.5794 - recall_2: 0.5433\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6657 - acc: 0.5826 - precision_2: 0.5855 - recall_2: 0.5698 2s -\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6651 - acc: 0.5829 - precision_2: 0.5852 - recall_2: 0.5732\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6636 - acc: 0.5906 - precision_2: 0.5904 - recall_2: 0.5958\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6617 - acc: 0.5837 - precision_2: 0.5859 - recall_2: 0.5749 0s - loss: 0.6619 - acc: 0.5831 - precision_2: 0.5855 - recall_2: 0.\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6573 - acc: 0.5857 - precision_2: 0.5891 - recall_2: 0.5698\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6957 - acc: 0.5177 - precision_3: 0.5162 - recall_3: 0.4675  - ETA: 2s - loss: 0.7015 - acc: 0.5197 - precision_3: 0.5202 - recall_3: 0.58 - E - ETA: 0s - loss: 0.6966 - acc: 0.5161 - precision_3: 0.511\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6909 - acc: 0.5296 - precision_3: 0.5258 - recall_3: 0.5437 2s - loss: 0.6914 - acc: 0.5272 - precision_3: 0.5163 - recall_3: 0. - ETA: \n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6899 - acc: 0.5337 - precision_3: 0.5340 - recall_3: 0.4827\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6898 - acc: 0.5338 - precision_3: 0.5287 - recall_3: 0.5685\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6891 - acc: 0.5417 - precision_3: 0.5410 - recall_3: 0.5124 0s - loss: 0.6889 - acc: 0.5407 - precision_3: 0.5\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6870 - acc: 0.5455 - precision_3: 0.5414 - recall_3: 0.5572\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6866 - acc: 0.5454 - precision_3: 0.5439 - recall_3: 0.5266 3s - loss: 0.6898 - acc: 0.5391 -  - ETA: 0s - loss: 0.6874 - acc: 0.5445 - precision_3: 0\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6860 - acc: 0.5437 - precision_3: 0.5417 - recall_3: 0.5298\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6846 - acc: 0.5485 - precision_3: 0.5475 - recall_3: 0.5268\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6833 - acc: 0.5529 - precision_3: 0.5551 - recall_3: 0.5048\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6835 - acc: 0.5563 - precision_3: 0.5558 - recall_3: 0.5337\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.6831 - acc: 0.5580 - precision_3: 0.5577 - recall_3: 0.53 - 4s 17ms/step - loss: 0.6831 - acc: 0.5580 - precision_3: 0.5577 - recall_3: 0.5337\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6806 - acc: 0.5545 - precision_3: 0.5548 - recall_3: 0.5232 1s - loss: 0.6806 - acc: 0.5554 - precision_3: 0.5585 - recall - ETA: 1s - loss: 0.6802 - acc: 0.5556 - pr\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6803 - acc: 0.5609 - precision_3: 0.5572 - recall_3: 0.5665\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6816 - acc: 0.5580 - precision_3: 0.5594 - recall_3: 0.5202\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6808 - acc: 0.5553 - precision_3: 0.5566 - recall_3: 0.5165\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6804 - acc: 0.5637 - precision_3: 0.5616 - recall_3: 0.5560 \n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6800 - acc: 0.5624 - precision_3: 0.5645 - recall_3: 0.5219\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6784 - acc: 0.5608 - precision_3: 0.5591 - recall_3: 0.5496\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6773 - acc: 0.5674 - precision_3: 0.5676 - recall_3: 0.5435\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6771 - acc: 0.5693 - precision_3: 0.5717 - recall_3: 0.5312\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6770 - acc: 0.5600 - precision_3: 0.5596 - recall_3: 0.5376\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6754 - acc: 0.5702 - precision_3: 0.5736 - recall_3: 0.5261 0s - loss: 0.6731 - acc: 0.5712 - prec\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6750 - acc: 0.5676 - precision_3: 0.5675 - recall_3: 0.5459\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6731 - acc: 0.5712 - precision_3: 0.5735 - recall_3: 0.5347\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6739 - acc: 0.5641 - precision_3: 0.5700 - recall_3: 0.4999 0s - loss: 0.6750 - acc: 0.5612 - precision_3: 0.5635 - recall\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6713 - acc: 0.5717 - precision_3: 0.5722 - recall_3: 0.5469\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6699 - acc: 0.5741 - precision_3: 0.5786 - recall_3: 0.5259\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6687 - acc: 0.5820 - precision_3: 0.5835 - recall_3: 0.5545\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6665 - acc: 0.5822 - precision_3: 0.5870 - recall_3: 0.5371\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6645 - acc: 0.5824 - precision_3: 0.5851 - recall_3: 0.5481 2s - loss: 0.6674 - acc: 0.5745 - precision_3: 0.5779 - recall_3:  - ETA: 1s - loss: 0.6677 - acc: 0.5717 - precision_3: 0.5779 - reca - ETA: 1s - loss: 0\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6615 - acc: 0.5908 - precision_3: 0.5976 - recall_3: 0.5401\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6628 - acc: 0.5864 - precision_3: 0.5893 - recall_3: 0.5528\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6615 - acc: 0.5853 - precision_3: 0.5909 - recall_3: 0.5376\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6568 - acc: 0.5910 - precision_3: 0.5964 - recall_3: 0.5474\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6552 - acc: 0.5970 - precision_3: 0.5981 - recall_3: 0.5761 1s - los\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6510 - acc: 0.6027 - precision_3: 0.6064 - recall_3: 0.5712 1s - loss: 0.6501 - acc: 0.6013 - prec\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6496 - acc: 0.6004 - precision_3: 0.6031 - recall_3: 0.5727\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6450 - acc: 0.6025 - precision_3: 0.6121 - recall_3: 0.5457\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6431 - acc: 0.6056 - precision_3: 0.6078 - recall_3: 0.5817\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6397 - acc: 0.6117 - precision_3: 0.6145 - recall_3: 0.5866\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6381 - acc: 0.6122 - precision_3: 0.6165 - recall_3: 0.5807\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6360 - acc: 0.6190 - precision_3: 0.6210 - recall_3: 0.5986 0s - loss: 0.6339 - acc: 0.6213 - precision_3:\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6344 - acc: 0.6191 - precision_3: 0.6245 - recall_3: 0.5856\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6259 - acc: 0.6204 - precision_3: 0.6256 - recall_3: 0.5878\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6251 - acc: 0.6289 - precision_3: 0.6324 - recall_3: 0.6045\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6200 - acc: 0.6310 - precision_3: 0.6362 - recall_3: 0.6011\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6151 - acc: 0.6362 - precision_3: 0.6363 - recall_3: 0.6253\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6130 - acc: 0.6381 - precision_3: 0.6424 - recall_3: 0.6131\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6086 - acc: 0.6364 - precision_3: 0.6420 - recall_3: 0.6065\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7294 - acc: 0.5345 - precision_3: 0.5576 - recall_3: 0.5726\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6939 - acc: 0.5182 - precision_4: 0.5183 - recall_4: 0.5702\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6925 - acc: 0.5216 - precision_4: 0.5204 - recall_4: 0.6010\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6923 - acc: 0.5215 - precision_4: 0.5205 - recall_4: 0.5945\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6918 - acc: 0.5172 - precision_4: 0.5157 - recall_4: 0.6282 3s - - ETA: 1s - l\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6918 - acc: 0.5248 - precision_4: 0.5234 - recall_4: 0.5971\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6916 - acc: 0.5272 - precision_4: 0.5258 - recall_4: 0.5940 1s - loss: 0.6914 - acc: 0.5290 \n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6917 - acc: 0.5210 - precision_4: 0.5203 - recall_4: 0.5872\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6908 - acc: 0.5267 - precision_4: 0.5232 - recall_4: 0.6447 0s - loss: 0.6907 - acc: 0.5257 - precision_4: 0.5216 - \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6909 - acc: 0.5348 - precision_4: 0.5328 - recall_4: 0.5950 2s\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6911 - acc: 0.5333 - precision_4: 0.5294 - recall_4: 0.6330\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6913 - acc: 0.5270 - precision_4: 0.5249 - recall_4: 0.6081 3s - loss: 0.6924 - \n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6903 - acc: 0.5279 - precision_4: 0.5252 - recall_4: 0.6224\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6896 - acc: 0.5335 - precision_4: 0.5312 - recall_4: 0.6022 0s - loss: 0.6895 - acc: 0.5334 - precision_4: 0.5306 - recall\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6901 - acc: 0.5366 - precision_4: 0.5322 - recall_4: 0.6355\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6896 - acc: 0.5377 - precision_4: 0.5344 - recall_4: 0.6134\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6894 - acc: 0.5328 - precision_4: 0.5303 - recall_4: 0.6068 0s - loss: 0.6893 - acc: 0.5310 - precision_4: 0.5270 - \n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6889 - acc: 0.5306 - precision_4: 0.5262 - recall_4: 0.6520\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6888 - acc: 0.5314 - precision_4: 0.5275 - recall_4: 0.6369\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6888 - acc: 0.5299 - precision_4: 0.5272 - recall_4: 0.6168\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6880 - acc: 0.5318 - precision_4: 0.5274 - recall_4: 0.6495 1s - loss: 0.6866 - \n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6883 - acc: 0.5405 - precision_4: 0.5375 - recall_4: 0.6066\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6880 - acc: 0.5400 - precision_4: 0.5364 - recall_4: 0.6168\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6869 - acc: 0.5372 - precision_4: 0.5342 - recall_4: 0.6107\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6872 - acc: 0.5385 - precision_4: 0.5340 - recall_4: 0.6342 1s -\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6861 - acc: 0.5416 - precision_4: 0.5381 - recall_4: 0.6129  - ETA\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6850 - acc: 0.5412 - precision_4: 0.5356 - recall_4: 0.6476 1s - loss: 0.6853 - acc: 0.5386 \n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6844 - acc: 0.5443 - precision_4: 0.5396 - recall_4: 0.6284 1s - loss: 0.6830 - acc: 0.545\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6856 - acc: 0.5418 - precision_4: 0.5375 - recall_4: 0.6253 \n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6834 - acc: 0.5491 - precision_4: 0.5421 - recall_4: 0.6558 2s - loss: 0.6854 - acc: 0 - ETA: 1s - loss: 0.6838 - acc: 0\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6836 - acc: 0.5430 - precision_4: 0.5381 - recall_4: 0.6330\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6824 - acc: 0.5495 - precision_4: 0.5446 - recall_4: 0.6258 0s - loss: 0.6824 - acc: 0.5514 - precisio\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6809 - acc: 0.5495 - precision_4: 0.5446 - recall_4: 0.6258\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6802 - acc: 0.5479 - precision_4: 0.5442 - recall_4: 0.6122\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6785 - acc: 0.5477 - precision_4: 0.5408 - recall_4: 0.6558\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6771 - acc: 0.5587 - precision_4: 0.5519 - recall_4: 0.6437 1s - loss: 0.6760 - acc: 0.5615 - precision_4: 0.5501 - re - ETA: 0s - loss: 0.6767 - acc: 0.5594 - precis\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6777 - acc: 0.5490 - precision_4: 0.5427 - recall_4: 0.6459 1s - loss: 0.6756 - acc: 0.5\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6739 - acc: 0.5612 - precision_4: 0.5556 - recall_4: 0.6294 1s\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6733 - acc: 0.5581 - precision_4: 0.5509 - recall_4: 0.6483\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6714 - acc: 0.5608 - precision_4: 0.5546 - recall_4: 0.6357\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6706 - acc: 0.5579 - precision_4: 0.5537 - recall_4: 0.6151\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6682 - acc: 0.5630 - precision_4: 0.5590 - recall_4: 0.6131\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6656 - acc: 0.5713 - precision_4: 0.5623 - recall_4: 0.6592\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6643 - acc: 0.5673 - precision_4: 0.5626 - recall_4: 0.6202\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6626 - acc: 0.5693 - precision_4: 0.5636 - recall_4: 0.6299\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6642 - acc: 0.5631 - precision_4: 0.5545 - recall_4: 0.6604\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6587 - acc: 0.5701 - precision_4: 0.5660 - recall_4: 0.6153 1s - los\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6588 - acc: 0.5696 - precision_4: 0.5630 - recall_4: 0.6369\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6565 - acc: 0.5759 - precision_4: 0.5713 - recall_4: 0.6221\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6555 - acc: 0.5769 - precision_4: 0.5704 - recall_4: 0.6369\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 4s 18ms/step - loss: 0.6515 - acc: 0.5751 - precision_4: 0.5743 - recall_4: 0.5930 1s - loss: 0.6536 - acc: 0.5715 - pr\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6921 - acc: 0.5444 - precision_4: 0.5252 - recall_4: 0.5682\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6945 - acc: 0.5119 - precision_5: 0.5107 - recall_5: 0.6101\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6905 - acc: 0.5293 - precision_5: 0.5304 - recall_5: 0.5260\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6899 - acc: 0.5345 - precision_5: 0.5333 - recall_5: 0.5659\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6892 - acc: 0.5406 - precision_5: 0.5437 - recall_5: 0.5153\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6892 - acc: 0.5367 - precision_5: 0.5348 - recall_5: 0.5768\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6885 - acc: 0.5489 - precision_5: 0.5478 - recall_5: 0.5693\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6869 - acc: 0.5468 - precision_5: 0.5443 - recall_5: 0.5858\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6867 - acc: 0.5484 - precision_5: 0.5468 - recall_5: 0.5749\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6867 - acc: 0.5457 - precision_5: 0.5440 - recall_5: 0.5754\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6862 - acc: 0.5488 - precision_5: 0.5478 - recall_5: 0.5683\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 3s 14ms/step - loss: 0.6846 - acc: 0.5535 - precision_5: 0.5497 - recall_5: 0.6004\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6837 - acc: 0.5590 - precision_5: 0.5560 - recall_5: 0.5933 0s - loss: 0.6827 - acc: 0.5628 - precis\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 3s 14ms/step - loss: 0.6829 - acc: 0.5553 - precision_5: 0.5518 - recall_5: 0.5984\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6811 - acc: 0.5601 - precision_5: 0.5572 - recall_5: 0.5936\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6815 - acc: 0.5596 - precision_5: 0.5557 - recall_5: 0.6028\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6799 - acc: 0.5651 - precision_5: 0.5637 - recall_5: 0.5826\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6805 - acc: 0.5651 - precision_5: 0.5621 - recall_5: 0.5963 1s - loss: 0.6802 - acc: 0.5625 - \n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6783 - acc: 0.5630 - precision_5: 0.5620 - recall_5: 0.5780- ETA: 0s - loss: 0.6775 - acc: 0.5634 - precision_5: 0.5613 - recall\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6794 - acc: 0.5589 - precision_5: 0.5559 - recall_5: 0.5936\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6775 - acc: 0.5642 - precision_5: 0.5640 - recall_5: 0.5732\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6768 - acc: 0.5693 - precision_5: 0.5688 - recall_5: 0.5797\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6764 - acc: 0.5684 - precision_5: 0.5650 - recall_5: 0.6011\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6769 - acc: 0.5654 - precision_5: 0.5627 - recall_5: 0.5941\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6748 - acc: 0.5718 - precision_5: 0.5693 - recall_5: 0.5958\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6748 - acc: 0.5691 - precision_5: 0.5691 - recall_5: 0.5758 1s - loss: 0.6745 - acc: 0.5661 - precision_5: 0.5652 - reca - ETA: 0s - loss: 0.6744 - acc: 0.5671 - precision_\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6739 - acc: 0.5684 - precision_5: 0.5654 - recall_5: 0.5982 0s - loss: 0.6742 - acc: 0.5679 - precision_5: 0.5637 \n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6719 - acc: 0.5712 - precision_5: 0.5700 - recall_5: 0.5860\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6690 - acc: 0.5831 - precision_5: 0.5798 - recall_5: 0.6096\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6678 - acc: 0.5792 - precision_5: 0.5756 - recall_5: 0.6091 3s - loss: 0.6674 - acc: - ETA: 2s - los - ETA: 0s - loss: 0.6679 - acc: 0.5787 - precision_5: 0.5774 - re - ETA: 0s - loss: 0.6677 - acc: 0.5791 - precision_5: 0.5753 - recall_5: 0.60\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6663 - acc: 0.5821 - precision_5: 0.5829 - recall_5: 0.5829\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6662 - acc: 0.5877 - precision_5: 0.5858 - recall_5: 0.6043\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6623 - acc: 0.5870 - precision_5: 0.5840 - recall_5: 0.6101 1s - loss: 0.6602 - acc: 0\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6601 - acc: 0.5944 - precision_5: 0.5936 - recall_5: 0.6035\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6582 - acc: 0.5938 - precision_5: 0.5911 - recall_5: 0.6138\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6567 - acc: 0.5962 - precision_5: 0.5948 - recall_5: 0.6084\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6543 - acc: 0.6005 - precision_5: 0.5989 - recall_5: 0.6130\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6505 - acc: 0.6048 - precision_5: 0.6029 - recall_5: 0.6181\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6462 - acc: 0.6099 - precision_5: 0.6092 - recall_5: 0.6172\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6454 - acc: 0.6077 - precision_5: 0.6043 - recall_5: 0.6283 3s - loss: 0.6466 - acc: 0.6070 - precisio - ETA: 0s - loss: 0.6459 - acc: 0.6061 - precision_5: 0.6035 - recall_5:  - ETA: 0s - loss: 0.6463 - acc: 0.6052 - precision_5: 0.6015 - recall_5\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6395 - acc: 0.6146 - precision_5: 0.6132 - recall_5: 0.6247\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6343 - acc: 0.6211 - precision_5: 0.6184 - recall_5: 0.6359\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6339 - acc: 0.6234 - precision_5: 0.6232 - recall_5: 0.6276\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6229 - acc: 0.6336 - precision_5: 0.6299 - recall_5: 0.6512\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6252 - acc: 0.6303 - precision_5: 0.6273 - recall_5: 0.6456 1s - loss: 0.622 - ETA: 0s - loss: 0.6252 - acc: 0.6303 - precision_5: 0.6265 - re\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6218 - acc: 0.6296 - precision_5: 0.6273 - recall_5: 0.6422\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6152 - acc: 0.6426 - precision_5: 0.6400 - recall_5: 0.6551 0s - loss: 0.6149 - acc: 0.6432 - precision_5: 0.6411 - recall_5: \n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6115 - acc: 0.6378 - precision_5: 0.6347 - recall_5: 0.6522 3s - loss: 0 - ETA\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6077 - acc: 0.6458 - precision_5: 0.6429 - recall_5: 0.6590 0s - loss: 0.6079 - acc: 0.6442 - precision_5: 0.643\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6007 - acc: 0.6513 - precision_5: 0.6498 - recall_5: 0.6590 2s - loss: 0.5961 - acc: 0.6580 - precision_5: 0.6556 -  - ETA: 2s - loss: 0.5955 - acc: 0.6576 - precision_5: 0.6601 - recall - ETA:  - ETA: 0s - loss: 0.6004 - acc: 0.6525 - precision_5: 0.6502 - recall_5: 0.\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.5999 - acc: 0.6459 - precision_5: 0.6446 - recall_5: 0.6534\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7155 - acc: 0.5761 - precision_5: 0.5838 - recall_5: 0.4811\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6947 - acc: 0.5093 - precision_6: 0.5039 - recall_6: 0.5053\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6921 - acc: 0.5220 - precision_6: 0.5190 - recall_6: 0.4598\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6916 - acc: 0.5205 - precision_6: 0.5165 - recall_6: 0.4785\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6908 - acc: 0.5307 - precision_6: 0.5272 - recall_6: 0.4967 0s - loss: 0.6908 - acc: 0.5302 - precision_6: 0.5273 - recall\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6901 - acc: 0.5318 - precision_6: 0.5263 - recall_6: 0.5336 2s - loss: 0.6910 - acc: 0.5225 -  - ETA: 1s - l\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6900 - acc: 0.5276 - precision_6: 0.5249 - recall_6: 0.4740\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6895 - acc: 0.5304 - precision_6: 0.5303 - recall_6: 0.4433\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6890 - acc: 0.5306 - precision_6: 0.5274 - recall_6: 0.4908\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6892 - acc: 0.5335 - precision_6: 0.5310 - recall_6: 0.4868 1s - loss: 0.6895 - acc: 0.5327 \n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6891 - acc: 0.5342 - precision_6: 0.5322 - recall_6: 0.4819 4s - loss:\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6881 - acc: 0.5353 - precision_6: 0.5352 - recall_6: 0.4605 3s - ETA: 1s - loss:\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6877 - acc: 0.5370 - precision_6: 0.5363 - recall_6: 0.4728\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6859 - acc: 0.5432 - precision_6: 0.5390 - recall_6: 0.5287\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6870 - acc: 0.5419 - precision_6: 0.5408 - recall_6: 0.4888\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6855 - acc: 0.5443 - precision_6: 0.5456 - recall_6: 0.4716 0s - loss: 0.6861 - acc: 0.5438 - pr\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6852 - acc: 0.5452 - precision_6: 0.5427 - recall_6: 0.5110\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6846 - acc: 0.5443 - precision_6: 0.5461 - recall_6: 0.4662\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6850 - acc: 0.5448 - precision_6: 0.5457 - recall_6: 0.4762\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6836 - acc: 0.5482 - precision_6: 0.5489 - recall_6: 0.4866\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6823 - acc: 0.5536 - precision_6: 0.5562 - recall_6: 0.4826 2s\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6828 - acc: 0.5537 - precision_6: 0.5542 - recall_6: 0.4991\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6829 - acc: 0.5519 - precision_6: 0.5532 - recall_6: 0.4890 0s - loss: 0.6832 - acc: 0.5524 - precision_6: 0.552\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6802 - acc: 0.5526 - precision_6: 0.5534 - recall_6: 0.4945 0s - loss: 0.6803 - acc: 0.5523 - precision_6: 0.5543 - recall_6: 0.\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6799 - acc: 0.5567 - precision_6: 0.5611 - recall_6: 0.4767\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6793 - acc: 0.5517 - precision_6: 0.5526 - recall_6: 0.4927 1s - loss: 0.6\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6797 - acc: 0.5569 - precision_6: 0.5598 - recall_6: 0.4873 0s - loss: 0.6794 - acc: 0.5566 - precision_6: 0.5609 - recall\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6766 - acc: 0.5621 - precision_6: 0.5629 - recall_6: 0.5129\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6769 - acc: 0.5632 - precision_6: 0.5673 - recall_6: 0.4930\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6747 - acc: 0.5668 - precision_6: 0.5725 - recall_6: 0.4905 1s - loss: 0.6732 \n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6745 - acc: 0.5718 - precision_6: 0.5748 - recall_6: 0.5161\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6711 - acc: 0.5711 - precision_6: 0.5772 - recall_6: 0.4967\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6721 - acc: 0.5679 - precision_6: 0.5704 - recall_6: 0.5122\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6680 - acc: 0.5743 - precision_6: 0.5770 - recall_6: 0.5220 0s - loss: 0.6665 - acc: 0.5781 - precision_\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6679 - acc: 0.5741 - precision_6: 0.5725 - recall_6: 0.5491\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6666 - acc: 0.5816 - precision_6: 0.5858 - recall_6: 0.5262\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6647 - acc: 0.5780 - precision_6: 0.5802 - recall_6: 0.5314 0s - loss: 0.6648 - acc: 0.5779 - precision_6: 0.5785 - re\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6615 - acc: 0.5814 - precision_6: 0.5848 - recall_6: 0.5302 0s - loss: 0.6611 - acc: 0.5836 - precision_6: 0.5883 \n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6625 - acc: 0.5795 - precision_6: 0.5794 - recall_6: 0.5466\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6587 - acc: 0.5858 - precision_6: 0.5850 - recall_6: 0.5597\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6554 - acc: 0.5912 - precision_6: 0.5933 - recall_6: 0.5516 0s - loss: 0.6545 - acc: 0.5910 - precisio\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6556 - acc: 0.5906 - precision_6: 0.5925 - recall_6: 0.5516 1s - loss: 0.6519 - acc: 0.5956 - prec\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6522 - acc: 0.5980 - precision_6: 0.5985 - recall_6: 0.5690\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6492 - acc: 0.5976 - precision_6: 0.5972 - recall_6: 0.5732 0s - loss: 0.6492 - acc: 0.5972 - precision_6: 0.5969 - recall_6: 0.\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6439 - acc: 0.6032 - precision_6: 0.6022 - recall_6: 0.5828\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6423 - acc: 0.6066 - precision_6: 0.6064 - recall_6: 0.5833\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6372 - acc: 0.6107 - precision_6: 0.6110 - recall_6: 0.5860\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6344 - acc: 0.6170 - precision_6: 0.6158 - recall_6: 0.6003\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6323 - acc: 0.6242 - precision_6: 0.6249 - recall_6: 0.6008 0s - loss: 0.6335 - acc: 0.6237 - precision_\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6342 - acc: 0.6171 - precision_6: 0.6140 - recall_6: 0.6087\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6238 - acc: 0.6286 - precision_6: 0.6277 - recall_6: 0.6121\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7320 - acc: 0.5461 - precision_6: 0.5919 - recall_6: 0.5540\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6941 - acc: 0.5172 - precision_7: 0.5147 - recall_7: 0.5604\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6920 - acc: 0.5167 - precision_7: 0.5149 - recall_7: 0.5345\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6918 - acc: 0.5180 - precision_7: 0.5148 - recall_7: 0.5851\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6914 - acc: 0.5253 - precision_7: 0.5210 - recall_7: 0.5987 0s - loss: 0.6915 - acc: 0.5239 - precision_7: 0.5196 \n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6906 - acc: 0.5303 - precision_7: 0.5268 - recall_7: 0.5738\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6910 - acc: 0.5264 - precision_7: 0.5237 - recall_7: 0.5592\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6901 - acc: 0.5345 - precision_7: 0.5296 - recall_7: 0.5960 0s - loss: 0.6905 - acc: 0.5327 - precision_7: 0.5277 - re\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6899 - acc: 0.5342 - precision_7: 0.5299 - recall_7: 0.5860\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6898 - acc: 0.5314 - precision_7: 0.5264 - recall_7: 0.6034\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6896 - acc: 0.5349 - precision_7: 0.5293 - recall_7: 0.6109\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6886 - acc: 0.5347 - precision_7: 0.5290 - recall_7: 0.6126\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6885 - acc: 0.5371 - precision_7: 0.5324 - recall_7: 0.5924 1s - loss: 0.6883 - acc: 0.5 - ETA: 0s - loss: 0.6885 - acc: 0.5366 - precision_7: 0.5314 - re\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6879 - acc: 0.5341 - precision_7: 0.5279 - recall_7: 0.6241\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6879 - acc: 0.5343 - precision_7: 0.5286 - recall_7: 0.6129\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6868 - acc: 0.5397 - precision_7: 0.5334 - recall_7: 0.6153\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6875 - acc: 0.5369 - precision_7: 0.5302 - recall_7: 0.6283\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6871 - acc: 0.5374 - precision_7: 0.5306 - recall_7: 0.6285\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 3s 14ms/step - loss: 0.6864 - acc: 0.5418 - precision_7: 0.5345 - recall_7: 0.6290\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6856 - acc: 0.5436 - precision_7: 0.5360 - recall_7: 0.6324\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6863 - acc: 0.5360 - precision_7: 0.5286 - recall_7: 0.6454\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 4s 14ms/step - loss: 0.6848 - acc: 0.5396 - precision_7: 0.5330 - recall_7: 0.6202\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6845 - acc: 0.5425 - precision_7: 0.5363 - recall_7: 0.6112\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6846 - acc: 0.5403 - precision_7: 0.5340 - recall_7: 0.6161\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6844 - acc: 0.5411 - precision_7: 0.5331 - recall_7: 0.6449\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6836 - acc: 0.5374 - precision_7: 0.5324 - recall_7: 0.5960 1s - loss: 0.6828 - acc: 0.5\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6814 - acc: 0.5526 - precision_7: 0.5449 - recall_7: 0.6256\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6810 - acc: 0.5545 - precision_7: 0.5460 - recall_7: 0.6349\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6797 - acc: 0.5519 - precision_7: 0.5440 - recall_7: 0.6273\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6808 - acc: 0.5467 - precision_7: 0.5406 - recall_7: 0.6073 1s - loss: 0.6811 - acc: 0\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 3s 14ms/step - loss: 0.6780 - acc: 0.5545 - precision_7: 0.5486 - recall_7: 0.6034\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6776 - acc: 0.5550 - precision_7: 0.5478 - recall_7: 0.6187 0s - loss: 0.6767 - acc: 0.5580 - precision_7: 0.5505 - re\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6766 - acc: 0.5498 - precision_7: 0.5444 - recall_7: 0.5965\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6759 - acc: 0.5536 - precision_7: 0.5488 - recall_7: 0.5904\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6739 - acc: 0.5534 - precision_7: 0.5480 - recall_7: 0.5982\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6717 - acc: 0.5598 - precision_7: 0.5525 - recall_7: 0.6178 4s - loss: 0.6569 - acc: 0.5667 - precision_7: 0.5509 -  - ETA: 3s - loss: 0.6606 - \n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6704 - acc: 0.5592 - precision_7: 0.5531 - recall_7: 0.6051\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6686 - acc: 0.5648 - precision_7: 0.5556 - recall_7: 0.6363\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6686 - acc: 0.5657 - precision_7: 0.5587 - recall_7: 0.6153 1s - loss: 0.6694 - acc: 0.5638 - precision_7: 0.5584 -  - ETA: 0s - loss: 0.6686 - acc: 0.5673 - precision_7: 0.561\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6639 - acc: 0.5656 - precision_7: 0.5618 - recall_7: 0.5873 0s - loss: 0.6635 - acc: 0.5659 - precision_7: 0.5631 - recall_7: \n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6652 - acc: 0.5632 - precision_7: 0.5613 - recall_7: 0.5685\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6629 - acc: 0.5692 - precision_7: 0.5663 - recall_7: 0.5819 1s - loss: 0.659\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6596 - acc: 0.5738 - precision_7: 0.5657 - recall_7: 0.6261\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6576 - acc: 0.5674 - precision_7: 0.5641 - recall_7: 0.5846\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6582 - acc: 0.5735 - precision_7: 0.5704 - recall_7: 0.5870 1s - loss: 0.6558 - acc: 0.5\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6565 - acc: 0.5670 - precision_7: 0.5590 - recall_7: 0.6241\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6530 - acc: 0.5805 - precision_7: 0.5686 - recall_7: 0.6588 0s - loss: 0.6530 - acc: 0.5805 - precision_7: 0.5686 - recall_7: 0.65\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6514 - acc: 0.5827 - precision_7: 0.5842 - recall_7: 0.5668\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6503 - acc: 0.5822 - precision_7: 0.5755 - recall_7: 0.6185 0s - loss: 0.6495 - acc: 0.5862 - prec\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6466 - acc: 0.5824 - precision_7: 0.5793 - recall_7: 0.5943 3s - loss: 0.645 - ETA: 1s - loss: - ETA: 0s - loss: 0.6472 - acc: 0.5816 - precision_7: 0.5786 - recall_7: 0.59\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6474 - acc: 0.5813 - precision_7: 0.5746 - recall_7: 0.6183\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7205 - acc: 0.5252 - precision_7: 0.5310 - recall_7: 0.6073\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 4s 16ms/step - loss: 0.6934 - acc: 0.5217 - precision_8: 0.5222 - recall_8: 0.5545 2s - loss: 0.6960 - acc: 0.5173  - ETA: 1s - loss: 0.6943 - acc: 0.520\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6914 - acc: 0.5276 - precision_8: 0.5284 - recall_8: 0.5481 0s - loss: 0.6914 - acc: 0.5327 - prec\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 4s 15ms/step - loss: 0.6909 - acc: 0.5257 - precision_8: 0.5260 - recall_8: 0.5574\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6904 - acc: 0.5290 - precision_8: 0.5300 - recall_8: 0.5445\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6899 - acc: 0.5325 - precision_8: 0.5304 - recall_8: 0.5986\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6893 - acc: 0.5324 - precision_8: 0.5328 - recall_8: 0.5557\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6884 - acc: 0.5375 - precision_8: 0.5389 - recall_8: 0.5443\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6874 - acc: 0.5459 - precision_8: 0.5437 - recall_8: 0.5928 3s - loss: 0.6870  - ETA: 1s\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.6874 - acc: 0.5420 - precision_8: 0.5412 - recall_8: 0.57 - 5s 20ms/step - loss: 0.6874 - acc: 0.5420 - precision_8: 0.5412 - recall_8: 0.5756\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6866 - acc: 0.5431 - precision_8: 0.5421 - recall_8: 0.5782 2s - loss: 0.6852 - acc: 0.5522 - precisio - ETA: 1s - loss: 0.6\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6847 - acc: 0.5520 - precision_8: 0.5535 - recall_8: 0.5557\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6849 - acc: 0.5470 - precision_8: 0.5485 - recall_8: 0.5515\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6845 - acc: 0.5448 - precision_8: 0.5462 - recall_8: 0.5506 0s - loss: 0.6844 - acc: 0.5458 - precision_8: 0.5484 - recall_8: 0.54\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6834 - acc: 0.5514 - precision_8: 0.5554 - recall_8: 0.5324\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6833 - acc: 0.5513 - precision_8: 0.5496 - recall_8: 0.5877 1s - loss: 0.6824 - acc: 0.5548 - precision_8: 0.5498 - recall - ETA: 1s - loss: 0.6826 - acc: 0.5537 - precision_8: 0.5 - ETA: 0s - loss: 0.6833 - acc: 0.5520 - precision_8: 0.5474 - re\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6808 - acc: 0.5590 - precision_8: 0.5594 - recall_8: 0.5719 3s - loss: 0 - ETA: 1s - loss: 0.6800 - \n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6810 - acc: 0.5618 - precision_8: 0.5616 - recall_8: 0.5789 1s - loss: 0.6811 - acc: 0.5641 \n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6825 - acc: 0.5538 - precision_8: 0.5550 - recall_8: 0.5603\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6812 - acc: 0.5522 - precision_8: 0.5514 - recall_8: 0.5787\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6800 - acc: 0.5543 - precision_8: 0.5543 - recall_8: 0.5722 0s - loss: 0.6800 - acc: 0.5583 - precis\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6798 - acc: 0.5566 - precision_8: 0.5572 - recall_8: 0.5685\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6782 - acc: 0.5594 - precision_8: 0.5593 - recall_8: 0.5768\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6780 - acc: 0.5616 - precision_8: 0.5646 - recall_8: 0.5532 2s - loss: 0.6747 - acc: 0.5668  - ETA: 1s - loss:\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6757 - acc: 0.5622 - precision_8: 0.5651 - recall_8: 0.5549\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6757 - acc: 0.5681 - precision_8: 0.5684 - recall_8: 0.5794 2s - loss: 0.6717 - acc: 0.5704 - precisio - ETA: 1s - loss:\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6745 - acc: 0.5639 - precision_8: 0.5646 - recall_8: 0.5731 0s - loss: 0.6747 - acc: 0.5628 - precis\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6734 - acc: 0.5677 - precision_8: 0.5699 - recall_8: 0.5659 0s - loss: 0.6736 - acc: 0.5666 - precision_8: 0.5694 - recall_8: \n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6724 - acc: 0.5710 - precision_8: 0.5749 - recall_8: 0.5578 1s - loss: 0.6729 - acc: 0.5\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6726 - acc: 0.5716 - precision_8: 0.5723 - recall_8: 0.5799\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6684 - acc: 0.5762 - precision_8: 0.5775 - recall_8: 0.5799\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6663 - acc: 0.5804 - precision_8: 0.5835 - recall_8: 0.5726 2s - loss: 0.6625 - acc: 0.5881 - precision_8: 0.5932 - recall_8: \n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6665 - acc: 0.5795 - precision_8: 0.5828 - recall_8: 0.5709\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6635 - acc: 0.5842 - precision_8: 0.5835 - recall_8: 0.5998 0s - loss: 0.6640 - acc: 0.5834 - precision_8: 0.5845 - recall\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6603 - acc: 0.5879 - precision_8: 0.5894 - recall_8: 0.5899\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6604 - acc: 0.5875 - precision_8: 0.5920 - recall_8: 0.5736 2s - - ETA: 0s - loss: 0.6607 - acc: 0.5855 - precision_\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6569 - acc: 0.5891 - precision_8: 0.5942 - recall_8: 0.5724 2s - loss: 0.6565 - acc: 0.5938  - ETA: 0s - loss: 0.6580 - acc: 0.5890 - precisio\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6550 - acc: 0.5958 - precision_8: 0.6010 - recall_8: 0.5794\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6495 - acc: 0.6015 - precision_8: 0.6041 - recall_8: 0.5981\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6468 - acc: 0.6012 - precision_8: 0.6016 - recall_8: 0.6081\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6457 - acc: 0.6052 - precision_8: 0.6099 - recall_8: 0.5923\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6408 - acc: 0.6082 - precision_8: 0.6083 - recall_8: 0.6163 1s - loss: 0.6406 - ac\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6397 - acc: 0.6074 - precision_8: 0.6115 - recall_8: 0.5971\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6333 - acc: 0.6206 - precision_8: 0.6194 - recall_8: 0.6335 0s - loss: 0.6339 - acc: 0.6209 - precision_8: 0.6217 - re\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6290 - acc: 0.6157 - precision_8: 0.6174 - recall_8: 0.6161\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6289 - acc: 0.6214 - precision_8: 0.6245 - recall_8: 0.6161 3s - loss: 0.6292 - acc: 0.6\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6227 - acc: 0.6193 - precision_8: 0.6227 - recall_8: 0.6129\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6196 - acc: 0.6221 - precision_8: 0.6234 - recall_8: 0.6243\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6137 - acc: 0.6329 - precision_8: 0.6311 - recall_8: 0.6469\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6080 - acc: 0.6344 - precision_8: 0.6375 - recall_8: 0.6299\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6041 - acc: 0.6410 - precision_8: 0.6419 - recall_8: 0.6442 4s - loss: 0.5818  - ETA: 3s - loss: 0.6038 - acc: 0.6380 -  -\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7308 - acc: 0.5526 - precision_8: 0.5388 - recall_8: 0.5045\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6949 - acc: 0.5072 - precision_9: 0.5087 - recall_9: 0.5835\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6925 - acc: 0.5140 - precision_9: 0.5139 - recall_9: 0.6160\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6922 - acc: 0.5186 - precision_9: 0.5181 - recall_9: 0.6114\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6906 - acc: 0.5276 - precision_9: 0.5264 - recall_9: 0.6027\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6910 - acc: 0.5256 - precision_9: 0.5247 - recall_9: 0.5990 0s - loss: 0.6910 - acc: 0.5256 - precision_9: 0.5247 - recall_9: 0.59\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 3s 12ms/step - loss: 0.6909 - acc: 0.5274 - precision_9: 0.5257 - recall_9: 0.6153\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 3s 13ms/step - loss: 0.6905 - acc: 0.5303 - precision_9: 0.5280 - recall_9: 0.6208 0s - loss: 0.6913 - acc: 0.523\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6899 - acc: 0.5282 - precision_9: 0.5262 - recall_9: 0.6194 1s - loss: 0.6899 - acc: 0\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6897 - acc: 0.5349 - precision_9: 0.5333 - recall_9: 0.6005\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6895 - acc: 0.5334 - precision_9: 0.5287 - recall_9: 0.6627\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6893 - acc: 0.5302 - precision_9: 0.5264 - recall_9: 0.6538\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6892 - acc: 0.5299 - precision_9: 0.5286 - recall_9: 0.6022\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6891 - acc: 0.5341 - precision_9: 0.5317 - recall_9: 0.6153\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6883 - acc: 0.5363 - precision_9: 0.5317 - recall_9: 0.6523\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6873 - acc: 0.5327 - precision_9: 0.5311 - recall_9: 0.6039 0s - loss: 0.6872 - acc: 0.5328 - precisio\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6872 - acc: 0.5347 - precision_9: 0.5315 - recall_9: 0.6283\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6879 - acc: 0.5285 - precision_9: 0.5263 - recall_9: 0.6215\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6856 - acc: 0.5351 - precision_9: 0.5310 - recall_9: 0.6446\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6863 - acc: 0.5416 - precision_9: 0.5378 - recall_9: 0.6286\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6863 - acc: 0.5403 - precision_9: 0.5359 - recall_9: 0.6404\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6848 - acc: 0.5427 - precision_9: 0.5373 - recall_9: 0.6530\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6841 - acc: 0.5430 - precision_9: 0.5391 - recall_9: 0.6281\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6829 - acc: 0.5494 - precision_9: 0.5435 - recall_9: 0.6487\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6825 - acc: 0.5487 - precision_9: 0.5421 - recall_9: 0.6588 1s - loss: 0.6817 - \n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6822 - acc: 0.5461 - precision_9: 0.5416 - recall_9: 0.6339\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6818 - acc: 0.5450 - precision_9: 0.5410 - recall_9: 0.6281\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6805 - acc: 0.5474 - precision_9: 0.5432 - recall_9: 0.6271\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6794 - acc: 0.5465 - precision_9: 0.5435 - recall_9: 0.6121\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6773 - acc: 0.5561 - precision_9: 0.5474 - recall_9: 0.6768 3s - ETA: 1s\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6785 - acc: 0.5474 - precision_9: 0.5415 - recall_9: 0.6511 2s - loss: 0.6774 - acc: 0.556 - ETA: 1s - loss: 0.6776 - acc: 0.5544  - ETA: 0s - loss: 0.6784 - acc: 0.5479 - precision_9: 0.5412 - reca\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6746 - acc: 0.5600 - precision_9: 0.5541 - recall_9: 0.6397\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6748 - acc: 0.5562 - precision_9: 0.5505 - recall_9: 0.6402 0s - loss: 0.6752 - acc: 0.5547 - precision_\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6729 - acc: 0.5553 - precision_9: 0.5512 - recall_9: 0.6213 0s - loss: 0.6715 - acc: 0.5582 - precision_9: 0.5527 \n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6724 - acc: 0.5578 - precision_9: 0.5504 - recall_9: 0.6584 3s - loss: 0 - ETA: 2s - loss: - ETA: 0s - loss: 0.6716 - acc: 0.5591 - precision_9: 0.5543 - \n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6694 - acc: 0.5582 - precision_9: 0.5546 - recall_9: 0.6157\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 4s 17ms/step - loss: 0.6694 - acc: 0.5578 - precision_9: 0.5524 - recall_9: 0.6356\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6675 - acc: 0.5592 - precision_9: 0.5523 - recall_9: 0.6506\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6660 - acc: 0.5645 - precision_9: 0.5584 - recall_9: 0.6402 0s - loss: 0.6656 - acc: 0.5658 - precision_9: 0.5598 - recall_9\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6632 - acc: 0.5649 - precision_9: 0.5580 - recall_9: 0.6472 0s - loss: 0.6628 - acc: 0.5657 - precision_9: 0.5576 - re\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6618 - acc: 0.5627 - precision_9: 0.5577 - recall_9: 0.6300 1s - loss: 0.6652 - acc: 0.5590 - precision_9: 0.5539 - recall_9:  - ETA: 1s - loss: 0.6659 - acc: 0.5577 - precisio - ETA: 0s - loss: 0.6640 - acc: 0.5586 - precision_9: 0.5\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6589 - acc: 0.5698 - precision_9: 0.5635 - recall_9: 0.6404\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6607 - acc: 0.5676 - precision_9: 0.5609 - recall_9: 0.6448\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6555 - acc: 0.5704 - precision_9: 0.5614 - recall_9: 0.6649 0s - loss: 0.6564 - acc: 0.5699 - precision_9: 0.5631 - re\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6540 - acc: 0.5745 - precision_9: 0.5758 - recall_9: 0.5843\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6519 - acc: 0.5810 - precision_9: 0.5722 - recall_9: 0.6600 3s - loss: 0.6597 - acc: 0.5855 - precision_ - ETA - ETA: 1s - loss: 0.6520 - acc: 0.5818 - \n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 18ms/step - loss: 0.6492 - acc: 0.5869 - precision_9: 0.5771 - recall_9: 0.6680\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6507 - acc: 0.5773 - precision_9: 0.5709 - recall_9: 0.6416 3s - loss: 0.6429 - acc: 0.5911 - precision_9: 0.5865 - recall_9 - ETA: 3s - loss: 0.6434 - acc: 0.5918 - precision_9: 0.5843 - recall_9:  - ETA: 3s - loss: 0.6415 - acc: 0.5934 - precision_9: 0\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6470 - acc: 0.5847 - precision_9: 0.5806 - recall_9: 0.6269\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6441 - acc: 0.5858 - precision_9: 0.5810 - recall_9: 0.6324\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6447 - acc: 0.5842 - precision_9: 0.5804 - recall_9: 0.6249 0s - loss: 0.6439 - acc: 0.5855 - precision_9: 0.5806 - reca\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7337 - acc: 0.5241 - precision_9: 0.4990 - recall_9: 0.5727\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= tf_idf (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNNLSTM = Sequential() \n",
    "\n",
    "    modelCNNLSTM.add(embedding_layer)\n",
    "    modelCNNLSTM.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "    modelCNNLSTM.add(MaxPooling1D(pool_size=4))\n",
    "    modelCNNLSTM.add(Dropout(0.25))\n",
    "    modelCNNLSTM.add(LSTM(128))                            \n",
    "    modelCNNLSTM.add(Flatten())\n",
    "    modelCNNLSTM.add(Dense(1, activation='sigmoid'))\n",
    "    modelCNNLSTM.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNNLSTM.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelCNNLSTM.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.541199\n",
      "test precision: 0.542128\n",
      "test recall: 0.554267\n",
      "test f1_score: 0.546263\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
