{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['tweets','duygu','preprocessing']\n",
    "#df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "\n",
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell=şahan gökbakaravea=ata demirervodafon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dini imanı para olan turkcell fizy ile ilgili ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@zeyrekadin yok \"hat değiştirmiş\" adama sahtek...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea gibi allah bin belanı versin yarin ilk iş...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oha lan turkcell 'den 14 gb internet geldi ay ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>turkcell salla kazan kampanyası 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>çok başarılı turkcell müsteri hizmetleri'nin ç...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>ben platinum paketten ciktim siz tabii ki 6gb ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>şuan o dört çeker diye diye övdüğünüz turkcell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>* ev kirasinin yarisini turkcell'e oduyorum te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     turkcell=şahan gökbakaravea=ata demirervodafon...     0\n",
       "1     dini imanı para olan turkcell fizy ile ilgili ...     0\n",
       "2     @zeyrekadin yok \"hat değiştirmiş\" adama sahtek...     1\n",
       "3     avea gibi allah bin belanı versin yarin ilk iş...     1\n",
       "4     oha lan turkcell 'den 14 gb internet geldi ay ...     1\n",
       "...                                                 ...   ...\n",
       "9121               turkcell salla kazan kampanyası 2017     1\n",
       "9122  çok başarılı turkcell müsteri hizmetleri'nin ç...     0\n",
       "9123  ben platinum paketten ciktim siz tabii ki 6gb ...     0\n",
       "9124  şuan o dört çeker diye diye övdüğünüz turkcell...     0\n",
       "9125  * ev kirasinin yarisini turkcell'e oduyorum te...     0\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf (X_train,y_train,X_test,y_test):\n",
    "    #Create a tokenizer, configured to only take into account the 20 most common words çok küçük olursa kelimeleri \n",
    "    #kaybederiz underfit yaparız\n",
    "    tokenizer = Tokenizer(num_words=1000) #en yaygın kaç kelimeyi dikkate alacağı. Belirtilecek en iyi kelime sayısı #1000 yapan da var\n",
    "    tokenizer.fit_on_texts(X_train) #keras tokenizer ile metni dictionary haline getiriyor.\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train) #kelimelerin dictionarydeki karşılığı \n",
    "    #[[2, 1, 3], [2, 1], [4, 1], [5, 6]] şekline getiriliyor. 2-machine 1- learning 3-Knowledge \n",
    "    word_index = tokenizer.word_index #dictionarydeki kelimelerin sayısal karşılığı 'unk': 1, 'ürün': 2,\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)): #len(sequences_X_train) ile kaç tane [[2,3,4],[2,6]] var bulunuyor burda 2\n",
    "        numberofwords=len(sequences_X_train[review_number]) #[2,3,4] içinde kaç tane şey var 3 burda\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords #tüm kelimelere bakıp en uzun olanı buluyor\n",
    "\n",
    "    vocabulary=[]\n",
    "    for key in word_index.keys():\n",
    "        vocabulary.append(key)\n",
    "\n",
    "    pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
    "                     ('tfid', TfidfTransformer())]).fit(X_train)\n",
    "\n",
    "    res = dict(zip(vocabulary, pipe['tfid'].idf_))\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length) #ikili boyutlu matrise çevirip her cümelnin uzunluğunu eşit yapıyor.\n",
    "    #En uzun cümle uzunluğuna tamamlanıyor.[[2 1 3] [0 2 1]] alt alta gelecek şekilde en uzun 6 ise 6x6 matris oluyor\n",
    "    y_train = np.asarray(y_train) #tek boyutlu bir matris oluyor [1 1 0 ... 0 1 0] gibi\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test) #train için yapılan gibi dictionary alınıyor\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length) #en uzun olana göre pad sequence yapılıyor\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    unique_words = len(word_index) #word_index ile unique olan kelimeler alınıyor 0 dan başladığı için bir arttırılıyor\n",
    "    total_words = unique_words + 1\n",
    "    \n",
    "    skipped_words = 0\n",
    "    embedding_dim = 1 #embedding dim vector size ile aynı \n",
    "    embedding_vector=0\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items(): #kelime ve kelimenin dictionarydeki karşılığı alınıyor\n",
    "        try:\n",
    "            embedding_vector = res[word] #kelimenin word2vec karşılığı vektör olarak\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector \n",
    "            \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "\n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6998 - acc: 0.5209 - precision: 0.5214 - recall: 0.5468\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6928 - acc: 0.5180 - precision: 0.5186 - recall: 0.5449 3s - loss: 0.6932 - acc: 0.5155 - pr\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6908 - acc: 0.5265 - precision: 0.5266 - recall: 0.5558\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6889 - acc: 0.5360 - precision: 0.5378 - recall: 0.5337\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6873 - acc: 0.5384 - precision: 0.5420 - recall: 0.5153\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6868 - acc: 0.5399 - precision: 0.5417 - recall: 0.5371\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6846 - acc: 0.5489 - precision: 0.5481 - recall: 0.5735\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6849 - acc: 0.5422 - precision: 0.5434 - recall: 0.5473\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6821 - acc: 0.5577 - precision: 0.5608 - recall: 0.5449\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6813 - acc: 0.5573 - precision: 0.5624 - recall: 0.5296\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6800 - acc: 0.5574 - precision: 0.5591 - recall: 0.5568\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6779 - acc: 0.5680 - precision: 0.5738 - recall: 0.5396\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6759 - acc: 0.5684 - precision: 0.5690 - recall: 0.57520s - loss: 0.6760 - acc: 0.5694 - precision: 0.5\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6723 - acc: 0.5756 - precision: 0.5812 - recall: 0.5505\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6719 - acc: 0.5743 - precision: 0.5792 - recall: 0.5539\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6663 - acc: 0.5844 - precision: 0.5914 - recall: 0.5553\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6651 - acc: 0.5865 - precision: 0.5948 - recall: 0.5515\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6617 - acc: 0.5854 - precision: 0.5902 - recall: 0.5677\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6554 - acc: 0.6016 - precision: 0.6093 - recall: 0.57350s - loss: 0.6550 - acc: 0.6015 - precision: 0.6087 - \n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6515 - acc: 0.6060 - precision: 0.6132 - recall: 0.5813\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6437 - acc: 0.6193 - precision: 0.6232 - recall: 0.6097\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.6390 - acc: 0.6199 - precision: 0.6301 - recall: 0.5867\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6317 - acc: 0.6262 - precision: 0.6322 - recall: 0.60921s - loss: 0.6292 - \n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.6228 - acc: 0.6311 - precision: 0.6367 - recall: 0.61601s - loss: 0.6204 - acc: 0.6332 - precis\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6154 - acc: 0.6347 - precision: 0.6379 - recall: 0.6289\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6042 - acc: 0.6442 - precision: 0.6486 - recall: 0.6345\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5912 - acc: 0.6603 - precision: 0.6637 - recall: 0.6544\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5859 - acc: 0.6671 - precision: 0.6766 - recall: 0.6444\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.5778 - acc: 0.6754 - precision: 0.6800 - recall: 0.6667\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.5680 - acc: 0.6808 - precision: 0.6832 - recall: 0.6779\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5500 - acc: 0.6878 - precision: 0.6902 - recall: 0.6852\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.5468 - acc: 0.6899 - precision: 0.7036 - recall: 0.6597\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5388 - acc: 0.6969 - precision: 0.7062 - recall: 0.6779\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.5264 - acc: 0.7094 - precision: 0.7136 - recall: 0.70274s - loss: 0.5215 -  - ETA: 2s\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.5083 - acc: 0.7165 - precision: 0.7179 - recall: 0.71652s - loss: 0.5063 - acc: 0.7177 -  - ETA: 0s - loss: 0.5057 - acc: 0.7198 - precision: 0\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.5062 - acc: 0.7193 - precision: 0.7206 - recall: 0.7194\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.4863 - acc: 0.7351 - precision: 0.7394 - recall: 0.7286\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.4748 - acc: 0.7354 - precision: 0.7362 - recall: 0.7364\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.4869 - acc: 0.7363 - precision: 0.7359 - recall: 0.7398\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.4563 - acc: 0.7486 - precision: 0.7469 - recall: 0.7544\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4431 - acc: 0.7604 - precision: 0.7626 - recall: 0.7585\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4642 - acc: 0.7497 - precision: 0.7495 - recall: 0.7524\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4397 - acc: 0.7648 - precision: 0.7670 - recall: 0.7629\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4210 - acc: 0.7724 - precision: 0.7718 - recall: 0.7757\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.4044 - acc: 0.7831 - precision: 0.7811 - recall: 0.7888\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.4033 - acc: 0.7831 - precision: 0.7878 - recall: 0.7769\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4019 - acc: 0.7844 - precision: 0.7889 - recall: 0.7784: 10s - loss: 0.3700 - acc: 0.8164 - precision: 0.8226 - recall: 0. - ETA: 10s - l - ETA: 7s - l\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.4182 - acc: 0.7829 - precision: 0.7859 - recall: 0.7796\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.4289 - acc: 0.7729 - precision: 0.7735 - recall: 0.77402s - l\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.3868 - acc: 0.7947 - precision: 0.8029 - recall: 0.7830\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 1.1075 - acc: 0.5148 - precision: 0.5000 - recall: 0.5824\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6968 - acc: 0.5161 - precision_1: 0.5143 - recall_1: 0.5442\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6914 - acc: 0.5250 - precision_1: 0.5235 - recall_1: 0.5347\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6908 - acc: 0.5299 - precision_1: 0.5292 - recall_1: 0.5249 0s - loss: 0.6910 - acc: 0.5296 - precision_1: 0.5297 \n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.6895 - acc: 0.5354 - precision_1: 0.5362 - recall_1: 0.5100\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6870 - acc: 0.5412 - precision_1: 0.5423 - recall_1: 0.5166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6857 - acc: 0.5385 - precision_1: 0.5416 - recall_1: 0.4898\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6844 - acc: 0.5486 - precision_1: 0.5499 - recall_1: 0.5259\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6834 - acc: 0.5473 - precision_1: 0.5513 - recall_1: 0.4983\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6820 - acc: 0.5591 - precision_1: 0.5586 - recall_1: 0.55440s - loss: 0.6819 - acc: 0.5582 - precision_1: 0.5582 - reca\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6817 - acc: 0.5586 - precision_1: 0.5636 - recall_1: 0.5115\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6802 - acc: 0.5600 - precision_1: 0.5610 - recall_1: 0.5427\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6771 - acc: 0.5676 - precision_1: 0.5751 - recall_1: 0.51121s - loss: 0.6757 \n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6767 - acc: 0.5678 - precision_1: 0.5709 - recall_1: 0.5386\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6757 - acc: 0.5704 - precision_1: 0.5729 - recall_1: 0.5464\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6717 - acc: 0.5746 - precision_1: 0.5837 - recall_1: 0.5137\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6708 - acc: 0.5779 - precision_1: 0.5856 - recall_1: 0.5266\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6674 - acc: 0.5814 - precision_1: 0.5910 - recall_1: 0.5229\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.6641 - acc: 0.5864 - precision_1: 0.5946 - recall_1: 0.5378\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6645 - acc: 0.5836 - precision_1: 0.5884 - recall_1: 0.5505\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6600 - acc: 0.5905 - precision_1: 0.6017 - recall_1: 0.53051s - loss: 0.6580 \n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6530 - acc: 0.6062 - precision_1: 0.6173 - recall_1: 0.5549\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6541 - acc: 0.6001 - precision_1: 0.6084 - recall_1: 0.5576\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6501 - acc: 0.6126 - precision_1: 0.6207 - recall_1: 0.5747\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6384 - acc: 0.6200 - precision_1: 0.6318 - recall_1: 0.5715\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6357 - acc: 0.6247 - precision_1: 0.6334 - recall_1: 0.5886\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6326 - acc: 0.6239 - precision_1: 0.6389 - recall_1: 0.5661\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6262 - acc: 0.6312 - precision_1: 0.6405 - recall_1: 0.5944 0s - loss: 0.6240 - acc: 0.6326 - precision_1:\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5853 - acc: 0.6709 - precision_1: 0.6861 - recall_1: 0.6274\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5792 - acc: 0.6705 - precision_1: 0.6775 - recall_1: 0.64840s - loss: 0.5775 - acc: 0.6737 - precision_1: 0.6\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5681 - acc: 0.6794 - precision_1: 0.6894 - recall_1: 0.6506\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5719 - acc: 0.6794 - precision_1: 0.6912 - recall_1: 0.6462\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5471 - acc: 0.6980 - precision_1: 0.7015 - recall_1: 0.68723s - loss: 0.5473 - acc: 0.6940 - precision_1: 0.6983 - reca\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.5445 - acc: 0.6967 - precision_1: 0.7047 - recall_1: 0.6750\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5256 - acc: 0.7137 - precision_1: 0.7157 - recall_1: 0.7072\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5176 - acc: 0.7119 - precision_1: 0.7122 - recall_1: 0.7094\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5098 - acc: 0.7140 - precision_1: 0.7175 - recall_1: 0.7040\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5240 - acc: 0.7114 - precision_1: 0.7139 - recall_1: 0.70380s - loss: 0.5243 - acc: 0.7120 - precision_1: 0.7140 - recall_1: 0.\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.5023 - acc: 0.7265 - precision_1: 0.7293 - recall_1: 0.7186\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4782 - acc: 0.7404 - precision_1: 0.7449 - recall_1: 0.7296 0s - loss: 0.4779 - acc: 0.7409 - precision_1: 0.7457 - re\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4663 - acc: 0.7460 - precision_1: 0.7411 - recall_1: 0.7545\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4634 - acc: 0.7483 - precision_1: 0.7488 - recall_1: 0.7457 4s - loss: 0.4\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.4650 - acc: 0.7478 - precision_1: 0.7477 - recall_1: 0.7465\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.4558 - acc: 0.7493 - precision_1: 0.7470 - recall_1: 0.7523\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.4543 - acc: 0.7533 - precision_1: 0.7568 - recall_1: 0.7450 1s - loss:\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.4390 - acc: 0.7639 - precision_1: 0.7635 - recall_1: 0.7633 2s - l - ETA: 0s - loss: 0.4351 - acc: 0.7657 - precision_\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4297 - acc: 0.7722 - precision_1: 0.7702 - recall_1: 0.7745\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0552 - acc: 0.5520 - precision_1: 0.5598 - recall_1: 0.5634\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6991 - acc: 0.5119 - precision_2: 0.5102 - recall_2: 0.5231\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6921 - acc: 0.5150 - precision_2: 0.5132 - recall_2: 0.5306\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6915 - acc: 0.5287 - precision_2: 0.5278 - recall_2: 0.5192\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6900 - acc: 0.5267 - precision_2: 0.5260 - recall_2: 0.51457s - loss: 0.6880 - acc: 0.5351 - pr\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6877 - acc: 0.5388 - precision_2: 0.5381 - recall_2: 0.5294\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6879 - acc: 0.5338 - precision_2: 0.5337 - recall_2: 0.5148\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6865 - acc: 0.5408 - precision_2: 0.5409 - recall_2: 0.5231\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6854 - acc: 0.5406 - precision_2: 0.5430 - recall_2: 0.4960\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6846 - acc: 0.5483 - precision_2: 0.5497 - recall_2: 0.5199\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6831 - acc: 0.5451 - precision_2: 0.5494 - recall_2: 0.4872\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6810 - acc: 0.5551 - precision_2: 0.5589 - recall_2: 0.51063s - loss: - ETA: 0s - loss: 0.6807 - acc: 0.5552 - precision_2: 0.5602 - \n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6801 - acc: 0.5531 - precision_2: 0.5540 - recall_2: 0.5324\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6783 - acc: 0.5570 - precision_2: 0.5582 - recall_2: 0.5350\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6766 - acc: 0.5628 - precision_2: 0.5626 - recall_2: 0.5531\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6759 - acc: 0.5622 - precision_2: 0.5638 - recall_2: 0.53820s - loss: 0.6758 - acc: 0.5615 - precision_2: 0.5\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6730 - acc: 0.5712 - precision_2: 0.5703 - recall_2: 0.56753s - loss: 0.6707 - acc: 0.5751 - precisio - ETA: 2s - l\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6677 - acc: 0.5814 - precision_2: 0.5829 - recall_2: 0.56397s - loss: 0 - ETA: 1s - loss: 0.6674 - acc:\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6663 - acc: 0.5814 - precision_2: 0.5834 - recall_2: 0.5612\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6621 - acc: 0.5865 - precision_2: 0.5923 - recall_2: 0.5477\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6586 - acc: 0.5894 - precision_2: 0.5980 - recall_2: 0.5387\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6509 - acc: 0.6005 - precision_2: 0.6048 - recall_2: 0.5736 - ETA: 0s - loss: 0.6504 - acc: 0.6023 - precision_2:\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.6475 - acc: 0.6054 - precision_2: 0.6163 - recall_2: 0.5524\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6409 - acc: 0.6173 - precision_2: 0.6182 - recall_2: 0.6078\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6363 - acc: 0.6222 - precision_2: 0.6275 - recall_2: 0.5961\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6288 - acc: 0.6247 - precision_2: 0.6330 - recall_2: 0.5885\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6219 - acc: 0.6323 - precision_2: 0.6422 - recall_2: 0.5929\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6092 - acc: 0.6521 - precision_2: 0.6569 - recall_2: 0.6330\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6059 - acc: 0.6436 - precision_2: 0.6488 - recall_2: 0.6220\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5965 - acc: 0.6611 - precision_2: 0.6655 - recall_2: 0.6442\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.5831 - acc: 0.6681 - precision_2: 0.6756 - recall_2: 0.6430\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.5741 - acc: 0.6767 - precision_2: 0.6798 - recall_2: 0.6647\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.5652 - acc: 0.6878 - precision_2: 0.6923 - recall_2: 0.6730\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.5540 - acc: 0.6939 - precision_2: 0.7003 - recall_2: 0.6750\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.5496 - acc: 0.6996 - precision_2: 0.7070 - recall_2: 0.67891s - loss: 0.549\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.5406 - acc: 0.6997 - precision_2: 0.7017 - recall_2: 0.6921\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.5189 - acc: 0.7144 - precision_2: 0.7128 - recall_2: 0.71532s - loss: 0.5\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.5177 - acc: 0.7206 - precision_2: 0.7261 - recall_2: 0.70576s - loss: 0.5007 - acc: 0.7349  - ETA: 4s - loss: 0.5060 - acc: 0.7276 -  - ETA: 3s - loss: 0.5081 - acc: 0.7272 - precision_2: 0.7319 - \n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4969 - acc: 0.7296 - precision_2: 0.7332 - recall_2: 0.71942s - loss: 0.494\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4857 - acc: 0.7330 - precision_2: 0.7354 - recall_2: 0.7255\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4783 - acc: 0.7435 - precision_2: 0.7459 - recall_2: 0.7363\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4831 - acc: 0.7436 - precision_2: 0.7446 - recall_2: 0.7392\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4627 - acc: 0.7505 - precision_2: 0.7545 - recall_2: 0.7407\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4433 - acc: 0.7635 - precision_2: 0.7653 - recall_2: 0.7582\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4441 - acc: 0.7677 - precision_2: 0.7676 - recall_2: 0.7661\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4289 - acc: 0.7707 - precision_2: 0.7704 - recall_2: 0.7695\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4063 - acc: 0.7892 - precision_2: 0.7889 - recall_2: 0.7883\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4214 - acc: 0.7786 - precision_2: 0.7844 - recall_2: 0.7668\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.4196 - acc: 0.7821 - precision_2: 0.7814 - recall_2: 0.7814\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.3997 - acc: 0.7924 - precision_2: 0.7956 - recall_2: 0.7853\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.4163 - acc: 0.7821 - precision_2: 0.7824 - recall_2: 0.7797\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1143 - acc: 0.5498 - precision_2: 0.5632 - recall_2: 0.5427\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6982 - acc: 0.5146 - precision_3: 0.5133 - recall_3: 0.5310\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6905 - acc: 0.5294 - precision_3: 0.5281 - recall_3: 0.53834s - loss: 0.6907 - acc: 0.5303 - precision_3: - ETA: 3s - loss: 0.6903 - acc: 0.5299 - precisio - ETA: 2s - loss: 0.690\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6888 - acc: 0.5337 - precision_3: 0.5352 - recall_3: 0.5007\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6875 - acc: 0.5362 - precision_3: 0.5349 - recall_3: 0.5441\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6868 - acc: 0.5455 - precision_3: 0.5488 - recall_3: 0.5029\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6861 - acc: 0.5384 - precision_3: 0.5396 - recall_3: 0.51290s - loss: 0.6862 - acc: 0.5384 - precision_3: 0.5397 - recall_3: 0.\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6833 - acc: 0.5530 - precision_3: 0.5566 - recall_3: 0.5149\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6844 - acc: 0.5444 - precision_3: 0.5483 - recall_3: 0.4959\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6823 - acc: 0.5563 - precision_3: 0.5594 - recall_3: 0.5239\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.6808 - acc: 0.5531 - precision_3: 0.5545 - recall_3: 0.5334\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6788 - acc: 0.5606 - precision_3: 0.5690 - recall_3: 0.4939\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6777 - acc: 0.5652 - precision_3: 0.5697 - recall_3: 0.5273\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6784 - acc: 0.5569 - precision_3: 0.5573 - recall_3: 0.5471\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.6724 - acc: 0.5782 - precision_3: 0.5850 - recall_3: 0.5339\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6713 - acc: 0.5758 - precision_3: 0.5828 - recall_3: 0.5288\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6686 - acc: 0.5841 - precision_3: 0.5855 - recall_3: 0.5715\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6636 - acc: 0.5877 - precision_3: 0.5957 - recall_3: 0.5422\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.6613 - acc: 0.5871 - precision_3: 0.5902 - recall_3: 0.5659\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.6559 - acc: 0.5948 - precision_3: 0.6012 - recall_3: 0.55950s - loss: 0.6565 - acc: 0.5935 - precision_3: 0.6002 - recall_3\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6508 - acc: 0.6065 - precision_3: 0.6157 - recall_3: 0.5632\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6473 - acc: 0.6049 - precision_3: 0.6102 - recall_3: 0.5773\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6423 - acc: 0.6124 - precision_3: 0.6220 - recall_3: 0.5700\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6344 - acc: 0.6202 - precision_3: 0.6305 - recall_3: 0.5780\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6291 - acc: 0.6278 - precision_3: 0.6340 - recall_3: 0.6017 1s - loss: 0.6284 - acc: 0.6283 - precision_3: 0.6342 - recall_3: 0.60 - ETA: 1s - loss: 0.6286 - acc: 0.6279 \n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6220 - acc: 0.6313 - precision_3: 0.6385 - recall_3: 0.6027 3s - loss: 0.6175 - acc: 0.6388 - precision_ - ETA - ETA: 0s - loss: 0.6210 - acc: 0.6327 - precision_3: 0.6416 - reca\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6164 - acc: 0.6425 - precision_3: 0.6528 - recall_3: 0.6066\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.6109 - acc: 0.6467 - precision_3: 0.6545 - recall_3: 0.61900s - loss: 0.6097 - acc: 0.6466 - precision_3: 0.652\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5974 - acc: 0.6593 - precision_3: 0.6632 - recall_3: 0.6451\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.5959 - acc: 0.6590 - precision_3: 0.6662 - recall_3: 0.6351\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5769 - acc: 0.6744 - precision_3: 0.6793 - recall_3: 0.6588\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5638 - acc: 0.6849 - precision_3: 0.6903 - recall_3: 0.6688\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.5590 - acc: 0.6879 - precision_3: 0.6950 - recall_3: 0.6680 0s - loss: 0.5589 - acc: 0.6882 - precision_3: 0.6954 - recall_3: 0.66\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5433 - acc: 0.6957 - precision_3: 0.6994 - recall_3: 0.6849 1s - loss: 0.5459 - \n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5319 - acc: 0.7081 - precision_3: 0.7124 - recall_3: 0.6966\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5206 - acc: 0.7195 - precision_3: 0.7223 - recall_3: 0.7117\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.5260 - acc: 0.7128 - precision_3: 0.7180 - recall_3: 0.6993\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4990 - acc: 0.7287 - precision_3: 0.7283 - recall_3: 0.7283\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4874 - acc: 0.7390 - precision_3: 0.7441 - recall_3: 0.7271 2s - loss: 0.4789 - acc: 0.7477 - precision_3: 0.748 - ETA: 1s - loss: 0.4801 - acc: 0.7456 - precisio - ETA: 1s - loss: 0.4821 - acc: 0.7436 - pr\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.4739 - acc: 0.7487 - precision_3: 0.7491 - recall_3: 0.7466\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.4713 - acc: 0.7447 - precision_3: 0.7475 - recall_3: 0.7378\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.4525 - acc: 0.7551 - precision_3: 0.7556 - recall_3: 0.7532\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.4396 - acc: 0.7679 - precision_3: 0.7718 - recall_3: 0.7598\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4696 - acc: 0.7461 - precision_3: 0.7417 - recall_3: 0.7541\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.4449 - acc: 0.7659 - precision_3: 0.7680 - recall_3: 0.7607\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4330 - acc: 0.7722 - precision_3: 0.7710 - recall_3: 0.7734\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.3990 - acc: 0.7852 - precision_3: 0.7850 - recall_3: 0.7846\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.3998 - acc: 0.7878 - precision_3: 0.7865 - recall_3: 0.7890\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4086 - acc: 0.7850 - precision_3: 0.7804 - recall_3: 0.7922 6s - loss: 0.3856 - acc: 0.7966 - precision_ - ETA: 5s - loss: 0.3903 -  - ETA: 1s - loss: 0.4110 - acc: 0.7833 - prec\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.3792 - acc: 0.7989 - precision_3: 0.7997 - recall_3: 0.7966 2s - loss: 0.3781 - acc: 0.7959 - precision_3: 0.7959 -  - ETA: 1s - loss: 0.3\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.3650 - acc: 0.8091 - precision_3: 0.8055 - recall_3: 0.8141 4s - loss: 0.3572 - acc: 0.8151 - precision_3: 0.8031 - re - ETA: 1s - loss: 0.360\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.2199 - acc: 0.5367 - precision_3: 0.5472 - recall_3: 0.5011\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6952 - acc: 0.5240 - precision_4: 0.5252 - recall_4: 0.5824\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6912 - acc: 0.5228 - precision_4: 0.5263 - recall_4: 0.5336\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6888 - acc: 0.5290 - precision_4: 0.5321 - recall_4: 0.5452\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6902 - acc: 0.5433 - precision_4: 0.5495 - recall_4: 0.52202s - loss:\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6879 - acc: 0.5388 - precision_4: 0.5408 - recall_4: 0.5633\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6859 - acc: 0.5469 - precision_4: 0.5538 - recall_4: 0.5213\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6840 - acc: 0.5503 - precision_4: 0.5480 - recall_4: 0.6159\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6834 - acc: 0.5523 - precision_4: 0.5561 - recall_4: 0.55392s - loss: 0.6833 \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6817 - acc: 0.5556 - precision_4: 0.5570 - recall_4: 0.57872s\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6802 - acc: 0.5591 - precision_4: 0.5574 - recall_4: 0.6082\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6790 - acc: 0.5637 - precision_4: 0.5635 - recall_4: 0.59666s - loss: 0.6778 - ac - ETA: 1s - loss: 0.6794 - acc: 0.5626 - pr\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6769 - acc: 0.5670 - precision_4: 0.5674 - recall_4: 0.5940\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6743 - acc: 0.5753 - precision_4: 0.5753 - recall_4: 0.6017\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6732 - acc: 0.5725 - precision_4: 0.5703 - recall_4: 0.6164\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6700 - acc: 0.5859 - precision_4: 0.5887 - recall_4: 0.59230s - loss: 0.6701 - acc: 0.5859 - precision_4: 0.587\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6650 - acc: 0.5858 - precision_4: 0.5894 - recall_4: 0.58741s - loss: 0.6659 - acc: 0.5842 - precision_\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6628 - acc: 0.5913 - precision_4: 0.5895 - recall_4: 0.6229\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6586 - acc: 0.5926 - precision_4: 0.5958 - recall_4: 0.59610s - loss: 0.6586 - acc: 0.5924 - precision_4: 0.5957 - recall_4: 0.\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6551 - acc: 0.6005 - precision_4: 0.6031 - recall_4: 0.6070\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6472 - acc: 0.6195 - precision_4: 0.6216 - recall_4: 0.6268\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.6422 - acc: 0.6165 - precision_4: 0.6220 - recall_4: 0.6094\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6339 - acc: 0.6190 - precision_4: 0.6232 - recall_4: 0.6176\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.6323 - acc: 0.6311 - precision_4: 0.6343 - recall_4: 0.6331\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6183 - acc: 0.6390 - precision_4: 0.6423 - recall_4: 0.6406\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6151 - acc: 0.6413 - precision_4: 0.6475 - recall_4: 0.6331\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.6062 - acc: 0.6493 - precision_4: 0.6520 - recall_4: 0.6529 0s - loss: 0.6055 - acc: 0.6495 - precision_\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5961 - acc: 0.6603 - precision_4: 0.6619 - recall_4: 0.66640s - loss: 0.5948 - acc: 0.6615 - precision_4: 0.6648 \n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5837 - acc: 0.6700 - precision_4: 0.6721 - recall_4: 0.6744\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5815 - acc: 0.6716 - precision_4: 0.6744 - recall_4: 0.6739\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5736 - acc: 0.6776 - precision_4: 0.6817 - recall_4: 0.6761\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5535 - acc: 0.6877 - precision_4: 0.6890 - recall_4: 0.6935\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5496 - acc: 0.6988 - precision_4: 0.7025 - recall_4: 0.6981\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5345 - acc: 0.7049 - precision_4: 0.7053 - recall_4: 0.7121\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5235 - acc: 0.7173 - precision_4: 0.7158 - recall_4: 0.7283\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5073 - acc: 0.7229 - precision_4: 0.7251 - recall_4: 0.72511s - loss: 0.5069 - acc: 0.7232 - precision_4:\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5022 - acc: 0.7280 - precision_4: 0.7253 - recall_4: 0.7411\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.5018 - acc: 0.7321 - precision_4: 0.7292 - recall_4: 0.7454\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4723 - acc: 0.7418 - precision_4: 0.7396 - recall_4: 0.7527\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4680 - acc: 0.7528 - precision_4: 0.7504 - recall_4: 0.7638\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4545 - acc: 0.7606 - precision_4: 0.7609 - recall_4: 0.7657\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4377 - acc: 0.7696 - precision_4: 0.7706 - recall_4: 0.7732\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4357 - acc: 0.7695 - precision_4: 0.7678 - recall_4: 0.77801s - loss: 0.4368 - acc: 0.7710 - prec\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.4254 - acc: 0.7754 - precision_4: 0.7746 - recall_4: 0.7819\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4125 - acc: 0.7817 - precision_4: 0.7792 - recall_4: 0.7911\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4433 - acc: 0.7662 - precision_4: 0.7640 - recall_4: 0.7758\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.3987 - acc: 0.7924 - precision_4: 0.7901 - recall_4: 0.8010\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4023 - acc: 0.7886 - precision_4: 0.7854 - recall_4: 0.7990\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.3945 - acc: 0.7942 - precision_4: 0.7915 - recall_4: 0.8034\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.3759 - acc: 0.8058 - precision_4: 0.8038 - recall_4: 0.8133\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.3764 - acc: 0.8017 - precision_4: 0.7984 - recall_4: 0.8114\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1096 - acc: 0.5389 - precision_4: 0.5022 - recall_4: 0.5437\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.6971 - acc: 0.5216 - precision_5: 0.5192 - recall_5: 0.5409\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6909 - acc: 0.5279 - precision_5: 0.5278 - recall_5: 0.5004\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6899 - acc: 0.5311 - precision_5: 0.5294 - recall_5: 0.5319\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6884 - acc: 0.5351 - precision_5: 0.5335 - recall_5: 0.5348\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6879 - acc: 0.5366 - precision_5: 0.5372 - recall_5: 0.5060\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.6853 - acc: 0.5493 - precision_5: 0.5501 - recall_5: 0.5246\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6839 - acc: 0.5449 - precision_5: 0.5485 - recall_5: 0.4903 2s - loss: 0.6838 - acc: 0.5490 - pr - ETA: 1s - loss: 0.6842 - ac\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.6819 - acc: 0.5479 - precision_5: 0.5527 - recall_5: 0.4867\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6808 - acc: 0.5592 - precision_5: 0.5580 - recall_5: 0.5558\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6797 - acc: 0.5661 - precision_5: 0.5700 - recall_5: 0.5260\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6776 - acc: 0.5675 - precision_5: 0.5742 - recall_5: 0.5116\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6747 - acc: 0.5628 - precision_5: 0.5657 - recall_5: 0.5280\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6745 - acc: 0.5758 - precision_5: 0.5802 - recall_5: 0.5382 0s - loss: 0.6750 - acc: 0.5751 - precision_5: 0.5789 - recall_5: \n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6707 - acc: 0.5745 - precision_5: 0.5779 - recall_5: 0.5419\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6664 - acc: 0.5859 - precision_5: 0.5877 - recall_5: 0.5663 1s - loss: 0.6662 - acc: 0.586\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6627 - acc: 0.5847 - precision_5: 0.5899 - recall_5: 0.5468\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6591 - acc: 0.5909 - precision_5: 0.5945 - recall_5: 0.5634\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6561 - acc: 0.5933 - precision_5: 0.6012 - recall_5: 0.5463\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.6504 - acc: 0.6019 - precision_5: 0.6076 - recall_5: 0.5676\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6450 - acc: 0.6093 - precision_5: 0.6155 - recall_5: 0.5754 1s - loss: 0.6459 - acc: 0\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6428 - acc: 0.6120 - precision_5: 0.6178 - recall_5: 0.5803\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6327 - acc: 0.6246 - precision_5: 0.6305 - recall_5: 0.5961\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6235 - acc: 0.6292 - precision_5: 0.6340 - recall_5: 0.6057\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6196 - acc: 0.6395 - precision_5: 0.6489 - recall_5: 0.6025 0s - loss: 0.6201 - acc: 0.6387 - precision_5: 0.6473 \n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6156 - acc: 0.6381 - precision_5: 0.6444 - recall_5: 0.6110\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6016 - acc: 0.6524 - precision_5: 0.6575 - recall_5: 0.6313\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5919 - acc: 0.6624 - precision_5: 0.6705 - recall_5: 0.6340 0s - loss: 0.5913 - acc: 0.6636 - precision_5: 0.6731 - recall_5: \n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5756 - acc: 0.6723 - precision_5: 0.6805 - recall_5: 0.6457\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.5677 - acc: 0.6827 - precision_5: 0.6904 - recall_5: 0.6587\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5579 - acc: 0.6840 - precision_5: 0.6946 - recall_5: 0.6531 3s - loss: 0.5338 - \n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.5707 - acc: 0.6773 - precision_5: 0.6860 - recall_5: 0.6501\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.5334 - acc: 0.7033 - precision_5: 0.7079 - recall_5: 0.6887\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.5340 - acc: 0.7067 - precision_5: 0.7138 - recall_5: 0.6868\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.5203 - acc: 0.7152 - precision_5: 0.7242 - recall_5: 0.6922\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.5097 - acc: 0.7219 - precision_5: 0.7284 - recall_5: 0.7049\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4932 - acc: 0.7329 - precision_5: 0.7360 - recall_5: 0.7234\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.4891 - acc: 0.7364 - precision_5: 0.7421 - recall_5: 0.7220\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4755 - acc: 0.7431 - precision_5: 0.7467 - recall_5: 0.7332\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4647 - acc: 0.7548 - precision_5: 0.7571 - recall_5: 0.7479\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4621 - acc: 0.7596 - precision_5: 0.7643 - recall_5: 0.7486\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4506 - acc: 0.7609 - precision_5: 0.7602 - recall_5: 0.7598\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.4255 - acc: 0.7719 - precision_5: 0.7760 - recall_5: 0.7625\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4346 - acc: 0.7715 - precision_5: 0.7759 - recall_5: 0.7613\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4389 - acc: 0.7721 - precision_5: 0.7804 - recall_5: 0.7552\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4180 - acc: 0.7840 - precision_5: 0.7837 - recall_5: 0.7826 3s - loss: 0.4101 - acc: 0.7910 - precision_\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.4198 - acc: 0.7785 - precision_5: 0.7828 - recall_5: 0.7689\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.3830 - acc: 0.7963 - precision_5: 0.7983 - recall_5: 0.7911\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.3828 - acc: 0.7980 - precision_5: 0.8035 - recall_5: 0.7872\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.3904 - acc: 0.7975 - precision_5: 0.8015 - recall_5: 0.7892 0s - loss: 0.3884 - acc: 0.7996 - pr\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.3899 - acc: 0.7964 - precision_5: 0.7926 - recall_5: 0.8011\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1699 - acc: 0.5192 - precision_5: 0.5335 - recall_5: 0.5255\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6994 - acc: 0.5172 - precision_6: 0.5170 - recall_6: 0.5305\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6929 - acc: 0.5207 - precision_6: 0.5212 - recall_6: 0.5152\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6914 - acc: 0.5258 - precision_6: 0.5271 - recall_6: 0.5064\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6897 - acc: 0.5304 - precision_6: 0.5330 - recall_6: 0.4953 5s - los - ETA: 0s - loss: 0.6904 - acc: 0.5274 - precis\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6882 - acc: 0.5335 - precision_6: 0.5341 - recall_6: 0.5286\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6884 - acc: 0.5327 - precision_6: 0.5363 - recall_6: 0.4870\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.6876 - acc: 0.5338 - precision_6: 0.5342 - recall_6: 0.5315\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.6853 - acc: 0.5420 - precision_6: 0.5458 - recall_6: 0.5028\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6838 - acc: 0.5482 - precision_6: 0.5496 - recall_6: 0.5364 1s - loss: 0.6837 - acc: 0.5483 - prec\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6822 - acc: 0.5531 - precision_6: 0.5554 - recall_6: 0.5347 1s - loss: 0.6821 - acc: 0.5536 - \n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6812 - acc: 0.5539 - precision_6: 0.5557 - recall_6: 0.5405\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6806 - acc: 0.5509 - precision_6: 0.5495 - recall_6: 0.5678\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6779 - acc: 0.5586 - precision_6: 0.5571 - recall_6: 0.5731\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6755 - acc: 0.5692 - precision_6: 0.5661 - recall_6: 0.5941\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6735 - acc: 0.5668 - precision_6: 0.5651 - recall_6: 0.5824\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6695 - acc: 0.5733 - precision_6: 0.5702 - recall_6: 0.5972\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6672 - acc: 0.5804 - precision_6: 0.5807 - recall_6: 0.5799\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6653 - acc: 0.5822 - precision_6: 0.5838 - recall_6: 0.5741\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6582 - acc: 0.5962 - precision_6: 0.5934 - recall_6: 0.6121\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6566 - acc: 0.5933 - precision_6: 0.5958 - recall_6: 0.5814\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6490 - acc: 0.6042 - precision_6: 0.6044 - recall_6: 0.6043\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6447 - acc: 0.6073 - precision_6: 0.6131 - recall_6: 0.5824\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6398 - acc: 0.6158 - precision_6: 0.6196 - recall_6: 0.6006\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.6347 - acc: 0.6202 - precision_6: 0.6278 - recall_6: 0.5911\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.6226 - acc: 0.6322 - precision_6: 0.6438 - recall_6: 0.5926\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6156 - acc: 0.6384 - precision_6: 0.6477 - recall_6: 0.6077\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6080 - acc: 0.6446 - precision_6: 0.6569 - recall_6: 0.6062\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6021 - acc: 0.6553 - precision_6: 0.6610 - recall_6: 0.6384\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5873 - acc: 0.6656 - precision_6: 0.6713 - recall_6: 0.6495\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5730 - acc: 0.6790 - precision_6: 0.6899 - recall_6: 0.6508\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5671 - acc: 0.6863 - precision_6: 0.6871 - recall_6: 0.6846\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5607 - acc: 0.6860 - precision_6: 0.6998 - recall_6: 0.6520 0s - loss: 0.5613 - acc: 0.6854 - precision_6: 0\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5479 - acc: 0.6955 - precision_6: 0.6993 - recall_6: 0.6865\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5334 - acc: 0.7028 - precision_6: 0.7122 - recall_6: 0.6812\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5299 - acc: 0.7106 - precision_6: 0.7176 - recall_6: 0.6951\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.5489 - acc: 0.6949 - precision_6: 0.6979 - recall_6: 0.6880\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5109 - acc: 0.7163 - precision_6: 0.7239 - recall_6: 0.6999\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5078 - acc: 0.7244 - precision_6: 0.7356 - recall_6: 0.7009\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4806 - acc: 0.7446 - precision_6: 0.7464 - recall_6: 0.7413\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4883 - acc: 0.7386 - precision_6: 0.7485 - recall_6: 0.7192\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4751 - acc: 0.7454 - precision_6: 0.7510 - recall_6: 0.7347\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.4721 - acc: 0.7437 - precision_6: 0.7475 - recall_6: 0.7364\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4490 - acc: 0.7537 - precision_6: 0.7568 - recall_6: 0.7481\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4411 - acc: 0.7614 - precision_6: 0.7624 - recall_6: 0.7598 1s - los\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4309 - acc: 0.7665 - precision_6: 0.7778 - recall_6: 0.7464\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.4214 - acc: 0.7726 - precision_6: 0.7739 - recall_6: 0.7705\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4161 - acc: 0.7782 - precision_6: 0.7838 - recall_6: 0.7686\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4736 - acc: 0.7492 - precision_6: 0.7528 - recall_6: 0.7425\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.4043 - acc: 0.7855 - precision_6: 0.7873 - recall_6: 0.7827\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.3857 - acc: 0.7957 - precision_6: 0.8000 - recall_6: 0.7888\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1730 - acc: 0.5219 - precision_6: 0.5191 - recall_6: 0.5396 0s - loss: 1.1862 - acc: 0.5180 - precision_6: 0.5195 - recall_6: 0.54\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.7000 - acc: 0.5072 - precision_7: 0.5059 - recall_7: 0.5207 3s - loss: 0.7050 - ac\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6930 - acc: 0.5209 - precision_7: 0.5191 - recall_7: 0.5393\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6910 - acc: 0.5306 - precision_7: 0.5296 - recall_7: 0.5283\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6897 - acc: 0.5287 - precision_7: 0.5259 - recall_7: 0.5632\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6893 - acc: 0.5332 - precision_7: 0.5323 - recall_7: 0.5307\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.6875 - acc: 0.5413 - precision_7: 0.5384 - recall_7: 0.5652\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6873 - acc: 0.5420 - precision_7: 0.5402 - recall_7: 0.5515 1s - loss: 0.6\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6850 - acc: 0.5455 - precision_7: 0.5457 - recall_7: 0.5317 0s - loss: 0.6849 - acc: 0.5459 - precision_7:\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6855 - acc: 0.5474 - precision_7: 0.5449 - recall_7: 0.5625\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6836 - acc: 0.5525 - precision_7: 0.5520 - recall_7: 0.5461\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6821 - acc: 0.5559 - precision_7: 0.5568 - recall_7: 0.5381 0s - loss: 0.6823 - acc: 0.5550 - precision_7: 0.5569 - recall_7\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6811 - acc: 0.5545 - precision_7: 0.5550 - recall_7: 0.5405\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6799 - acc: 0.5556 - precision_7: 0.5547 - recall_7: 0.5539 0s - loss: 0.6793 - acc: 0.5563 - precision_\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6782 - acc: 0.5594 - precision_7: 0.5578 - recall_7: 0.5637 2s - loss: 0.6773 - acc: 0.5621 - precision_7: 0.564 -\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6771 - acc: 0.5656 - precision_7: 0.5628 - recall_7: 0.5793\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6744 - acc: 0.5700 - precision_7: 0.5690 - recall_7: 0.5695\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6723 - acc: 0.5743 - precision_7: 0.5719 - recall_7: 0.5830\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.6700 - acc: 0.5740 - precision_7: 0.5722 - recall_7: 0.5796\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6676 - acc: 0.5774 - precision_7: 0.5766 - recall_7: 0.5759\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6643 - acc: 0.5827 - precision_7: 0.5810 - recall_7: 0.5864\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6590 - acc: 0.5897 - precision_7: 0.5878 - recall_7: 0.5944\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6561 - acc: 0.5961 - precision_7: 0.5901 - recall_7: 0.6232\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6497 - acc: 0.6114 - precision_7: 0.6067 - recall_7: 0.6284\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6479 - acc: 0.6109 - precision_7: 0.6086 - recall_7: 0.6169 2s - - ETA: 0s - loss: 0.6454 - acc: 0.6125 - pr\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6399 - acc: 0.6177 - precision_7: 0.6171 - recall_7: 0.6159 4s - loss: 0\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6353 - acc: 0.6213 - precision_7: 0.6217 - recall_7: 0.6152\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6235 - acc: 0.6344 - precision_7: 0.6336 - recall_7: 0.6335\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6166 - acc: 0.6346 - precision_7: 0.6348 - recall_7: 0.6303 3s - loss: 0.6105 - acc:\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.6124 - acc: 0.6446 - precision_7: 0.6442 - recall_7: 0.6428\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.6012 - acc: 0.6525 - precision_7: 0.6516 - recall_7: 0.6525\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5921 - acc: 0.6648 - precision_7: 0.6654 - recall_7: 0.6603\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.5791 - acc: 0.6680 - precision_7: 0.6718 - recall_7: 0.6542 2s - loss: 0.5789 - acc: 0.6721 - precision_ - ETA: 1s - loss: 0.5797 - acc: 0.6\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5699 - acc: 0.6796 - precision_7: 0.6794 - recall_7: 0.6774 2s - loss: 0 - ETA: 1s - loss: 0.5691 - acc: 0.6807 - \n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5611 - acc: 0.6846 - precision_7: 0.6871 - recall_7: 0.6752\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5449 - acc: 0.6954 - precision_7: 0.6923 - recall_7: 0.7011\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.5404 - acc: 0.6992 - precision_7: 0.6989 - recall_7: 0.6974 0s - loss: 0.5375 - acc: 0.7036 - prec\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.5211 - acc: 0.7118 - precision_7: 0.7144 - recall_7: 0.7038\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.5242 - acc: 0.7145 - precision_7: 0.7177 - recall_7: 0.7052 \n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.5099 - acc: 0.7190 - precision_7: 0.7206 - recall_7: 0.7135 0s - loss: 0.5063 - acc: 0.7204 - prec\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 8s 31ms/step - loss: 0.4867 - acc: 0.7330 - precision_7: 0.7329 - recall_7: 0.7313\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.4708 - acc: 0.7468 - precision_7: 0.7437 - recall_7: 0.7513\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4675 - acc: 0.7453 - precision_7: 0.7486 - recall_7: 0.7369 6s - loss: 0.4605 - acc: 0.7615 - precis - ETA: 6s - loss: 0.4456 - acc:\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.4574 - acc: 0.7532 - precision_7: 0.7472 - recall_7: 0.7638\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.4397 - acc: 0.7594 - precision_7: 0.7633 - recall_7: 0.7506\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4312 - acc: 0.7738 - precision_7: 0.7742 - recall_7: 0.7716\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.4295 - acc: 0.7704 - precision_7: 0.7716 - recall_7: 0.7667 1s - loss: 0.4247 - ac - ETA: 0s - loss: 0.4289 - acc: 0.7708 - precision_7: 0.7720 - recall_7: 0.\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.4235 - acc: 0.7721 - precision_7: 0.7713 - recall_7: 0.7721 2s - - ETA: 0s - loss: 0.4246 - acc: 0.7745 - pr\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.4084 - acc: 0.7820 - precision_7: 0.7805 - recall_7: 0.7833\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.4091 - acc: 0.7801 - precision_7: 0.7768 - recall_7: 0.7848\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.3998 - acc: 0.7854 - precision_7: 0.7780 - recall_7: 0.7972 0s - loss: 0.3998 - acc: 0.7854 - precision_7: 0.7780 - recall_7: 0.79\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.2328 - acc: 0.5428 - precision_7: 0.5561 - recall_7: 0.5118\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6995 - acc: 0.5151 - precision_8: 0.5142 - recall_8: 0.5391\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6904 - acc: 0.5293 - precision_8: 0.5277 - recall_8: 0.5554\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6889 - acc: 0.5363 - precision_8: 0.5373 - recall_8: 0.5191\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6887 - acc: 0.5351 - precision_8: 0.5358 - recall_8: 0.5213\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6873 - acc: 0.5472 - precision_8: 0.5476 - recall_8: 0.5408\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6860 - acc: 0.5455 - precision_8: 0.5491 - recall_8: 0.5069\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.6852 - acc: 0.5516 - precision_8: 0.5534 - recall_8: 0.5323\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 6s 23ms/step - loss: 0.6831 - acc: 0.5511 - precision_8: 0.5546 - recall_8: 0.5174\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.6827 - acc: 0.5471 - precision_8: 0.5526 - recall_8: 0.4923\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6809 - acc: 0.5567 - precision_8: 0.5543 - recall_8: 0.5773\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6810 - acc: 0.5579 - precision_8: 0.5631 - recall_8: 0.5150\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6788 - acc: 0.5614 - precision_8: 0.5642 - recall_8: 0.5374\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6761 - acc: 0.5660 - precision_8: 0.5691 - recall_8: 0.5420\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.6725 - acc: 0.5709 - precision_8: 0.5736 - recall_8: 0.5508\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6721 - acc: 0.5706 - precision_8: 0.5734 - recall_8: 0.5498\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6692 - acc: 0.5726 - precision_8: 0.5733 - recall_8: 0.5661\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6629 - acc: 0.5840 - precision_8: 0.5852 - recall_8: 0.5754\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6565 - acc: 0.5930 - precision_8: 0.5934 - recall_8: 0.5898\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6542 - acc: 0.6001 - precision_8: 0.6034 - recall_8: 0.5827\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6504 - acc: 0.5998 - precision_8: 0.6016 - recall_8: 0.5900\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6522 - acc: 0.6003 - precision_8: 0.6032 - recall_8: 0.5851\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6419 - acc: 0.6129 - precision_8: 0.6134 - recall_8: 0.6095\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6330 - acc: 0.6176 - precision_8: 0.6217 - recall_8: 0.5998\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.6262 - acc: 0.6272 - precision_8: 0.6312 - recall_8: 0.6112\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.6174 - acc: 0.6381 - precision_8: 0.6398 - recall_8: 0.6309\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.6126 - acc: 0.6450 - precision_8: 0.6475 - recall_8: 0.6358\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.6009 - acc: 0.6523 - precision_8: 0.6549 - recall_8: 0.6431\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.5921 - acc: 0.6597 - precision_8: 0.6612 - recall_8: 0.6546\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.5811 - acc: 0.6659 - precision_8: 0.6727 - recall_8: 0.6458\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.5678 - acc: 0.6768 - precision_8: 0.6753 - recall_8: 0.6804\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 8s 32ms/step - loss: 0.5595 - acc: 0.6855 - precision_8: 0.6860 - recall_8: 0.6838\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.5511 - acc: 0.6948 - precision_8: 0.6948 - recall_8: 0.6943\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.5351 - acc: 0.6995 - precision_8: 0.7027 - recall_8: 0.6911\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.5219 - acc: 0.7064 - precision_8: 0.7070 - recall_8: 0.7043\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.5065 - acc: 0.7215 - precision_8: 0.7175 - recall_8: 0.7301 \n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.5077 - acc: 0.7241 - precision_8: 0.7205 - recall_8: 0.7320 0s - loss: 0.5047 - acc: 0.7252 - precision_8:\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 6s 21ms/step - loss: 0.5051 - acc: 0.7224 - precision_8: 0.7216 - recall_8: 0.7238\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4808 - acc: 0.7389 - precision_8: 0.7358 - recall_8: 0.7449 0s - loss: 0.4794 - acc: 0.7393 - precision_8: 0.7375 - \n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4633 - acc: 0.7477 - precision_8: 0.7446 - recall_8: 0.7537 1s - loss: 0.455\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.4662 - acc: 0.7479 - precision_8: 0.7417 - recall_8: 0.7603\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4558 - acc: 0.7558 - precision_8: 0.7560 - recall_8: 0.7549\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4456 - acc: 0.7616 - precision_8: 0.7568 - recall_8: 0.7708\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 6s 21ms/step - loss: 0.4332 - acc: 0.7684 - precision_8: 0.7617 - recall_8: 0.7810\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4179 - acc: 0.7759 - precision_8: 0.7750 - recall_8: 0.7771\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4251 - acc: 0.7770 - precision_8: 0.7770 - recall_8: 0.7766 1s - loss: 0.419\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.4137 - acc: 0.7778 - precision_8: 0.7758 - recall_8: 0.7812 2s - l\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4051 - acc: 0.7855 - precision_8: 0.7803 - recall_8: 0.7944\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.3868 - acc: 0.7945 - precision_8: 0.7914 - recall_8: 0.7995\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 6s 21ms/step - loss: 0.3973 - acc: 0.7946 - precision_8: 0.7960 - recall_8: 0.7920\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.3878 - acc: 0.7908 - precision_8: 0.7899 - recall_8: 0.7922\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.2662 - acc: 0.5417 - precision_8: 0.5439 - recall_8: 0.5415\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6960 - acc: 0.5251 - precision_9: 0.5252 - recall_9: 0.5274\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6921 - acc: 0.5226 - precision_9: 0.5225 - recall_9: 0.5305\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6907 - acc: 0.5338 - precision_9: 0.5336 - recall_9: 0.5410 1s - loss: 0.6910 - acc: 0.5\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6892 - acc: 0.5380 - precision_9: 0.5395 - recall_9: 0.5215 0s - loss: 0.6892 - acc: 0.5377 - precision_9: 0.5393 - recall_9: 0.\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6902 - acc: 0.5284 - precision_9: 0.5304 - recall_9: 0.4982 2s - loss: 0.6898 -  - ETA: 0s - loss: 0.6902 - acc: 0.5273 - precis\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 5s 19ms/step - loss: 0.6866 - acc: 0.5411 - precision_9: 0.5432 - recall_9: 0.5201 4s - loss: 0.6828 - acc: 0 - ETA: 3s - loss: 0.6876 - acc: 0.5395 - precis\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6865 - acc: 0.5390 - precision_9: 0.5406 - recall_9: 0.5215\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6846 - acc: 0.5485 - precision_9: 0.5526 - recall_9: 0.5113\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6843 - acc: 0.5442 - precision_9: 0.5473 - recall_9: 0.5138 1s - loss: 0.6833 - acc: 0.5455 - prec - ETA: 0s - loss: 0.6841 - acc: 0.5423 - precision_9:\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6826 - acc: 0.5478 - precision_9: 0.5495 - recall_9: 0.5337 1s - loss: 0.6830 - acc: 0.547\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6811 - acc: 0.5525 - precision_9: 0.5552 - recall_9: 0.5303\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6793 - acc: 0.5573 - precision_9: 0.5628 - recall_9: 0.5155\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6779 - acc: 0.5645 - precision_9: 0.5649 - recall_9: 0.5632\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6744 - acc: 0.5763 - precision_9: 0.5785 - recall_9: 0.5641\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6716 - acc: 0.5773 - precision_9: 0.5807 - recall_9: 0.5578\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6679 - acc: 0.5739 - precision_9: 0.5806 - recall_9: 0.5337 1s - loss:\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6636 - acc: 0.5856 - precision_9: 0.5903 - recall_9: 0.5610 1s - loss: 0.665\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6607 - acc: 0.5891 - precision_9: 0.5973 - recall_9: 0.5483 1s - loss: 0.6607 \n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6591 - acc: 0.5995 - precision_9: 0.6073 - recall_9: 0.5641\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6570 - acc: 0.5974 - precision_9: 0.6050 - recall_9: 0.5624\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6465 - acc: 0.6045 - precision_9: 0.6120 - recall_9: 0.5717 1s - loss: 0\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6469 - acc: 0.6031 - precision_9: 0.6095 - recall_9: 0.5751\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6415 - acc: 0.6127 - precision_9: 0.6217 - recall_9: 0.5770\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6364 - acc: 0.6183 - precision_9: 0.6243 - recall_9: 0.5953\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6293 - acc: 0.6325 - precision_9: 0.6393 - recall_9: 0.6087\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.6198 - acc: 0.6361 - precision_9: 0.6431 - recall_9: 0.6126\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6205 - acc: 0.6355 - precision_9: 0.6405 - recall_9: 0.6184\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6055 - acc: 0.6511 - precision_9: 0.6600 - recall_9: 0.6240 3s - loss: 0.5877 - acc: 0.6706 - precision_ - ETA: 2s - l - ETA: 0s - loss: 0.6014 - acc: 0.6577 - precision_\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.6012 - acc: 0.6563 - precision_9: 0.6662 - recall_9: 0.6272 3s - loss: 0.5912 - acc: 0.6693 \n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5872 - acc: 0.6718 - precision_9: 0.6796 - recall_9: 0.6505\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.5783 - acc: 0.6724 - precision_9: 0.6825 - recall_9: 0.6452\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 6s 22ms/step - loss: 0.5664 - acc: 0.6796 - precision_9: 0.6860 - recall_9: 0.6629\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5524 - acc: 0.6914 - precision_9: 0.7013 - recall_9: 0.6673\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5439 - acc: 0.6984 - precision_9: 0.7078 - recall_9: 0.6763 2s\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5353 - acc: 0.7051 - precision_9: 0.7128 - recall_9: 0.6875 3s - loss: 0.5\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5184 - acc: 0.7201 - precision_9: 0.7256 - recall_9: 0.7084\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.5073 - acc: 0.7263 - precision_9: 0.7311 - recall_9: 0.7165\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4969 - acc: 0.7333 - precision_9: 0.7423 - recall_9: 0.7150\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4787 - acc: 0.7471 - precision_9: 0.7540 - recall_9: 0.7340\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4722 - acc: 0.7519 - precision_9: 0.7582 - recall_9: 0.7401 2s - loss: 0.4640 - acc: 0.7559 - precision_9: 0.7567 - recall_9\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4590 - acc: 0.7555 - precision_9: 0.7594 - recall_9: 0.7484\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 5s 21ms/step - loss: 0.4615 - acc: 0.7576 - precision_9: 0.7562 - recall_9: 0.7608\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4517 - acc: 0.7559 - precision_9: 0.7598 - recall_9: 0.7488\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4315 - acc: 0.7693 - precision_9: 0.7708 - recall_9: 0.7669\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4368 - acc: 0.7664 - precision_9: 0.7781 - recall_9: 0.7457\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4404 - acc: 0.7655 - precision_9: 0.7637 - recall_9: 0.7693 3s - loss: 0.4460 - acc: 0.7663  - ETA\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.3955 - acc: 0.7910 - precision_9: 0.7920 - recall_9: 0.7895\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4219 - acc: 0.7771 - precision_9: 0.7814 - recall_9: 0.7698 1s - loss: 0.4062 - acc: 0.7\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.4157 - acc: 0.7800 - precision_9: 0.7827 - recall_9: 0.7756\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 5s 20ms/step - loss: 0.3910 - acc: 0.7918 - precision_9: 0.7939 - recall_9: 0.7885 1s - loss: 0.3724 - acc: 0.8025 - precision_9: 0.8040 - recall_9: 0.80 - ETA: 1s - loss: 0.3729 - ac\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.1557 - acc: 0.5450 - precision_9: 0.5457 - recall_9: 0.5132\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=1)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= tf_idf (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    model = Sequential() #rnn\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(128,activation='relu',return_sequences= True))\n",
    "    model.add(SimpleRNN(256,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.536271\n",
      "test precision: 0.537052\n",
      "test recall: 0.536509\n",
      "test f1_score: 0.536099\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
