{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5511569699086511556\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2958553908\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15052127645038666387\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "Name: /physical_device:GPU:0   Type: GPU\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20032\\3535943740.py:8: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "1 Physical GPU, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=14336 )] #7168  6144\n",
    "    )\n",
    "\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "     ---------------------------------------- 68.8/68.8 kB 1.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in d:\\program\\anaconda\\envs\\tf\\lib\\site-packages (from fasttext) (65.5.0)\n",
      "Requirement already satisfied: numpy in d:\\program\\anaconda\\envs\\tf\\lib\\site-packages (from fasttext) (1.24.0)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-win_amd64.whl size=222525 sha256=becc77c904f43ccc7bc5a6474e297542e5fbc307984d8972b3fa42eb2d022caa\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\3f\\84\\86\\c63cf501c46fb575152daee4b937075a5e9b31765c0e620fd4\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_total.xlsx\")\n",
    "\n",
    "#column = ['tweets','duygu']\n",
    "#df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "#df = pd.read_excel(\"../dataset/preprocessing_kemik.xlsx\")\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whatsapp'tan vazgecelim. yazilimi ve serverlar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ay deli gibi oldum yemin ederim, turkcell'in r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>başlarım turkcell’e de 3g’sine de. beceriksizl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkcell fakirin halinden anlıyo açık net</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahasjhdaşdhasd:akp-turkcell chp-avea ve mhp-vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17246</th>\n",
       "      <td>turkcell'e lira yüklüyorum 15 tane reklam mesa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17247</th>\n",
       "      <td>#turkcellkullanmiyorumcunku bi saniye lan ben ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17248</th>\n",
       "      <td>5 gb hediye internet veren turkcell ne kadar d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17249</th>\n",
       "      <td>turkcell soydun yine beni !!! her ay olmaz böyle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17250</th>\n",
       "      <td>turkcell superonline için yazdığım sikayeti so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  duygu\n",
       "0      whatsapp'tan vazgecelim. yazilimi ve serverlar...      2\n",
       "1      ay deli gibi oldum yemin ederim, turkcell'in r...      2\n",
       "2      başlarım turkcell’e de 3g’sine de. beceriksizl...      1\n",
       "3              turkcell fakirin halinden anlıyo açık net      2\n",
       "4      ahasjhdaşdhasd:akp-turkcell chp-avea ve mhp-vo...      0\n",
       "...                                                  ...    ...\n",
       "17246  turkcell'e lira yüklüyorum 15 tane reklam mesa...      1\n",
       "17247  #turkcellkullanmiyorumcunku bi saniye lan ben ...      0\n",
       "17248  5 gb hediye internet veren turkcell ne kadar d...      2\n",
       "17249   turkcell soydun yine beni !!! her ay olmaz böyle      1\n",
       "17250  turkcell superonline için yazdığım sikayeti so...      0\n",
       "\n",
       "[17251 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Load my word embeddings\n",
    "#import gensim\n",
    "#wordembeddings = gensim.models.KeyedVectors.load_word2vec_format('drive/My Drive/CNNPhraseEmbeddings/Resources/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "wordembeddings = fasttext.load_model('D:/Desktop/İndirilenler yedek/cc.tr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext (X_train,y_train,X_test,y_test):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)):\n",
    "        numberofwords=len(sequences_X_train[review_number])\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length)\n",
    "    y_test = np.asarray(y_test)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    unique_words = len(word_index)\n",
    "    total_words = unique_words + 1\n",
    "    skipped_words = 0\n",
    "    embedding_dim = 300\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = wordembeddings[word]\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "      \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "\n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 212s 433ms/step - loss: 1.0212 - accuracy: 0.4814\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 212s 435ms/step - loss: 0.9250 - accuracy: 0.5721\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 212s 436ms/step - loss: nan - accuracy: 0.5476\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 211s 434ms/step - loss: nan - accuracy: 0.3362\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 213s 437ms/step - loss: nan - accuracy: 0.3362\n",
      "Epoch 5: early stopping\n",
      "54/54 [==============================] - 2s 38ms/step - loss: nan - accuracy: 0.3424\n",
      "54/54 [==============================] - 2s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 204s 417ms/step - loss: 1.0299 - accuracy: 0.4844\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.9393 - accuracy: 0.5659\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 197s 406ms/step - loss: 0.8874 - accuracy: 0.6025\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 197s 405ms/step - loss: 0.8533 - accuracy: 0.6167\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 198s 408ms/step - loss: 0.8239 - accuracy: 0.6328\n",
      "Epoch 6/75\n",
      "486/486 [==============================] - 198s 407ms/step - loss: 0.7962 - accuracy: 0.6512\n",
      "Epoch 7/75\n",
      "486/486 [==============================] - 199s 410ms/step - loss: 0.7592 - accuracy: 0.6704\n",
      "Epoch 8/75\n",
      "486/486 [==============================] - 199s 410ms/step - loss: 0.7359 - accuracy: 0.6818\n",
      "Epoch 9/75\n",
      "486/486 [==============================] - 204s 420ms/step - loss: 0.7450 - accuracy: 0.6816\n",
      "Epoch 10/75\n",
      "486/486 [==============================] - 198s 408ms/step - loss: 0.7899 - accuracy: 0.6543\n",
      "Epoch 11/75\n",
      "486/486 [==============================] - 198s 408ms/step - loss: 0.7415 - accuracy: 0.6841\n",
      "Epoch 11: early stopping\n",
      "54/54 [==============================] - 3s 40ms/step - loss: 0.9166 - accuracy: 0.5936\n",
      "54/54 [==============================] - 2s 38ms/step\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 207s 422ms/step - loss: 1.0263 - accuracy: 0.4789\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 204s 421ms/step - loss: 0.9359 - accuracy: 0.5643\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 205s 422ms/step - loss: 0.8866 - accuracy: 0.6013\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 204s 419ms/step - loss: 0.8485 - accuracy: 0.6215\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 204s 420ms/step - loss: 0.8386 - accuracy: 0.6302\n",
      "Epoch 6/75\n",
      "486/486 [==============================] - 204s 420ms/step - loss: 0.7936 - accuracy: 0.6570\n",
      "Epoch 7/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: 0.7634 - accuracy: 0.6682\n",
      "Epoch 8/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.7487 - accuracy: 0.6793\n",
      "Epoch 9/75\n",
      "486/486 [==============================] - 206s 423ms/step - loss: 0.7468 - accuracy: 0.6800\n",
      "Epoch 10/75\n",
      "486/486 [==============================] - 202s 417ms/step - loss: nan - accuracy: 0.6780\n",
      "Epoch 11/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: nan - accuracy: 0.3363\n",
      "Epoch 12/75\n",
      "486/486 [==============================] - 203s 418ms/step - loss: nan - accuracy: 0.3363\n",
      "Epoch 12: early stopping\n",
      "54/54 [==============================] - 3s 41ms/step - loss: nan - accuracy: 0.3420\n",
      "54/54 [==============================] - 2s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 203s 414ms/step - loss: 1.0259 - accuracy: 0.4805\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.9339 - accuracy: 0.5691\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.8798 - accuracy: 0.6027\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.8399 - accuracy: 0.6288\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.8115 - accuracy: 0.6432\n",
      "Epoch 6/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: 0.7754 - accuracy: 0.6604\n",
      "Epoch 7/75\n",
      "486/486 [==============================] - 200s 412ms/step - loss: 0.7700 - accuracy: 0.6673\n",
      "Epoch 8/75\n",
      "486/486 [==============================] - 201s 413ms/step - loss: 0.7604 - accuracy: 0.6720\n",
      "Epoch 9/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.8177 - accuracy: 0.6391\n",
      "Epoch 10/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.7732 - accuracy: 0.6646\n",
      "Epoch 11/75\n",
      "486/486 [==============================] - 200s 412ms/step - loss: 0.7354 - accuracy: 0.6846\n",
      "Epoch 12/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.6968 - accuracy: 0.7069\n",
      "Epoch 13/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.6668 - accuracy: 0.7207\n",
      "Epoch 14/75\n",
      "486/486 [==============================] - 201s 413ms/step - loss: 0.6436 - accuracy: 0.7308\n",
      "Epoch 15/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.6072 - accuracy: 0.7487\n",
      "Epoch 16/75\n",
      "486/486 [==============================] - 203s 418ms/step - loss: 0.6173 - accuracy: 0.7492\n",
      "Epoch 17/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: 0.5534 - accuracy: 0.7755\n",
      "Epoch 18/75\n",
      "486/486 [==============================] - 203s 418ms/step - loss: 0.5300 - accuracy: 0.7823\n",
      "Epoch 19/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.5254 - accuracy: 0.7845\n",
      "Epoch 20/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.4752 - accuracy: 0.8106\n",
      "Epoch 21/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.4602 - accuracy: 0.8197\n",
      "Epoch 22/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.4136 - accuracy: 0.8384\n",
      "Epoch 23/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.4213 - accuracy: 0.8347\n",
      "Epoch 24/75\n",
      "486/486 [==============================] - 203s 418ms/step - loss: 0.3770 - accuracy: 0.8544\n",
      "Epoch 25/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.3402 - accuracy: 0.8713\n",
      "Epoch 26/75\n",
      "486/486 [==============================] - 201s 413ms/step - loss: 0.3251 - accuracy: 0.8765\n",
      "Epoch 27/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: 0.3192 - accuracy: 0.8771\n",
      "Epoch 28/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: 0.2872 - accuracy: 0.8936\n",
      "Epoch 29/75\n",
      "486/486 [==============================] - 203s 418ms/step - loss: 0.2635 - accuracy: 0.9026\n",
      "Epoch 30/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.2726 - accuracy: 0.9015\n",
      "Epoch 31/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: 0.2500 - accuracy: 0.9073\n",
      "Epoch 32/75\n",
      "486/486 [==============================] - 202s 415ms/step - loss: 0.2299 - accuracy: 0.9161\n",
      "Epoch 33/75\n",
      "486/486 [==============================] - 203s 419ms/step - loss: 0.2007 - accuracy: 0.9282\n",
      "Epoch 34/75\n",
      "486/486 [==============================] - 201s 414ms/step - loss: nan - accuracy: 0.4831\n",
      "Epoch 35/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: nan - accuracy: 0.3377\n",
      "Epoch 36/75\n",
      "486/486 [==============================] - 203s 417ms/step - loss: nan - accuracy: 0.3377\n",
      "Epoch 36: early stopping\n",
      "54/54 [==============================] - 3s 41ms/step - loss: nan - accuracy: 0.3293\n",
      "54/54 [==============================] - 2s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 212s 434ms/step - loss: 1.0298 - accuracy: 0.4779\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 212s 436ms/step - loss: 0.9416 - accuracy: 0.5616\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 212s 436ms/step - loss: 0.8851 - accuracy: 0.5968\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 211s 435ms/step - loss: 0.8562 - accuracy: 0.6196\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 220s 452ms/step - loss: nan - accuracy: 0.3501\n",
      "Epoch 6/75\n",
      "486/486 [==============================] - 215s 443ms/step - loss: nan - accuracy: 0.3399\n",
      "Epoch 7/75\n",
      "486/486 [==============================] - 216s 445ms/step - loss: nan - accuracy: 0.3399\n",
      "Epoch 7: early stopping\n",
      "54/54 [==============================] - 3s 40ms/step - loss: nan - accuracy: 0.3096\n",
      "54/54 [==============================] - 2s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 213s 435ms/step - loss: 1.0235 - accuracy: 0.4857\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 210s 433ms/step - loss: 0.9394 - accuracy: 0.5664\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 210s 433ms/step - loss: 0.8821 - accuracy: 0.6054\n",
      "Epoch 4/75\n",
      "486/486 [==============================] - 212s 436ms/step - loss: 0.8480 - accuracy: 0.6221\n",
      "Epoch 5/75\n",
      "486/486 [==============================] - 210s 433ms/step - loss: 0.8216 - accuracy: 0.6365\n",
      "Epoch 6/75\n",
      "486/486 [==============================] - 213s 438ms/step - loss: 0.7842 - accuracy: 0.6610\n",
      "Epoch 7/75\n",
      "486/486 [==============================] - 206s 425ms/step - loss: 0.7614 - accuracy: 0.6703\n",
      "Epoch 8/75\n",
      "486/486 [==============================] - 206s 423ms/step - loss: 0.7305 - accuracy: 0.6853\n",
      "Epoch 9/75\n",
      "486/486 [==============================] - 204s 421ms/step - loss: 0.7259 - accuracy: 0.6922\n",
      "Epoch 10/75\n",
      "486/486 [==============================] - 207s 426ms/step - loss: 0.6849 - accuracy: 0.7131\n",
      "Epoch 11/75\n",
      "486/486 [==============================] - 205s 421ms/step - loss: 0.6639 - accuracy: 0.7246\n",
      "Epoch 12/75\n",
      "486/486 [==============================] - 206s 424ms/step - loss: 0.6250 - accuracy: 0.7355\n",
      "Epoch 13/75\n",
      "486/486 [==============================] - 207s 426ms/step - loss: 0.6180 - accuracy: 0.7469\n",
      "Epoch 14/75\n",
      "486/486 [==============================] - 205s 423ms/step - loss: 0.5747 - accuracy: 0.7640\n",
      "Epoch 15/75\n",
      "486/486 [==============================] - 205s 423ms/step - loss: 0.5423 - accuracy: 0.7835\n",
      "Epoch 16/75\n",
      "486/486 [==============================] - 207s 425ms/step - loss: 0.5182 - accuracy: 0.7907\n",
      "Epoch 17/75\n",
      "486/486 [==============================] - 206s 425ms/step - loss: 0.4927 - accuracy: 0.8025\n",
      "Epoch 18/75\n",
      "486/486 [==============================] - 207s 427ms/step - loss: 0.5568 - accuracy: 0.7742\n",
      "Epoch 19/75\n",
      "486/486 [==============================] - 207s 425ms/step - loss: nan - accuracy: 0.5223\n",
      "Epoch 20/75\n",
      "486/486 [==============================] - 206s 424ms/step - loss: nan - accuracy: 0.3366\n",
      "Epoch 20: early stopping\n",
      "54/54 [==============================] - 2s 39ms/step - loss: nan - accuracy: 0.3391\n",
      "54/54 [==============================] - 2s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/75\n",
      "486/486 [==============================] - 204s 416ms/step - loss: 1.0293 - accuracy: 0.4784\n",
      "Epoch 2/75\n",
      "486/486 [==============================] - 202s 416ms/step - loss: 0.9536 - accuracy: 0.5539\n",
      "Epoch 3/75\n",
      "486/486 [==============================] - 198s 407ms/step - loss: 0.8903 - accuracy: 0.5976\n",
      "Epoch 4/75\n",
      "368/486 [=====================>........] - ETA: 50s - loss: 0.8522 - accuracy: 0.6231"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1,mcc,cohen_kappa=[],[],[],[],[],[]\n",
    "pat = 3\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    " \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    " \n",
    "    model = Sequential() #rnn\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(256,activation='relu',return_sequences= True))\n",
    "    model.add(SimpleRNN(128,activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy']) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=75,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    preds = model.predict(X_test)\n",
    "    y_true=y_test.argmax(axis=1)\n",
    "    y_pred=preds.argmax(axis=1)\n",
    "    \n",
    "    precision= precision_score(y_true, y_pred, average='weighted')\n",
    "    recall= recall_score(y_true, y_pred, average='weighted')\n",
    "    f1_measure = f1_score(y_true, y_pred, average='weighted')\n",
    "    mcc_score = matthews_corrcoef(y_true, y_pred)\n",
    "    c_kappa=cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_measure)\n",
    "    mcc.append(mcc_score)\n",
    "    cohen_kappa.append(c_kappa)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))\n",
    "print('test mcc: %f' % (Average(mcc)))\n",
    "print('test cohen_kappa: %f' % (Average(cohen_kappa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1,mcc,cohen_kappa=[],[],[],[],[],[]\n",
    "pat = 3\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "    \n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train]\n",
    "    y_train=targets[train]\n",
    "    X_test=inputs[test]\n",
    "    y_test=targets[test]\n",
    "\n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNN = Sequential() #cnn\n",
    "\n",
    "    modelCNN.add(embedding_layer)\n",
    "    modelCNN.add(Conv1D(filters=128, kernel_size=3, activation='relu')) #kernal size 5 yan yana beş kelimeye bakması\n",
    "    modelCNN.add(MaxPooling1D(pool_size=3)) #tek satırlık 1d olduğu için\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(64, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(16, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Flatten()) #düzgünleştirmek için\n",
    "    modelCNN.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "    modelCNN.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy']) #binary cross çünkü sonucun pozitif yada negatif\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNN.fit(X_train, y_train, epochs=75,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy = modelCNN.evaluate(X_test, y_test)\n",
    "    preds = modelCNN.predict(X_test)\n",
    "    y_true=y_test.argmax(axis=1)\n",
    "    y_pred=preds.argmax(axis=1)\n",
    "    \n",
    "    precision= precision_score(y_true, y_pred, average='weighted')\n",
    "    recall= recall_score(y_true, y_pred, average='weighted')\n",
    "    f1_measure = f1_score(y_true, y_pred, average='weighted')\n",
    "    mcc_score = matthews_corrcoef(y_true, y_pred)\n",
    "    c_kappa=cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_measure)\n",
    "    mcc.append(mcc_score)\n",
    "    cohen_kappa.append(c_kappa)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))\n",
    "print('test mcc: %f' % (Average(mcc)))\n",
    "print('test cohen_kappa: %f' % (Average(cohen_kappa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1,mcc,cohen_kappa=[],[],[],[],[],[]\n",
    "pat = 3\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "    \n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train]\n",
    "    y_train=targets[train]\n",
    "    X_test=inputs[test]\n",
    "    y_test=targets[test]\n",
    "\n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "\n",
    "    modelLSTM = Sequential()\n",
    "    modelLSTM.add(embedding_layer)\n",
    "    modelLSTM.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    modelLSTM.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "    modelLSTM.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy']) #binary cross çünkü sonucun pozitif yada negatif\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelLSTM.fit(X_train, y_train, epochs=75,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy = modelLSTM.evaluate(X_test, y_test)\n",
    "    preds = modelLSTM.predict(X_test)\n",
    "    y_true=y_test.argmax(axis=1)\n",
    "    y_pred=preds.argmax(axis=1)\n",
    "    \n",
    "    precision= precision_score(y_true, y_pred, average='weighted')\n",
    "    recall= recall_score(y_true, y_pred, average='weighted')\n",
    "    f1_measure = f1_score(y_true, y_pred, average='weighted')\n",
    "    mcc_score = matthews_corrcoef(y_true, y_pred)\n",
    "    c_kappa=cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_measure)\n",
    "    mcc.append(mcc_score)\n",
    "    cohen_kappa.append(c_kappa)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))\n",
    "print('test mcc: %f' % (Average(mcc)))\n",
    "print('test cohen_kappa: %f' % (Average(cohen_kappa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn+lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1,mcc,cohen_kappa=[],[],[],[],[],[]\n",
    "pat = 3\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "    \n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train]\n",
    "    y_train=targets[train]\n",
    "    X_test=inputs[test]\n",
    "    y_test=targets[test]\n",
    "\n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "\n",
    "    modelCNNLSTM = Sequential() #cnn\n",
    "\n",
    "    modelCNNLSTM.add(embedding_layer)\n",
    "    modelCNNLSTM.add(Conv1D(filters=128, kernel_size=3, activation='relu')) #kernal size 5 yan yana beş kelimeye bakması\n",
    "    modelCNNLSTM.add(MaxPooling1D(pool_size=3)) #tek satırlık 1d olduğu için\n",
    "    modelCNNLSTM.add(Dropout(0.3))\n",
    "    modelCNNLSTM.add(Dense(64, activation='relu'))\n",
    "    modelCNNLSTM.add(Dropout(0.3))\n",
    "    modelCNNLSTM.add(Dense(16, activation='relu'))\n",
    "    modelCNNLSTM.add(Dropout(0.3))\n",
    "    modelCNNLSTM.add(LSTM(128))\n",
    "    modelCNNLSTM.add(Flatten()) #düzgünleştirmek için\n",
    "    modelCNNLSTM.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "    modelCNNLSTM.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy']) #binary cross çünkü sonucun pozitif yada negatif\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNNLSTM.fit(X_train, y_train, epochs=75,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy = modelCNNLSTM.evaluate(X_test, y_test)\n",
    "    preds = modelCNNLSTM.predict(X_test)\n",
    "    y_true=y_test.argmax(axis=1)\n",
    "    y_pred=preds.argmax(axis=1)\n",
    "    \n",
    "    precision= precision_score(y_true, y_pred, average='weighted')\n",
    "    recall= recall_score(y_true, y_pred, average='weighted')\n",
    "    f1_measure = f1_score(y_true, y_pred, average='weighted')\n",
    "    mcc_score = matthews_corrcoef(y_true, y_pred)\n",
    "    c_kappa=cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_measure)\n",
    "    mcc.append(mcc_score)\n",
    "    cohen_kappa.append(c_kappa)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))\n",
    "print('test mcc: %f' % (Average(mcc)))\n",
    "print('test cohen_kappa: %f' % (Average(cohen_kappa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
