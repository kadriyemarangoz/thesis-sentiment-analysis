{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beni bugun de unutmayip mesaj attigin icin tes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i̇yi ki kontr aldım... dün geceden beri aynı a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turkcell 1tl min ustune yatip 50mb verdi hepsi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>canini yedigimin turkcell i sende olmasan bizi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>halkın takımı oldugunu iddia eden 8taş turkcel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>turkcell kalitesi diye bişey var</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>bugun de turkcell ile skinti yasayarak basladi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>zaten turkcell'e çalışıyoruz aq ?????????? @ g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>vodafone'a geçmeyeyim diye turkcell üzerime he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell eskiden sadece mesaj atardi, şimdi ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     beni bugun de unutmayip mesaj attigin icin tes...     1\n",
       "1     i̇yi ki kontr aldım... dün geceden beri aynı a...     0\n",
       "2     turkcell 1tl min ustune yatip 50mb verdi hepsi...     0\n",
       "3     canini yedigimin turkcell i sende olmasan bizi...     1\n",
       "4     halkın takımı oldugunu iddia eden 8taş turkcel...     0\n",
       "...                                                 ...   ...\n",
       "9121                   turkcell kalitesi diye bişey var     1\n",
       "9122  bugun de turkcell ile skinti yasayarak basladi...     0\n",
       "9123  zaten turkcell'e çalışıyoruz aq ?????????? @ g...     0\n",
       "9124  vodafone'a geçmeyeyim diye turkcell üzerime he...     1\n",
       "9125  turkcell eskiden sadece mesaj atardi, şimdi ar...     0\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load my word embeddings\n",
    "#import gensim\n",
    "#wordembeddings = gensim.models.KeyedVectors.load_word2vec_format('drive/My Drive/CNNPhraseEmbeddings/Resources/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "wordembeddings = fasttext.load_model('D:/Desktop/İndirilenler yedek/cc.tr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext (X_train,y_train,X_test,y_test):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)):\n",
    "        numberofwords=len(sequences_X_train[review_number])\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length)\n",
    "    y_train = np.asarray(y_train)\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "    unique_words = len(word_index)\n",
    "    total_words = unique_words + 1\n",
    "    skipped_words = 0\n",
    "    embedding_dim = 300\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        try:\n",
    "            embedding_vector = wordembeddings[word]\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "      \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "\n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.5729 - acc: 0.6966 - precision: 0.7087 - recall: 0.6662\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4473 - acc: 0.8017 - precision: 0.8232 - recall: 0.7676\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3945 - acc: 0.8258 - precision: 0.8387 - recall: 0.8061\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.3418 - acc: 0.8555 - precision: 0.8657 - recall: 0.8410\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3060 - acc: 0.8773 - precision: 0.8898 - recall: 0.8608\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2521 - acc: 0.8977 - precision: 0.9075 - recall: 0.8854\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.2047 - acc: 0.9176 - precision: 0.9217 - recall: 0.9125\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1671 - acc: 0.9369 - precision: 0.9390 - recall: 0.9344\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.1403 - acc: 0.9475 - precision: 0.9495 - recall: 0.9451\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1130 - acc: 0.9579 - precision: 0.9576 - recall: 0.9581\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1007 - acc: 0.9631 - precision: 0.9623 - recall: 0.9639\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0697 - acc: 0.9765 - precision: 0.9759 - recall: 0.9771\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0546 - acc: 0.9826 - precision: 0.9820 - recall: 0.9832\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0684 - acc: 0.9760 - precision: 0.9747 - recall: 0.9773\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0843 - acc: 0.9721 - precision: 0.9729 - recall: 0.9712\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0489 - acc: 0.9828 - precision: 0.9843 - recall: 0.9812\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0408 - acc: 0.9871 - precision: 0.9873 - recall: 0.9868\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0300 - acc: 0.9905 - precision: 0.9910 - recall: 0.9900\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0401 - acc: 0.9871 - precision: 0.9868 - recall: 0.9873\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0251 - acc: 0.9917 - precision: 0.9922 - recall: 0.9912\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0462 - acc: 0.9842 - precision: 0.9834 - recall: 0.9849\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0390 - acc: 0.9869 - precision: 0.9861 - recall: 0.9876\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0282 - acc: 0.9910 - precision: 0.9910 - recall: 0.99100s - loss: 0.0286 - acc: 0.9909 - precision:\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0202 - acc: 0.9943 - precision: 0.9949 - recall: 0.9937\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0266 - acc: 0.9920 - precision: 0.9924 - recall: 0.9915\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0312 - acc: 0.9922 - precision: 0.9917 - recall: 0.9927\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0326 - acc: 0.9883 - precision: 0.9878 - recall: 0.9888\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0193 - acc: 0.9954 - precision: 0.9954 - recall: 0.9954\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0204 - acc: 0.9925 - precision: 0.9924 - recall: 0.9924\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0446 - acc: 0.9858 - precision: 0.9861 - recall: 0.9854\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0599 - acc: 0.9786 - precision: 0.9790 - recall: 0.9781\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0344 - acc: 0.9873 - precision: 0.9880 - recall: 0.9866\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0301 - acc: 0.9916 - precision: 0.9903 - recall: 0.9929\n",
      "Epoch 00033: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0632 - acc: 0.7985 - precision: 0.7704 - recall: 0.8571\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.5600 - acc: 0.7074 - precision_1: 0.7138 - recall_1: 0.6899\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.4451 - acc: 0.8007 - precision_1: 0.8101 - recall_1: 0.7842\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4004 - acc: 0.8237 - precision_1: 0.8354 - recall_1: 0.8052\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3425 - acc: 0.8572 - precision_1: 0.8664 - recall_1: 0.8438\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3024 - acc: 0.8742 - precision_1: 0.8837 - recall_1: 0.8611\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2482 - acc: 0.9006 - precision_1: 0.9096 - recall_1: 0.8892\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2160 - acc: 0.9129 - precision_1: 0.9138 - recall_1: 0.9114\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1730 - acc: 0.9296 - precision_1: 0.9333 - recall_1: 0.9250\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1408 - acc: 0.9461 - precision_1: 0.9456 - recall_1: 0.9463\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1071 - acc: 0.9601 - precision_1: 0.9593 - recall_1: 0.9607\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0950 - acc: 0.9657 - precision_1: 0.9674 - recall_1: 0.9636\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0846 - acc: 0.9692 - precision_1: 0.9683 - recall_1: 0.9700\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0614 - acc: 0.9794 - precision_1: 0.9795 - recall_1: 0.9792\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0674 - acc: 0.9767 - precision_1: 0.9754 - recall_1: 0.9780\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0658 - acc: 0.9776 - precision_1: 0.9778 - recall_1: 0.9773\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0682 - acc: 0.9759 - precision_1: 0.9754 - recall_1: 0.9763\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0404 - acc: 0.9848 - precision_1: 0.9849 - recall_1: 0.9846\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0255 - acc: 0.9926 - precision_1: 0.9934 - recall_1: 0.9917\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0350 - acc: 0.9895 - precision_1: 0.9885 - recall_1: 0.99051s - loss: 0.0312 - \n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0665 - acc: 0.9764 - precision_1: 0.9777 - recall_1: 0.9749\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0460 - acc: 0.9862 - precision_1: 0.9866 - recall_1: 0.9858\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0252 - acc: 0.9915 - precision_1: 0.9929 - recall_1: 0.9900\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0241 - acc: 0.9916 - precision_1: 0.9927 - recall_1: 0.9905\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0313 - acc: 0.9898 - precision_1: 0.9905 - recall_1: 0.9890\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0418 - acc: 0.9871 - precision_1: 0.9887 - recall_1: 0.9854\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0401 - acc: 0.9873 - precision_1: 0.9878 - recall_1: 0.9868\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0283 - acc: 0.9918 - precision_1: 0.9919 - recall_1: 0.9917\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0492 - acc: 0.9845 - precision_1: 0.9858 - recall_1: 0.9832\n",
      "Epoch 00028: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9810 - acc: 0.7952 - precision_1: 0.7869 - recall_1: 0.8223\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5492 - acc: 0.7285 - precision_2: 0.7467 - recall_2: 0.6929\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4487 - acc: 0.7993 - precision_2: 0.8119 - recall_2: 0.7800\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.3933 - acc: 0.8284 - precision_2: 0.8385 - recall_2: 0.8142\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3459 - acc: 0.8574 - precision_2: 0.8661 - recall_2: 0.8461\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2969 - acc: 0.8776 - precision_2: 0.8893 - recall_2: 0.8631\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2550 - acc: 0.8992 - precision_2: 0.9047 - recall_2: 0.8928\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.1973 - acc: 0.9233 - precision_2: 0.9288 - recall_2: 0.9171\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1563 - acc: 0.9373 - precision_2: 0.9375 - recall_2: 0.9373\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1323 - acc: 0.9503 - precision_2: 0.9508 - recall_2: 0.9499\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1125 - acc: 0.9575 - precision_2: 0.9579 - recall_2: 0.9572\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0757 - acc: 0.9748 - precision_2: 0.9747 - recall_2: 0.9750\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0715 - acc: 0.9766 - precision_2: 0.9760 - recall_2: 0.9774\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0849 - acc: 0.9720 - precision_2: 0.9723 - recall_2: 0.9718\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0635 - acc: 0.9788 - precision_2: 0.9795 - recall_2: 0.9781\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0535 - acc: 0.9843 - precision_2: 0.9842 - recall_2: 0.9844\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0459 - acc: 0.9844 - precision_2: 0.9854 - recall_2: 0.9835\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0522 - acc: 0.9820 - precision_2: 0.9813 - recall_2: 0.9827\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0414 - acc: 0.9864 - precision_2: 0.9871 - recall_2: 0.9857\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0308 - acc: 0.9915 - precision_2: 0.9910 - recall_2: 0.9920\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0499 - acc: 0.9840 - precision_2: 0.9842 - recall_2: 0.9840\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0545 - acc: 0.9825 - precision_2: 0.9841 - recall_2: 0.9808\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0415 - acc: 0.9873 - precision_2: 0.9871 - recall_2: 0.9876\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0292 - acc: 0.9909 - precision_2: 0.9910 - recall_2: 0.9908\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0251 - acc: 0.9921 - precision_2: 0.9915 - recall_2: 0.9927\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0329 - acc: 0.9898 - precision_2: 0.9903 - recall_2: 0.9893\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0277 - acc: 0.9916 - precision_2: 0.9908 - recall_2: 0.9925\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0284 - acc: 0.9918 - precision_2: 0.9927 - recall_2: 0.9910\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0367 - acc: 0.9872 - precision_2: 0.9876 - recall_2: 0.9869\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0316 - acc: 0.9904 - precision_2: 0.9908 - recall_2: 0.9900\n",
      "Epoch 00029: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9532 - acc: 0.8039 - precision_2: 0.8031 - recall_2: 0.7978\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.5623 - acc: 0.7111 - precision_3: 0.7264 - recall_3: 0.6729\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4434 - acc: 0.8009 - precision_3: 0.8197 - recall_3: 0.7693\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3781 - acc: 0.8357 - precision_3: 0.8540 - recall_3: 0.8082\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3359 - acc: 0.8573 - precision_3: 0.8699 - recall_3: 0.8388\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2883 - acc: 0.8806 - precision_3: 0.8922 - recall_3: 0.8645\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2373 - acc: 0.9031 - precision_3: 0.9127 - recall_3: 0.8904\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1947 - acc: 0.9223 - precision_3: 0.9287 - recall_3: 0.9141\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1602 - acc: 0.9358 - precision_3: 0.9371 - recall_3: 0.9337\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1232 - acc: 0.9543 - precision_3: 0.9569 - recall_3: 0.9511\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1075 - acc: 0.9585 - precision_3: 0.9580 - recall_3: 0.9587\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0988 - acc: 0.9631 - precision_3: 0.9637 - recall_3: 0.9621\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0678 - acc: 0.9778 - precision_3: 0.9777 - recall_3: 0.9777\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0608 - acc: 0.9783 - precision_3: 0.9780 - recall_3: 0.9785\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0570 - acc: 0.9817 - precision_3: 0.9835 - recall_3: 0.9797\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0603 - acc: 0.9788 - precision_3: 0.9794 - recall_3: 0.9780\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0497 - acc: 0.9839 - precision_3: 0.9850 - recall_3: 0.9826\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0324 - acc: 0.9897 - precision_3: 0.9900 - recall_3: 0.9892\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0629 - acc: 0.9799 - precision_3: 0.9785 - recall_3: 0.9812\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0533 - acc: 0.9823 - precision_3: 0.9833 - recall_3: 0.9812\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0321 - acc: 0.9894 - precision_3: 0.9916 - recall_3: 0.9870\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0554 - acc: 0.9805 - precision_3: 0.9814 - recall_3: 0.9795\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0467 - acc: 0.9843 - precision_3: 0.9846 - recall_3: 0.9839\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0318 - acc: 0.9909 - precision_3: 0.9900 - recall_3: 0.9917\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0121 - acc: 0.9966 - precision_3: 0.9963 - recall_3: 0.9968\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0238 - acc: 0.9918 - precision_3: 0.9936 - recall_3: 0.9900\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0300 - acc: 0.9904 - precision_3: 0.9895 - recall_3: 0.9912\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0554 - acc: 0.9833 - precision_3: 0.9838 - recall_3: 0.9826\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0278 - acc: 0.9910 - precision_3: 0.9912 - recall_3: 0.9907\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0369 - acc: 0.9875 - precision_3: 0.9870 - recall_3: 0.9878\n",
      "Epoch 00029: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1233 - acc: 0.7722 - precision_3: 0.7908 - recall_3: 0.7642\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5697 - acc: 0.7036 - precision_4: 0.7234 - recall_4: 0.6657\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4441 - acc: 0.8014 - precision_4: 0.8205 - recall_4: 0.7750\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3913 - acc: 0.8269 - precision_4: 0.8416 - recall_4: 0.8082\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.3573 - acc: 0.8461 - precision_4: 0.8564 - recall_4: 0.8341\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2983 - acc: 0.8763 - precision_4: 0.8855 - recall_4: 0.8662\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2661 - acc: 0.8911 - precision_4: 0.9006 - recall_4: 0.8810\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2085 - acc: 0.9154 - precision_4: 0.9228 - recall_4: 0.9078\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1605 - acc: 0.9385 - precision_4: 0.9448 - recall_4: 0.9323\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1261 - acc: 0.9541 - precision_4: 0.9534 - recall_4: 0.9555\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1049 - acc: 0.9623 - precision_4: 0.9632 - recall_4: 0.9618\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0864 - acc: 0.9672 - precision_4: 0.9647 - recall_4: 0.9705\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0832 - acc: 0.9719 - precision_4: 0.9738 - recall_4: 0.9702\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0668 - acc: 0.9765 - precision_4: 0.9779 - recall_4: 0.9753\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0681 - acc: 0.9761 - precision_4: 0.9768 - recall_4: 0.9758\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0617 - acc: 0.9808 - precision_4: 0.9821 - recall_4: 0.9797\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0375 - acc: 0.9887 - precision_4: 0.9886 - recall_4: 0.9889\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0700 - acc: 0.9759 - precision_4: 0.9749 - recall_4: 0.9773\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0398 - acc: 0.9881 - precision_4: 0.9874 - recall_4: 0.9889\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0385 - acc: 0.9886 - precision_4: 0.9886 - recall_4: 0.9886\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0306 - acc: 0.9890 - precision_4: 0.9886 - recall_4: 0.9896\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0475 - acc: 0.9828 - precision_4: 0.9826 - recall_4: 0.9833\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0341 - acc: 0.9886 - precision_4: 0.9882 - recall_4: 0.9891\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0285 - acc: 0.9915 - precision_4: 0.9908 - recall_4: 0.9923\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0320 - acc: 0.9906 - precision_4: 0.9903 - recall_4: 0.9910\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0146 - acc: 0.9961 - precision_4: 0.9961 - recall_4: 0.9961\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0395 - acc: 0.9879 - precision_4: 0.9865 - recall_4: 0.9896\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0503 - acc: 0.9847 - precision_4: 0.9841 - recall_4: 0.9855\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0228 - acc: 0.9927 - precision_4: 0.9927 - recall_4: 0.9927\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0161 - acc: 0.9954 - precision_4: 0.9954 - recall_4: 0.9954\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0402 - acc: 0.9865 - precision_4: 0.9865 - recall_4: 0.9867\n",
      "Epoch 00030: early stopping\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.8859 - acc: 0.8028 - precision_4: 0.7701 - recall_4: 0.8275\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5572 - acc: 0.7167 - precision_5: 0.7348 - recall_5: 0.6758\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.4378 - acc: 0.8049 - precision_5: 0.8132 - recall_5: 0.7905\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3826 - acc: 0.8353 - precision_5: 0.8442 - recall_5: 0.8213\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3279 - acc: 0.8647 - precision_5: 0.8730 - recall_5: 0.8528\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2858 - acc: 0.8818 - precision_5: 0.8933 - recall_5: 0.8665\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2548 - acc: 0.8992 - precision_5: 0.9081 - recall_5: 0.8877\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2149 - acc: 0.9149 - precision_5: 0.9207 - recall_5: 0.9075\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1650 - acc: 0.9379 - precision_5: 0.9408 - recall_5: 0.9343\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1264 - acc: 0.9512 - precision_5: 0.9507 - recall_5: 0.9514\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1131 - acc: 0.9576 - precision_5: 0.9580 - recall_5: 0.9570\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1067 - acc: 0.9602 - precision_5: 0.9615 - recall_5: 0.9585\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0776 - acc: 0.9743 - precision_5: 0.9741 - recall_5: 0.9744\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0584 - acc: 0.9800 - precision_5: 0.9800 - recall_5: 0.9800\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0440 - acc: 0.9851 - precision_5: 0.9858 - recall_5: 0.9844\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0569 - acc: 0.9797 - precision_5: 0.9788 - recall_5: 0.9805\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0597 - acc: 0.9811 - precision_5: 0.9828 - recall_5: 0.9792\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0464 - acc: 0.9844 - precision_5: 0.9853 - recall_5: 0.9834\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0472 - acc: 0.9854 - precision_5: 0.9851 - recall_5: 0.9856\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0451 - acc: 0.9858 - precision_5: 0.9861 - recall_5: 0.9854\n",
      "Epoch 00019: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9311 - acc: 0.7809 - precision_5: 0.7533 - recall_5: 0.8501\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.5644 - acc: 0.7180 - precision_6: 0.7304 - recall_6: 0.6920\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4418 - acc: 0.8016 - precision_6: 0.8164 - recall_6: 0.7786\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3914 - acc: 0.8318 - precision_6: 0.8428 - recall_6: 0.8161\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3432 - acc: 0.8557 - precision_6: 0.8602 - recall_6: 0.8499\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2977 - acc: 0.8770 - precision_6: 0.8885 - recall_6: 0.8626\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2483 - acc: 0.9005 - precision_6: 0.9027 - recall_6: 0.8981\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2086 - acc: 0.9200 - precision_6: 0.9247 - recall_6: 0.9146\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1611 - acc: 0.9385 - precision_6: 0.9428 - recall_6: 0.9338\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1555 - acc: 0.9391 - precision_6: 0.9418 - recall_6: 0.9363\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1050 - acc: 0.9603 - precision_6: 0.9617 - recall_6: 0.9589\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1073 - acc: 0.9610 - precision_6: 0.9633 - recall_6: 0.9586\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0613 - acc: 0.9778 - precision_6: 0.9774 - recall_6: 0.9784\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0805 - acc: 0.9719 - precision_6: 0.9732 - recall_6: 0.9706\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0672 - acc: 0.9771 - precision_6: 0.9771 - recall_6: 0.9771\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0566 - acc: 0.9811 - precision_6: 0.9806 - recall_6: 0.9818\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0594 - acc: 0.9795 - precision_6: 0.9786 - recall_6: 0.9805\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0423 - acc: 0.9870 - precision_6: 0.9866 - recall_6: 0.9874\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0659 - acc: 0.9778 - precision_6: 0.9769 - recall_6: 0.9788\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0394 - acc: 0.9870 - precision_6: 0.9892 - recall_6: 0.9847\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0404 - acc: 0.9872 - precision_6: 0.9881 - recall_6: 0.9864\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0321 - acc: 0.9914 - precision_6: 0.9922 - recall_6: 0.9905\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0436 - acc: 0.9862 - precision_6: 0.9845 - recall_6: 0.9881\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0374 - acc: 0.9866 - precision_6: 0.9861 - recall_6: 0.9871\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0279 - acc: 0.9905 - precision_6: 0.9905 - recall_6: 0.9905\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0152 - acc: 0.9956 - precision_6: 0.9956 - recall_6: 0.99561s - loss: 0.0163 \n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0212 - acc: 0.9925 - precision_6: 0.9925 - recall_6: 0.9925\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0598 - acc: 0.9795 - precision_6: 0.9812 - recall_6: 0.9779\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0395 - acc: 0.9873 - precision_6: 0.9881 - recall_6: 0.9866\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0234 - acc: 0.9935 - precision_6: 0.9927 - recall_6: 0.9944\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0400 - acc: 0.9873 - precision_6: 0.9888 - recall_6: 0.9859\n",
      "Epoch 00030: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1854 - acc: 0.7697 - precision_6: 0.7336 - recall_6: 0.8407\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.5591 - acc: 0.7143 - precision_7: 0.7367 - recall_7: 0.6704\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.4460 - acc: 0.7990 - precision_7: 0.8176 - recall_7: 0.7718\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3926 - acc: 0.8279 - precision_7: 0.8430 - recall_7: 0.8074\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3579 - acc: 0.8493 - precision_7: 0.8651 - recall_7: 0.8290\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3086 - acc: 0.8751 - precision_7: 0.8853 - recall_7: 0.8630\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2706 - acc: 0.8867 - precision_7: 0.8919 - recall_7: 0.8809\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2210 - acc: 0.9126 - precision_7: 0.9188 - recall_7: 0.9059\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1850 - acc: 0.9294 - precision_7: 0.9330 - recall_7: 0.9258\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1409 - acc: 0.9459 - precision_7: 0.9475 - recall_7: 0.9447\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1250 - acc: 0.9515 - precision_7: 0.9537 - recall_7: 0.9496\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0944 - acc: 0.9645 - precision_7: 0.9669 - recall_7: 0.9622\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0780 - acc: 0.9727 - precision_7: 0.9747 - recall_7: 0.9709\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0704 - acc: 0.9746 - precision_7: 0.9759 - recall_7: 0.9733\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0524 - acc: 0.9836 - precision_7: 0.9826 - recall_7: 0.9847\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0629 - acc: 0.9783 - precision_7: 0.9789 - recall_7: 0.9779\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0560 - acc: 0.9821 - precision_7: 0.9818 - recall_7: 0.9825\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0481 - acc: 0.9855 - precision_7: 0.9857 - recall_7: 0.9854\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0340 - acc: 0.9897 - precision_7: 0.9896 - recall_7: 0.9898\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0454 - acc: 0.9856 - precision_7: 0.9857 - recall_7: 0.9857\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0419 - acc: 0.9878 - precision_7: 0.9886 - recall_7: 0.9871\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0445 - acc: 0.9849 - precision_7: 0.9852 - recall_7: 0.9847\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0245 - acc: 0.9934 - precision_7: 0.9930 - recall_7: 0.9939\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0202 - acc: 0.9939 - precision_7: 0.9935 - recall_7: 0.9944\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0558 - acc: 0.9811 - precision_7: 0.9823 - recall_7: 0.98012s - l\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0555 - acc: 0.9830 - precision_7: 0.9826 - recall_7: 0.9835\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0267 - acc: 0.9915 - precision_7: 0.9913 - recall_7: 0.9918\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0315 - acc: 0.9892 - precision_7: 0.9893 - recall_7: 0.9891\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0285 - acc: 0.9906 - precision_7: 0.9915 - recall_7: 0.9898\n",
      "Epoch 00028: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9521 - acc: 0.7982 - precision_7: 0.7540 - recall_7: 0.8636\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5505 - acc: 0.7204 - precision_8: 0.7253 - recall_8: 0.7100\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.4468 - acc: 0.7949 - precision_8: 0.8123 - recall_8: 0.7674\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3885 - acc: 0.8324 - precision_8: 0.8455 - recall_8: 0.8136\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3450 - acc: 0.8487 - precision_8: 0.8630 - recall_8: 0.8292\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2994 - acc: 0.8757 - precision_8: 0.8876 - recall_8: 0.8606\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2671 - acc: 0.8893 - precision_8: 0.8972 - recall_8: 0.8796\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2065 - acc: 0.9195 - precision_8: 0.9232 - recall_8: 0.9153\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1676 - acc: 0.9322 - precision_8: 0.9364 - recall_8: 0.9275\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1365 - acc: 0.9489 - precision_8: 0.9474 - recall_8: 0.9506\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1254 - acc: 0.9519 - precision_8: 0.9547 - recall_8: 0.9489\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0990 - acc: 0.9640 - precision_8: 0.9672 - recall_8: 0.9606\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0706 - acc: 0.9743 - precision_8: 0.9751 - recall_8: 0.9735\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0447 - acc: 0.9827 - precision_8: 0.9825 - recall_8: 0.9830\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0618 - acc: 0.9772 - precision_8: 0.9783 - recall_8: 0.9762\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0446 - acc: 0.9862 - precision_8: 0.9864 - recall_8: 0.9861\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0577 - acc: 0.9800 - precision_8: 0.9819 - recall_8: 0.9781\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0585 - acc: 0.9798 - precision_8: 0.9789 - recall_8: 0.9808\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0397 - acc: 0.9870 - precision_8: 0.9862 - recall_8: 0.9878\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0295 - acc: 0.9918 - precision_8: 0.9934 - recall_8: 0.9903\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0333 - acc: 0.9893 - precision_8: 0.9900 - recall_8: 0.9886\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0361 - acc: 0.9875 - precision_8: 0.9869 - recall_8: 0.9881\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0440 - acc: 0.9844 - precision_8: 0.9849 - recall_8: 0.9839\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0499 - acc: 0.9845 - precision_8: 0.9844 - recall_8: 0.9847\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0187 - acc: 0.9953 - precision_8: 0.9951 - recall_8: 0.9954\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0273 - acc: 0.9923 - precision_8: 0.9922 - recall_8: 0.9925\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0331 - acc: 0.9897 - precision_8: 0.9893 - recall_8: 0.9900\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0203 - acc: 0.9942 - precision_8: 0.9942 - recall_8: 0.9942\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0241 - acc: 0.9921 - precision_8: 0.9922 - recall_8: 0.9920\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0379 - acc: 0.9884 - precision_8: 0.9900 - recall_8: 0.9869\n",
      "Epoch 00029: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8345 - acc: 0.7741 - precision_8: 0.7398 - recall_8: 0.8411\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.5646 - acc: 0.7111 - precision_9: 0.7207 - recall_9: 0.6867\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.4441 - acc: 0.8023 - precision_9: 0.8187 - recall_9: 0.7751\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3959 - acc: 0.8280 - precision_9: 0.8417 - recall_9: 0.8066\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3443 - acc: 0.8535 - precision_9: 0.8620 - recall_9: 0.8408\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.2989 - acc: 0.8764 - precision_9: 0.8846 - recall_9: 0.8650\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.2597 - acc: 0.8935 - precision_9: 0.8981 - recall_9: 0.8869\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.2208 - acc: 0.9142 - precision_9: 0.9158 - recall_9: 0.9116\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1712 - acc: 0.9328 - precision_9: 0.9332 - recall_9: 0.9319\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1433 - acc: 0.9462 - precision_9: 0.9469 - recall_9: 0.9451\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1073 - acc: 0.9591 - precision_9: 0.9588 - recall_9: 0.9592\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0908 - acc: 0.9677 - precision_9: 0.9646 - recall_9: 0.9709\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0749 - acc: 0.9752 - precision_9: 0.9742 - recall_9: 0.9761\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0538 - acc: 0.9809 - precision_9: 0.9805 - recall_9: 0.9812\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0550 - acc: 0.9826 - precision_9: 0.9822 - recall_9: 0.9829\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0515 - acc: 0.9831 - precision_9: 0.9820 - recall_9: 0.9841\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0558 - acc: 0.9819 - precision_9: 0.9829 - recall_9: 0.9807\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0613 - acc: 0.9787 - precision_9: 0.9792 - recall_9: 0.9780\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0266 - acc: 0.9915 - precision_9: 0.9915 - recall_9: 0.9915\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0360 - acc: 0.9877 - precision_9: 0.9878 - recall_9: 0.9875\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0584 - acc: 0.9811 - precision_9: 0.9791 - recall_9: 0.9832\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0388 - acc: 0.9879 - precision_9: 0.9885 - recall_9: 0.9873\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0255 - acc: 0.9928 - precision_9: 0.9941 - recall_9: 0.9915\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0268 - acc: 0.9915 - precision_9: 0.9924 - recall_9: 0.9905\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0330 - acc: 0.9905 - precision_9: 0.9914 - recall_9: 0.9895\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0207 - acc: 0.9925 - precision_9: 0.9924 - recall_9: 0.9924\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0577 - acc: 0.9805 - precision_9: 0.9805 - recall_9: 0.9805\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0112 - acc: 0.9968 - precision_9: 0.9968 - recall_9: 0.9968\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0213 - acc: 0.9932 - precision_9: 0.9929 - recall_9: 0.9934\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0482 - acc: 0.9860 - precision_9: 0.9849 - recall_9: 0.9871\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0280 - acc: 0.9918 - precision_9: 0.9907 - recall_9: 0.9929\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0204 - acc: 0.9927 - precision_9: 0.9927 - recall_9: 0.9927\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0297 - acc: 0.9912 - precision_9: 0.9917 - recall_9: 0.9907\n",
      "Epoch 00032: early stopping\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 1.3184 - acc: 0.7489 - precision_9: 0.7357 - recall_9: 0.7970\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    pat = 5\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=1)\n",
    "    model = Sequential() #rnn\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(128,activation='relu',return_sequences= True))\n",
    "    model.add(SimpleRNN(256,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.784457\n",
      "test precision: 0.763775\n",
      "test recall: 0.826143\n",
      "test f1_score: 0.793087\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6352 - acc: 0.6302 - precision_10: 0.6370 - recall_10: 0.5938\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.5179 - acc: 0.7545 - precision_10: 0.7799 - recall_10: 0.7046\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4439 - acc: 0.7991 - precision_10: 0.8165 - recall_10: 0.7681\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3862 - acc: 0.8287 - precision_10: 0.8449 - recall_10: 0.8024\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3335 - acc: 0.8592 - precision_10: 0.8680 - recall_10: 0.8451\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2810 - acc: 0.8802 - precision_10: 0.8870 - recall_10: 0.8696\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2273 - acc: 0.9099 - precision_10: 0.9166 - recall_10: 0.9005\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1896 - acc: 0.9229 - precision_10: 0.9242 - recall_10: 0.92030s - loss: 0.1885 - acc: 0.9234 - precision_10: 0.9243 - recall_10: \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1661 - acc: 0.9345 - precision_10: 0.9366 - recall_10: 0.93111s - loss: 0.1677 - acc: 0.9343 - precision_ - ETA: 0s - loss: 0.1667 - acc: 0.9340 - precision_10: 0.9360 - recall_10\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1387 - acc: 0.9498 - precision_10: 0.9482 - recall_10: 0.9510\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1375 - acc: 0.9487 - precision_10: 0.9478 - recall_10: 0.9490\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1147 - acc: 0.9556 - precision_10: 0.9523 - recall_10: 0.9586\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1156 - acc: 0.9558 - precision_10: 0.9576 - recall_10: 0.9532\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0923 - acc: 0.9666 - precision_10: 0.9666 - recall_10: 0.96622s - los\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1005 - acc: 0.9671 - precision_10: 0.9687 - recall_10: 0.9649\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0799 - acc: 0.9711 - precision_10: 0.9708 - recall_10: 0.9711\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0745 - acc: 0.9727 - precision_10: 0.9709 - recall_10: 0.9743\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0716 - acc: 0.9735 - precision_10: 0.9747 - recall_10: 0.9718\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0620 - acc: 0.9777 - precision_10: 0.9758 - recall_10: 0.97940s - loss: 0.0622 - acc: 0.9776 - precision_10: 0.9755 - recall_10: \n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0807 - acc: 0.9718 - precision_10: 0.9718 - recall_10: 0.97132s - loss: 0.0809 - acc: 0.9723 - precision_10: 0.9716 - recall_ - ETA: 2s - loss: 0.080\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0662 - acc: 0.9756 - precision_10: 0.9767 - recall_10: 0.9743\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0772 - acc: 0.9727 - precision_10: 0.9737 - recall_10: 0.97130s - loss: 0.0775 - acc: 0.9721 - prec\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0669 - acc: 0.9777 - precision_10: 0.9777 - recall_10: 0.9774\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0492 - acc: 0.9833 - precision_10: 0.9814 - recall_10: 0.9850\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0627 - acc: 0.9765 - precision_10: 0.9748 - recall_10: 0.9779\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0587 - acc: 0.9786 - precision_10: 0.9770 - recall_10: 0.9799\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0544 - acc: 0.9809 - precision_10: 0.9809 - recall_10: 0.9806\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0612 - acc: 0.9777 - precision_10: 0.9765 - recall_10: 0.9787\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0511 - acc: 0.9820 - precision_10: 0.9826 - recall_10: 0.9811\n",
      "Epoch 00029: early stopping\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8826 - acc: 0.7612 - precision_10: 0.7618 - recall_10: 0.7996\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6221 - acc: 0.6496 - precision_11: 0.6475 - recall_11: 0.6774\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.5200 - acc: 0.7495 - precision_11: 0.7865 - recall_11: 0.6945\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4548 - acc: 0.7923 - precision_11: 0.8172 - recall_11: 0.7603\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4007 - acc: 0.8203 - precision_11: 0.8394 - recall_11: 0.7982\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3431 - acc: 0.8510 - precision_11: 0.8686 - recall_11: 0.8319\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2918 - acc: 0.8758 - precision_11: 0.8900 - recall_11: 0.8614\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2428 - acc: 0.9026 - precision_11: 0.9080 - recall_11: 0.8989\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.1963 - acc: 0.9220 - precision_11: 0.9256 - recall_11: 0.9200\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1725 - acc: 0.9325 - precision_11: 0.9353 - recall_11: 0.9313\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1493 - acc: 0.9433 - precision_11: 0.9477 - recall_11: 0.9399\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1367 - acc: 0.9472 - precision_11: 0.9462 - recall_11: 0.9498\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1158 - acc: 0.9569 - precision_11: 0.9562 - recall_11: 0.9589\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1133 - acc: 0.9560 - precision_11: 0.9563 - recall_11: 0.9570\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0951 - acc: 0.9641 - precision_11: 0.9631 - recall_11: 0.9661\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0871 - acc: 0.9665 - precision_11: 0.9664 - recall_11: 0.9676\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0869 - acc: 0.9681 - precision_11: 0.9654 - recall_11: 0.9719\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.0815 - acc: 0.9704 - precision_11: 0.9698 - recall_11: 0.9719\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0724 - acc: 0.9716 - precision_11: 0.9719 - recall_11: 0.9721\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0770 - acc: 0.9727 - precision_11: 0.9702 - recall_11: 0.9762\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0732 - acc: 0.9731 - precision_11: 0.9724 - recall_11: 0.9745\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0701 - acc: 0.9750 - precision_11: 0.9741 - recall_11: 0.9767\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0570 - acc: 0.9806 - precision_11: 0.9815 - recall_11: 0.9803\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0756 - acc: 0.9736 - precision_11: 0.9727 - recall_11: 0.9753\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0672 - acc: 0.9750 - precision_11: 0.9762 - recall_11: 0.9745\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0562 - acc: 0.9791 - precision_11: 0.9805 - recall_11: 0.9781\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0563 - acc: 0.9802 - precision_11: 0.9789 - recall_11: 0.9820\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0484 - acc: 0.9817 - precision_11: 0.9820 - recall_11: 0.9820\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0539 - acc: 0.9814 - precision_11: 0.9824 - recall_11: 0.9808\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0550 - acc: 0.9808 - precision_11: 0.9803 - recall_11: 0.9817\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0477 - acc: 0.9830 - precision_11: 0.9839 - recall_11: 0.9825\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0517 - acc: 0.9810 - precision_11: 0.9820 - recall_11: 0.9805\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0520 - acc: 0.9808 - precision_11: 0.9806 - recall_11: 0.9815\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0491 - acc: 0.9826 - precision_11: 0.9818 - recall_11: 0.9839\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0534 - acc: 0.9830 - precision_11: 0.9830 - recall_11: 0.9834\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0463 - acc: 0.9836 - precision_11: 0.9837 - recall_11: 0.9839\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0470 - acc: 0.9838 - precision_11: 0.9855 - recall_11: 0.98250s - loss: 0.0462 - acc: 0.9840 - precision_11: 0.9857 - recall_11\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0562 - acc: 0.9814 - precision_11: 0.9790 - recall_11: 0.9844\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0490 - acc: 0.9827 - precision_11: 0.9827 - recall_11: 0.9832\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0472 - acc: 0.9811 - precision_11: 0.9822 - recall_11: 0.9805\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0401 - acc: 0.9862 - precision_11: 0.9861 - recall_11: 0.9868\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0467 - acc: 0.9821 - precision_11: 0.9834 - recall_11: 0.9813\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.0443 - acc: 0.9850 - precision_11: 0.9851 - recall_11: 0.9853\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.0473 - acc: 0.9810 - precision_11: 0.9824 - recall_11: 0.9801\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0301 - acc: 0.9897 - precision_11: 0.9911 - recall_11: 0.9885\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0496 - acc: 0.9828 - precision_11: 0.9818 - recall_11: 0.9844\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0360 - acc: 0.9871 - precision_11: 0.9870 - recall_11: 0.9875\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0465 - acc: 0.9853 - precision_11: 0.9856 - recall_11: 0.9853\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0276 - acc: 0.9909 - precision_11: 0.9909 - recall_11: 0.9911\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0481 - acc: 0.9839 - precision_11: 0.9841 - recall_11: 0.9841\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0404 - acc: 0.9854 - precision_11: 0.9854 - recall_11: 0.9858\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1295 - acc: 0.7864 - precision_11: 0.7378 - recall_11: 0.7950\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.6480 - acc: 0.6156 - precision_12: 0.6078 - recall_12: 0.65242s - loss: 0.6652 - ac\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.5137 - acc: 0.7536 - precision_12: 0.7706 - recall_12: 0.7222\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4413 - acc: 0.8030 - precision_12: 0.8155 - recall_12: 0.7833\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.3907 - acc: 0.8271 - precision_12: 0.8352 - recall_12: 0.81 - 12s 46ms/step - loss: 0.3907 - acc: 0.8271 - precision_12: 0.8352 - recall_12: 0.8152\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.3321 - acc: 0.8535 - precision_12: 0.8607 - recall_12: 0.84372s - loss: 0.3\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2668 - acc: 0.8890 - precision_12: 0.8913 - recall_12: 0.88613s - loss: 0.2672 - acc: 0.8908 - precision_ - ETA: 2s - loss: 0.2675 - acc:\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.2319 - acc: 0.9037 - precision_12: 0.9068 - recall_12: 0.90002s -\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1927 - acc: 0.9224 - precision_12: 0.9261 - recall_12: 0.9182\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1718 - acc: 0.9297 - precision_12: 0.9303 - recall_12: 0.9292\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1483 - acc: 0.9399 - precision_12: 0.9394 - recall_12: 0.94043s - loss: 0.1402 - acc: 0.9455 - precision_12: 0.9472 - recal - ETA: 3s - loss: 0.1424 - acc: 0.9442 - precision_12: 0.94 - ETA: 2s - loss: 0.1475 - acc: 0.9418 - precision_12: 0.9425 - recall_12: 0.94 - ETA: 2s - loss: 0.1478 - ac\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1343 - acc: 0.9459 - precision_12: 0.9455 - recall_12: 0.94640s - loss: 0.1328 - acc: 0.9463 - precision_12: 0.9461 - recal\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1114 - acc: 0.9598 - precision_12: 0.9594 - recall_12: 0.9603\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1083 - acc: 0.9614 - precision_12: 0.9609 - recall_12: 0.9620\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0955 - acc: 0.9649 - precision_12: 0.9638 - recall_12: 0.9662\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0896 - acc: 0.9652 - precision_12: 0.9659 - recall_12: 0.9645\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0907 - acc: 0.9676 - precision_12: 0.9667 - recall_12: 0.9686\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0760 - acc: 0.9714 - precision_12: 0.9717 - recall_12: 0.9710\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0779 - acc: 0.9704 - precision_12: 0.9717 - recall_12: 0.96916s\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0792 - acc: 0.9709 - precision_12: 0.9697 - recall_12: 0.9722\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0619 - acc: 0.9775 - precision_12: 0.9767 - recall_12: 0.9783\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0649 - acc: 0.9772 - precision_12: 0.9776 - recall_12: 0.9769\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0767 - acc: 0.9753 - precision_12: 0.9738 - recall_12: 0.9769\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0567 - acc: 0.9787 - precision_12: 0.9788 - recall_12: 0.9786\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0575 - acc: 0.9803 - precision_12: 0.9800 - recall_12: 0.9805\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0606 - acc: 0.9784 - precision_12: 0.9772 - recall_12: 0.97988s - loss: 0.0537 \n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0557 - acc: 0.9810 - precision_12: 0.9794 - recall_12: 0.9827\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0577 - acc: 0.9803 - precision_12: 0.9815 - recall_12: 0.9791 - ETA: 0s - loss: 0.0571 - acc: 0.9802 - precision_12: 0.98\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0578 - acc: 0.9786 - precision_12: 0.9807 - recall_12: 0.9764\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0562 - acc: 0.9786 - precision_12: 0.9776 - recall_12: 0.9796\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0449 - acc: 0.9844 - precision_12: 0.9842 - recall_12: 0.9847\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0471 - acc: 0.9811 - precision_12: 0.9803 - recall_12: 0.9820\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0495 - acc: 0.9832 - precision_12: 0.9839 - recall_12: 0.9825\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0547 - acc: 0.9825 - precision_12: 0.9827 - recall_12: 0.9822\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0480 - acc: 0.9838 - precision_12: 0.9849 - recall_12: 0.9827\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0425 - acc: 0.9851 - precision_12: 0.9878 - recall_12: 0.98251s - loss: 0.0425 - acc: 0.9\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0470 - acc: 0.9814 - precision_12: 0.9813 - recall_12: 0.98151s - loss: 0.0463 - acc: 0.9812 - precision_12: 0.9811 - recall_12 - ETA: 1s - loss: 0.0472 - acc: 0.9810 - precision_12: 0.9806 - r - ETA: 0s - loss: 0.0460 - acc: 0.9815 - precision_12: 0.9810 - recal\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0487 - acc: 0.9828 - precision_12: 0.9846 - recall_12: 0.9810\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0478 - acc: 0.9815 - precision_12: 0.9824 - recall_12: 0.9805\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0521 - acc: 0.9826 - precision_12: 0.9827 - recall_12: 0.98251s - loss: 0.0537 - acc: 0.9823 - precis\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0501 - acc: 0.9831 - precision_12: 0.9839 - recall_12: 0.9822\n",
      "Epoch 00040: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0961 - acc: 0.7207 - precision_12: 0.7212 - recall_12: 0.7165\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.6628 - acc: 0.5939 - precision_13: 0.5980 - recall_13: 0.5651\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5223 - acc: 0.7520 - precision_13: 0.7599 - recall_13: 0.7344\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4490 - acc: 0.7991 - precision_13: 0.8076 - recall_13: 0.7835\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.3869 - acc: 0.8259 - precision_13: 0.8353 - recall_13: 0.81040s - loss: 0.3880 - acc: 0.8254 - precision_13: 0.8351 - recall_13\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.3384 - acc: 0.8528 - precision_13: 0.8587 - recall_13: 0.8434\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2874 - acc: 0.8752 - precision_13: 0.8795 - recall_13: 0.8686\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.2270 - acc: 0.9064 - precision_13: 0.9064 - recall_13: 0.9057\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1902 - acc: 0.9249 - precision_13: 0.9220 - recall_13: 0.92773s -\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1662 - acc: 0.9334 - precision_13: 0.9310 - recall_13: 0.93570s - loss: 0.1660 - acc: 0.9337 - precision_13: 0.9311 - recall_13: 0.\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1460 - acc: 0.9446 - precision_13: 0.9428 - recall_13: 0.9462\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1336 - acc: 0.9457 - precision_13: 0.9449 - recall_13: 0.9462\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1179 - acc: 0.9542 - precision_13: 0.9565 - recall_13: 0.95143s - loss: 0.1201 - acc: 0.9543 - precision_ - ETA: 2s - loss: 0.1186 - acc:\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0929 - acc: 0.9637 - precision_13: 0.9618 - recall_13: 0.9656\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0922 - acc: 0.9655 - precision_13: 0.9631 - recall_13: 0.9680\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0877 - acc: 0.9707 - precision_13: 0.9682 - recall_13: 0.97315s - loss: 0.0840 - acc: 0.973 - E\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0876 - acc: 0.9652 - precision_13: 0.9639 - recall_13: 0.96635s - loss: 0.0767 - acc: 0.9685 - prec\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0897 - acc: 0.9681 - precision_13: 0.9673 - recall_13: 0.9687\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0777 - acc: 0.9708 - precision_13: 0.9691 - recall_13: 0.9724\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0722 - acc: 0.9739 - precision_13: 0.9743 - recall_13: 0.9734\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0645 - acc: 0.9780 - precision_13: 0.9768 - recall_13: 0.97900s - loss: 0.0638 - acc: 0.9780 - precision_13: 0.9765 - recall_13\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0673 - acc: 0.9767 - precision_13: 0.9754 - recall_13: 0.9780\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0713 - acc: 0.9754 - precision_13: 0.9772 - recall_13: 0.9734\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0597 - acc: 0.9778 - precision_13: 0.9761 - recall_13: 0.97950s - loss: 0.0613 - acc: 0.9775 - precision_13: 0.\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0524 - acc: 0.9803 - precision_13: 0.9800 - recall_13: 0.9805\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0524 - acc: 0.9828 - precision_13: 0.9815 - recall_13: 0.9841\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0589 - acc: 0.9799 - precision_13: 0.9802 - recall_13: 0.9795\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0618 - acc: 0.9783 - precision_13: 0.9745 - recall_13: 0.9822\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0538 - acc: 0.9798 - precision_13: 0.9811 - recall_13: 0.9783\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0562 - acc: 0.9811 - precision_13: 0.9802 - recall_13: 0.98190s - loss: 0.0546 - acc: 0.9818 - precision_13: 0.9807 - recal\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0518 - acc: 0.9806 - precision_13: 0.9809 - recall_13: 0.9802\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0618 - acc: 0.9777 - precision_13: 0.9778 - recall_13: 0.97756s - loss: 0.0622 - acc: 0.979 - ETA: 4s - loss: 0.0659 - acc: 0.9773 - precision_13: 0.97\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0545 - acc: 0.9822 - precision_13: 0.9822 - recall_13: 0.9822\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0458 - acc: 0.9832 - precision_13: 0.9831 - recall_13: 0.98311s - loss: 0.0456 - acc: 0.9834 - \n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0570 - acc: 0.9821 - precision_13: 0.9838 - recall_13: 0.9802\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0458 - acc: 0.9840 - precision_13: 0.9827 - recall_13: 0.9853\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0386 - acc: 0.9864 - precision_13: 0.9847 - recall_13: 0.9880\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0448 - acc: 0.9861 - precision_13: 0.9873 - recall_13: 0.9849\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0393 - acc: 0.9858 - precision_13: 0.9844 - recall_13: 0.9871\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0504 - acc: 0.9826 - precision_13: 0.9826 - recall_13: 0.98242s - loss:\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0413 - acc: 0.9847 - precision_13: 0.9858 - recall_13: 0.9834\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0525 - acc: 0.9833 - precision_13: 0.9822 - recall_13: 0.9844\n",
      "Epoch 00041: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.6339 - acc: 0.7404 - precision_13: 0.7298 - recall_13: 0.7872\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.6212 - acc: 0.6426 - precision_14: 0.6403 - recall_14: 0.6569\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4952 - acc: 0.7707 - precision_14: 0.7856 - recall_14: 0.7469\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4341 - acc: 0.8094 - precision_14: 0.8132 - recall_14: 0.8051\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.3623 - acc: 0.8439 - precision_14: 0.8518 - recall_14: 0.8340\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.3110 - acc: 0.8631 - precision_14: 0.8685 - recall_14: 0.8571\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.2752 - acc: 0.8883 - precision_14: 0.8883 - recall_14: 0.8893\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.2180 - acc: 0.9120 - precision_14: 0.9106 - recall_14: 0.9143\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.1885 - acc: 0.9252 - precision_14: 0.9241 - recall_14: 0.9272\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.1615 - acc: 0.9355 - precision_14: 0.9342 - recall_14: 0.9374\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 13s 52ms/step - loss: 0.1413 - acc: 0.9452 - precision_14: 0.9448 - recall_14: 0.9461\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1329 - acc: 0.9511 - precision_14: 0.9521 - recall_14: 0.9503\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1026 - acc: 0.9590 - precision_14: 0.9577 - recall_14: 0.9607\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1040 - acc: 0.9593 - precision_14: 0.9581 - recall_14: 0.9609\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0966 - acc: 0.9641 - precision_14: 0.9636 - recall_14: 0.9648\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0952 - acc: 0.9615 - precision_14: 0.9599 - recall_14: 0.9636\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0867 - acc: 0.9680 - precision_14: 0.9680 - recall_14: 0.96820s - loss: 0.0863 - acc: 0.9681 - precision_14: 0.9672 - recall_\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0872 - acc: 0.9692 - precision_14: 0.9660 - recall_14: 0.9728\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0676 - acc: 0.9737 - precision_14: 0.9738 - recall_14: 0.9738\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0784 - acc: 0.9696 - precision_14: 0.9674 - recall_14: 0.97211s - loss: 0.0775 - acc: 0.9702 - precision_14:  - ETA: 0s - loss: 0.0788 - acc: 0.9694 - precision_14: 0.9677 - recal\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0675 - acc: 0.9763 - precision_14: 0.9762 - recall_14: 0.9765\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0707 - acc: 0.9738 - precision_14: 0.9731 - recall_14: 0.9748\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0714 - acc: 0.9746 - precision_14: 0.9722 - recall_14: 0.9772\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0708 - acc: 0.9756 - precision_14: 0.9741 - recall_14: 0.9774\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0714 - acc: 0.9736 - precision_14: 0.9740 - recall_14: 0.9733\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0532 - acc: 0.9805 - precision_14: 0.9794 - recall_14: 0.9818\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0549 - acc: 0.9810 - precision_14: 0.9790 - recall_14: 0.9833\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0561 - acc: 0.9771 - precision_14: 0.9760 - recall_14: 0.9784\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0533 - acc: 0.9784 - precision_14: 0.9773 - recall_14: 0.9799\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0516 - acc: 0.9776 - precision_14: 0.9758 - recall_14: 0.97960s - loss: 0.0521 - acc: 0.9774 - precision_14: 0.9756 - recall_14: \n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0591 - acc: 0.9783 - precision_14: 0.9768 - recall_14: 0.9801\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0551 - acc: 0.9799 - precision_14: 0.9803 - recall_14: 0.9796\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0565 - acc: 0.9798 - precision_14: 0.9792 - recall_14: 0.9806\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0413 - acc: 0.9839 - precision_14: 0.9837 - recall_14: 0.9842\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0574 - acc: 0.9817 - precision_14: 0.9811 - recall_14: 0.9825\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0477 - acc: 0.9823 - precision_14: 0.9837 - recall_14: 0.98111s - loss: 0.0475 - acc: 0.9822 - precision_14\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0400 - acc: 0.9855 - precision_14: 0.9838 - recall_14: 0.9874\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0440 - acc: 0.9843 - precision_14: 0.9833 - recall_14: 0.9854\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0485 - acc: 0.9849 - precision_14: 0.9840 - recall_14: 0.9859\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0476 - acc: 0.9848 - precision_14: 0.9845 - recall_14: 0.9852\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0469 - acc: 0.9840 - precision_14: 0.9852 - recall_14: 0.9830\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0494 - acc: 0.9811 - precision_14: 0.9808 - recall_14: 0.98161s - loss: 0.0481 - acc: 0.9820 \n",
      "Epoch 00041: early stopping\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.2688 - acc: 0.7612 - precision_14: 0.7557 - recall_14: 0.7489\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.6127 - acc: 0.6588 - precision_15: 0.6597 - recall_15: 0.6519\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4830 - acc: 0.7801 - precision_15: 0.7995 - recall_15: 0.7460\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4128 - acc: 0.8224 - precision_15: 0.8383 - recall_15: 0.7975\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.3517 - acc: 0.8473 - precision_15: 0.8586 - recall_15: 0.8305\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 47ms/step - loss: 0.2913 - acc: 0.8835 - precision_15: 0.8914 - recall_15: 0.8725\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.2449 - acc: 0.9022 - precision_15: 0.9096 - recall_15: 0.89251s - loss: 0.2452 - acc: 0.9031 \n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2001 - acc: 0.9239 - precision_15: 0.9261 - recall_15: 0.9209\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1609 - acc: 0.9369 - precision_15: 0.9355 - recall_15: 0.93828s - loss: 0 - ETA: 5s - loss: 0.1505 - acc: 0.9413 \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1410 - acc: 0.9472 - precision_15: 0.9483 - recall_15: 0.9455\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1316 - acc: 0.9486 - precision_15: 0.9507 - recall_15: 0.9460\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1170 - acc: 0.9545 - precision_15: 0.9561 - recall_15: 0.9524\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0950 - acc: 0.9670 - precision_15: 0.9677 - recall_15: 0.9660\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0766 - acc: 0.9719 - precision_15: 0.9726 - recall_15: 0.9709\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0891 - acc: 0.9668 - precision_15: 0.9672 - recall_15: 0.9660\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0712 - acc: 0.9749 - precision_15: 0.9744 - recall_15: 0.9753\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0828 - acc: 0.9731 - precision_15: 0.9734 - recall_15: 0.9726\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0658 - acc: 0.9727 - precision_15: 0.9717 - recall_15: 0.9736\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0655 - acc: 0.9771 - precision_15: 0.9770 - recall_15: 0.9770\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0688 - acc: 0.9766 - precision_15: 0.9752 - recall_15: 0.9780\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0691 - acc: 0.9776 - precision_15: 0.9778 - recall_15: 0.9773\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0606 - acc: 0.9789 - precision_15: 0.9788 - recall_15: 0.9790\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0581 - acc: 0.9794 - precision_15: 0.9774 - recall_15: 0.9814\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0555 - acc: 0.9825 - precision_15: 0.9831 - recall_15: 0.9817\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0452 - acc: 0.9859 - precision_15: 0.9851 - recall_15: 0.9866\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0491 - acc: 0.9832 - precision_15: 0.9855 - recall_15: 0.9807\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0582 - acc: 0.9812 - precision_15: 0.9826 - recall_15: 0.97972s - loss: 0.0571 - \n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0521 - acc: 0.9828 - precision_15: 0.9820 - recall_15: 0.9836\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0502 - acc: 0.9838 - precision_15: 0.9827 - recall_15: 0.9849\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0489 - acc: 0.9838 - precision_15: 0.9836 - recall_15: 0.9839\n",
      "Epoch 00029: early stopping\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8816 - acc: 0.7875 - precision_15: 0.7800 - recall_15: 0.8166\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6514 - acc: 0.6149 - precision_16: 0.6232 - recall_16: 0.5805\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.5357 - acc: 0.7414 - precision_16: 0.7844 - recall_16: 0.6655\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4619 - acc: 0.7882 - precision_16: 0.8199 - recall_16: 0.73842s - loss: 0.4599 - ac\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4032 - acc: 0.8223 - precision_16: 0.8411 - recall_16: 0.7944\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.3476 - acc: 0.8479 - precision_16: 0.8628 - recall_16: 0.8273\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2965 - acc: 0.8775 - precision_16: 0.8838 - recall_16: 0.8692\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.2432 - acc: 0.8949 - precision_16: 0.9030 - recall_16: 0.8848\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2039 - acc: 0.9188 - precision_16: 0.9274 - recall_16: 0.9086\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1714 - acc: 0.9315 - precision_16: 0.9349 - recall_16: 0.9274TA: 5s\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1651 - acc: 0.9357 - precision_16: 0.9406 - recall_16: 0.9301\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1341 - acc: 0.9489 - precision_16: 0.9495 - recall_16: 0.9481\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1172 - acc: 0.9574 - precision_16: 0.9587 - recall_16: 0.95591s - loss: 0.1168 - acc: 0.9572 - precision_\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1099 - acc: 0.9607 - precision_16: 0.9596 - recall_16: 0.9618\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1058 - acc: 0.9598 - precision_16: 0.9603 - recall_16: 0.9593\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0942 - acc: 0.9670 - precision_16: 0.9667 - recall_16: 0.96741s - loss: 0.0922 - acc: 0.9682 - precision_16: 0.\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0865 - acc: 0.9685 - precision_16: 0.9679 - recall_16: 0.96912s - loss: 0.0888 - acc: 0.9689 - pr - ETA: 0s - loss: 0.0869 - acc: 0.9690 - precision_16: 0.96\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0802 - acc: 0.9720 - precision_16: 0.9718 - recall_16: 0.9722\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0742 - acc: 0.9733 - precision_16: 0.9746 - recall_16: 0.9720\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0734 - acc: 0.9714 - precision_16: 0.9715 - recall_16: 0.97135s - loss: - ETA: 2s\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0740 - acc: 0.9730 - precision_16: 0.9748 - recall_16: 0.9710\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0723 - acc: 0.9763 - precision_16: 0.9764 - recall_16: 0.9761\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0590 - acc: 0.9789 - precision_16: 0.9770 - recall_16: 0.9810\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0611 - acc: 0.9770 - precision_16: 0.9764 - recall_16: 0.9776\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0677 - acc: 0.9774 - precision_16: 0.9769 - recall_16: 0.97781s - loss: 0.0723 - acc: 0.9\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0635 - acc: 0.9786 - precision_16: 0.9788 - recall_16: 0.9783\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0587 - acc: 0.9819 - precision_16: 0.9810 - recall_16: 0.9827\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0530 - acc: 0.9799 - precision_16: 0.9784 - recall_16: 0.9815\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0601 - acc: 0.9802 - precision_16: 0.9796 - recall_16: 0.9808\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0565 - acc: 0.9810 - precision_16: 0.9817 - recall_16: 0.9803\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0422 - acc: 0.9848 - precision_16: 0.9854 - recall_16: 0.9842\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0526 - acc: 0.9800 - precision_16: 0.9796 - recall_16: 0.9805\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0556 - acc: 0.9787 - precision_16: 0.9788 - recall_16: 0.9786\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0472 - acc: 0.9821 - precision_16: 0.9834 - recall_16: 0.9808\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0475 - acc: 0.9826 - precision_16: 0.9822 - recall_16: 0.9829\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0443 - acc: 0.9855 - precision_16: 0.9854 - recall_16: 0.9856\n",
      "Epoch 00035: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0569 - acc: 0.7599 - precision_16: 0.7965 - recall_16: 0.7009\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.6304 - acc: 0.6444 - precision_17: 0.6519 - recall_17: 0.6262\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.5024 - acc: 0.7605 - precision_17: 0.7794 - recall_17: 0.7297\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.4379 - acc: 0.8053 - precision_17: 0.8209 - recall_17: 0.7833\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3788 - acc: 0.8291 - precision_17: 0.8362 - recall_17: 0.8204\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.3218 - acc: 0.8651 - precision_17: 0.8726 - recall_17: 0.8565\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2691 - acc: 0.8860 - precision_17: 0.8869 - recall_17: 0.8861\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.2171 - acc: 0.9105 - precision_17: 0.9075 - recall_17: 0.9152\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1926 - acc: 0.9218 - precision_17: 0.9222 - recall_17: 0.9222\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1796 - acc: 0.9290 - precision_17: 0.9280 - recall_17: 0.9309\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.1337 - acc: 0.9480 - precision_17: 0.9490 - recall_17: 0.9474\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1307 - acc: 0.9508 - precision_17: 0.9489 - recall_17: 0.9535\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1059 - acc: 0.9604 - precision_17: 0.9594 - recall_17: 0.9619\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0967 - acc: 0.9620 - precision_17: 0.9638 - recall_17: 0.9605\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0917 - acc: 0.9653 - precision_17: 0.9647 - recall_17: 0.9663\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0917 - acc: 0.9665 - precision_17: 0.9641 - recall_17: 0.9695\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0754 - acc: 0.9725 - precision_17: 0.9703 - recall_17: 0.9750\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0919 - acc: 0.9668 - precision_17: 0.9654 - recall_17: 0.9685\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0754 - acc: 0.9713 - precision_17: 0.9707 - recall_17: 0.9721\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0831 - acc: 0.9710 - precision_17: 0.9728 - recall_17: 0.9695\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0656 - acc: 0.9767 - precision_17: 0.9784 - recall_17: 0.9753\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0618 - acc: 0.9783 - precision_17: 0.9791 - recall_17: 0.9777\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0619 - acc: 0.9795 - precision_17: 0.9785 - recall_17: 0.98085s - loss: 0.0\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0586 - acc: 0.9791 - precision_17: 0.9789 - recall_17: 0.9794\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0584 - acc: 0.9781 - precision_17: 0.9786 - recall_17: 0.9777\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0684 - acc: 0.9780 - precision_17: 0.9763 - recall_17: 0.97992s - loss: 0\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0547 - acc: 0.9802 - precision_17: 0.9799 - recall_17: 0.9806\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0582 - acc: 0.9777 - precision_17: 0.9793 - recall_17: 0.9762\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0467 - acc: 0.9827 - precision_17: 0.9840 - recall_17: 0.98166s - l - ETA: 0s - loss: 0.0466 - acc: 0.9828 - precision_17: 0.9837 - recall_\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0559 - acc: 0.9805 - precision_17: 0.9801 - recall_17: 0.9811\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0556 - acc: 0.9795 - precision_17: 0.9796 - recall_17: 0.9796\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0524 - acc: 0.9808 - precision_17: 0.9825 - recall_17: 0.97920s - loss: 0.0531 - acc: 0.9803 - precision_17: 0.9819 -\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0550 - acc: 0.9802 - precision_17: 0.9808 - recall_17: 0.9796\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0480 - acc: 0.9817 - precision_17: 0.9825 - recall_17: 0.98112s - loss: 0\n",
      "Epoch 00033: early stopping\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0758 - acc: 0.7511 - precision_17: 0.7769 - recall_17: 0.6758\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.6573 - acc: 0.6041 - precision_18: 0.6146 - recall_18: 0.5497\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.5416 - acc: 0.7373 - precision_18: 0.7819 - recall_18: 0.6553\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.4714 - acc: 0.7846 - precision_18: 0.8098 - recall_18: 0.7419\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4022 - acc: 0.8225 - precision_18: 0.8419 - recall_18: 0.7925\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.3489 - acc: 0.8498 - precision_18: 0.8683 - recall_18: 0.82330s - loss: 0.3496 - acc: 0.8507 - precision_18: 0.8707 - recal\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.2876 - acc: 0.8820 - precision_18: 0.8936 - recall_18: 0.8663\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2381 - acc: 0.9028 - precision_18: 0.9101 - recall_18: 0.8932\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1861 - acc: 0.9260 - precision_18: 0.9299 - recall_18: 0.9208\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1749 - acc: 0.9283 - precision_18: 0.9334 - recall_18: 0.9218\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.1511 - acc: 0.9427 - precision_18: 0.9449 - recall_18: 0.9396\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1336 - acc: 0.9481 - precision_18: 0.9482 - recall_18: 0.9477\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1237 - acc: 0.9537 - precision_18: 0.9538 - recall_18: 0.9533\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0977 - acc: 0.9619 - precision_18: 0.9634 - recall_18: 0.9599\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0925 - acc: 0.9651 - precision_18: 0.9655 - recall_18: 0.9643\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0874 - acc: 0.9693 - precision_18: 0.9690 - recall_18: 0.9694\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0972 - acc: 0.9653 - precision_18: 0.9646 - recall_18: 0.9658\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0846 - acc: 0.9685 - precision_18: 0.9708 - recall_18: 0.9658\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0792 - acc: 0.9710 - precision_18: 0.9716 - recall_18: 0.9702\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0786 - acc: 0.9705 - precision_18: 0.9707 - recall_18: 0.97021s - loss: 0.0735 - acc: 0.9715 - prec\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.0643 - acc: 0.9770 - precision_18: 0.9770 - recall_18: 0.9768\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0606 - acc: 0.9780 - precision_18: 0.9789 - recall_18: 0.9768\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0622 - acc: 0.9772 - precision_18: 0.9770 - recall_18: 0.97733s - loss: 0.0611 - acc: 0.9779 - precision_18: 0.9776 - recall_18: 0.97 - E\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0654 - acc: 0.9778 - precision_18: 0.9768 - recall_18: 0.9787\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0618 - acc: 0.9760 - precision_18: 0.9774 - recall_18: 0.9743\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0603 - acc: 0.9776 - precision_18: 0.9780 - recall_18: 0.9770\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0557 - acc: 0.9809 - precision_18: 0.9819 - recall_18: 0.9797\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0592 - acc: 0.9789 - precision_18: 0.9811 - recall_18: 0.9765\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0589 - acc: 0.9803 - precision_18: 0.9804 - recall_18: 0.98000s - loss: 0.0585 - acc: 0.9809 - precision_18: 0.9811 -\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0507 - acc: 0.9809 - precision_18: 0.9819 - recall_18: 0.9797\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0501 - acc: 0.9811 - precision_18: 0.9788 - recall_18: 0.9834\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0507 - acc: 0.9814 - precision_18: 0.9805 - recall_18: 0.9822\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0514 - acc: 0.9833 - precision_18: 0.9831 - recall_18: 0.9834\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0496 - acc: 0.9823 - precision_18: 0.9841 - recall_18: 0.9804\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0407 - acc: 0.9848 - precision_18: 0.9846 - recall_18: 0.9848\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0402 - acc: 0.9842 - precision_18: 0.9848 - recall_18: 0.9834\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0418 - acc: 0.9861 - precision_18: 0.9856 - recall_18: 0.9866\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0502 - acc: 0.9833 - precision_18: 0.9843 - recall_18: 0.9822\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0432 - acc: 0.9847 - precision_18: 0.9844 - recall_18: 0.98482s - los\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0395 - acc: 0.9859 - precision_18: 0.9861 - recall_18: 0.9856\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0418 - acc: 0.9847 - precision_18: 0.9846 - recall_18: 0.9846\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0395 - acc: 0.9848 - precision_18: 0.9858 - recall_18: 0.98362s - loss:\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0460 - acc: 0.9844 - precision_18: 0.9832 - recall_18: 0.9856\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0516 - acc: 0.9839 - precision_18: 0.9855 - recall_18: 0.98221s - loss: 0.0516 \n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0352 - acc: 0.9873 - precision_18: 0.9873 - recall_18: 0.9873\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0433 - acc: 0.9843 - precision_18: 0.9832 - recall_18: 0.98530s - loss: 0.0434 - acc: 0.9842 - precision_18: 0.9831 - recall_18: 0.\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0483 - acc: 0.9827 - precision_18: 0.9822 - recall_18: 0.9831\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0436 - acc: 0.9856 - precision_18: 0.9863 - recall_18: 0.9848\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0341 - acc: 0.9878 - precision_18: 0.9883 - recall_18: 0.98730s - loss: 0.0333 - acc: 0.9880 - precision_18: 0.9883 - r\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0379 - acc: 0.9869 - precision_18: 0.9868 - recall_18: 0.9868\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0372 - acc: 0.9865 - precision_18: 0.9866 - recall_18: 0.9863\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.2265 - acc: 0.7489 - precision_18: 0.7537 - recall_18: 0.7648\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.6317 - acc: 0.6310 - precision_19: 0.6273 - recall_19: 0.63725s - loss:\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.5122 - acc: 0.7611 - precision_19: 0.7906 - recall_19: 0.7074\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.4441 - acc: 0.7981 - precision_19: 0.8140 - recall_19: 0.7705\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3987 - acc: 0.8221 - precision_19: 0.8376 - recall_19: 0.7972\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.3311 - acc: 0.8626 - precision_19: 0.8703 - recall_19: 0.8505\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.2836 - acc: 0.8783 - precision_19: 0.8822 - recall_19: 0.8718\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2351 - acc: 0.9037 - precision_19: 0.9077 - recall_19: 0.8977\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.2019 - acc: 0.9215 - precision_19: 0.9231 - recall_19: 0.9188\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1604 - acc: 0.9385 - precision_19: 0.9405 - recall_19: 0.9357\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1474 - acc: 0.9424 - precision_19: 0.9449 - recall_19: 0.9391\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1166 - acc: 0.9533 - precision_19: 0.9504 - recall_19: 0.9560\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.1098 - acc: 0.9581 - precision_19: 0.9584 - recall_19: 0.9574\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0964 - acc: 0.9638 - precision_19: 0.9613 - recall_19: 0.9662\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.1058 - acc: 0.9591 - precision_19: 0.9607 - recall_19: 0.9569\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0820 - acc: 0.9708 - precision_19: 0.9716 - recall_19: 0.9697\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.0899 - acc: 0.9679 - precision_19: 0.9675 - recall_19: 0.9680\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0899 - acc: 0.9677 - precision_19: 0.9684 - recall_19: 0.9667\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.0849 - acc: 0.9690 - precision_19: 0.9673 - recall_19: 0.97041s - loss: 0.0863 \n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0729 - acc: 0.9724 - precision_19: 0.9712 - recall_19: 0.9733\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0734 - acc: 0.9741 - precision_19: 0.9731 - recall_19: 0.9748\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0674 - acc: 0.9749 - precision_19: 0.9748 - recall_19: 0.9748\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0681 - acc: 0.9739 - precision_19: 0.9755 - recall_19: 0.9721\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0589 - acc: 0.9778 - precision_19: 0.9763 - recall_19: 0.9792\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0596 - acc: 0.9780 - precision_19: 0.9792 - recall_19: 0.9765\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0662 - acc: 0.9764 - precision_19: 0.9751 - recall_19: 0.9775\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0552 - acc: 0.9813 - precision_19: 0.9809 - recall_19: 0.9814\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0674 - acc: 0.9761 - precision_19: 0.9753 - recall_19: 0.9768\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0504 - acc: 0.9822 - precision_19: 0.9821 - recall_19: 0.9821\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0515 - acc: 0.9811 - precision_19: 0.9805 - recall_19: 0.9817\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.0520 - acc: 0.9821 - precision_19: 0.9814 - recall_19: 0.9826\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.0535 - acc: 0.9816 - precision_19: 0.9826 - recall_19: 0.9804\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0504 - acc: 0.9821 - precision_19: 0.9824 - recall_19: 0.98174s - loss: 0.0513 - acc: 0.9822 - precision_\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0576 - acc: 0.9794 - precision_19: 0.9802 - recall_19: 0.97850s - loss: 0.0567 - acc: 0.9796 - precision_19: 0.98\n",
      "Epoch 00033: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8197 - acc: 0.7862 - precision_19: 0.8431 - recall_19: 0.7242\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "    \n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNN = Sequential() #cnn\n",
    "\n",
    "    modelCNN.add(embedding_layer)\n",
    "    modelCNN.add(Conv1D(filters=256, kernel_size=5, activation='relu')) #kernal size 5 yan yana beş kelimeye bakması\n",
    "    modelCNN.add(MaxPooling1D(pool_size=2)) #tek satırlık 1d olduğu için\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(360, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(300, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(260, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(150, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(120, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(80, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Flatten()) #düzgünleştirmek için\n",
    "    modelCNN.add(Dense(1, activation='sigmoid'))\n",
    "    modelCNN.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNN.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelCNN.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.760356\n",
      "test precision: 0.765662\n",
      "test recall: 0.752952\n",
      "test f1_score: 0.757889\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.5581 - acc: 0.7176 - precision_20: 0.7373 - recall_20: 0.6791\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.4805 - acc: 0.7760 - precision_20: 0.7907 - recall_20: 0.7527\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4570 - acc: 0.7907 - precision_20: 0.8048 - recall_20: 0.7694\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4401 - acc: 0.7989 - precision_20: 0.8104 - recall_20: 0.7820\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.4168 - acc: 0.8088 - precision_20: 0.8199 - recall_20: 0.7932\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.4023 - acc: 0.8155 - precision_20: 0.8249 - recall_20: 0.8027\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3923 - acc: 0.8209 - precision_20: 0.8297 - recall_20: 0.8090\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3736 - acc: 0.8337 - precision_20: 0.8456 - recall_20: 0.8177\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3631 - acc: 0.8323 - precision_20: 0.8416 - recall_20: 0.82011s - loss: 0.3654 - acc: 0.8310 - precision_\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3441 - acc: 0.8400 - precision_20: 0.8480 - recall_20: 0.8299\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.3334 - acc: 0.8532 - precision_20: 0.8578 - recall_20: 0.8478\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3205 - acc: 0.8574 - precision_20: 0.8617 - recall_20: 0.8527\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3112 - acc: 0.8638 - precision_20: 0.8741 - recall_20: 0.8510\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2979 - acc: 0.8706 - precision_20: 0.8711 - recall_20: 0.8709\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2677 - acc: 0.8845 - precision_20: 0.8872 - recall_20: 0.8818\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2662 - acc: 0.8869 - precision_20: 0.8942 - recall_20: 0.8784\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2520 - acc: 0.8924 - precision_20: 0.8973 - recall_20: 0.8869\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2354 - acc: 0.9005 - precision_20: 0.9035 - recall_20: 0.8976\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2217 - acc: 0.9072 - precision_20: 0.9109 - recall_20: 0.9034\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2154 - acc: 0.9080 - precision_20: 0.9112 - recall_20: 0.9046\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2010 - acc: 0.9159 - precision_20: 0.9171 - recall_20: 0.9150\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1927 - acc: 0.9196 - precision_20: 0.9226 - recall_20: 0.9167\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1946 - acc: 0.9168 - precision_20: 0.9197 - recall_20: 0.9141\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1725 - acc: 0.9297 - precision_20: 0.9318 - recall_20: 0.9279\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1522 - acc: 0.9385 - precision_20: 0.9380 - recall_20: 0.9396\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1526 - acc: 0.9381 - precision_20: 0.9409 - recall_20: 0.9354\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1395 - acc: 0.9456 - precision_20: 0.9478 - recall_20: 0.9434\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1349 - acc: 0.9458 - precision_20: 0.9487 - recall_20: 0.9430\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1274 - acc: 0.9493 - precision_20: 0.9489 - recall_20: 0.9502\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1198 - acc: 0.9529 - precision_20: 0.9558 - recall_20: 0.9500\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1147 - acc: 0.9552 - precision_20: 0.9540 - recall_20: 0.9568\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1087 - acc: 0.9584 - precision_20: 0.9594 - recall_20: 0.9575\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.0995 - acc: 0.9610 - precision_20: 0.9627 - recall_20: 0.9595\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0987 - acc: 0.9620 - precision_20: 0.9617 - recall_20: 0.9626\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0859 - acc: 0.9681 - precision_20: 0.9696 - recall_20: 0.9667\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0868 - acc: 0.9674 - precision_20: 0.9702 - recall_20: 0.9646\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0829 - acc: 0.9687 - precision_20: 0.9685 - recall_20: 0.9692\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0776 - acc: 0.9707 - precision_20: 0.9716 - recall_20: 0.9699\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.0852 - acc: 0.9676 - precision_20: 0.9695 - recall_20: 0.9658\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0710 - acc: 0.9725 - precision_20: 0.9703 - recall_20: 0.9750\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0732 - acc: 0.9728 - precision_20: 0.9735 - recall_20: 0.9723\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0682 - acc: 0.9732 - precision_20: 0.9733 - recall_20: 0.9733\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.0655 - acc: 0.9758 - precision_20: 0.9764 - recall_20: 0.9752\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0639 - acc: 0.9766 - precision_20: 0.9783 - recall_20: 0.9750\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0529 - acc: 0.9809 - precision_20: 0.9818 - recall_20: 0.9801\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0510 - acc: 0.9820 - precision_20: 0.9811 - recall_20: 0.9830\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0593 - acc: 0.9784 - precision_20: 0.9800 - recall_20: 0.9769\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0538 - acc: 0.9802 - precision_20: 0.9794 - recall_20: 0.9811\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0578 - acc: 0.9806 - precision_20: 0.9822 - recall_20: 0.9791\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0475 - acc: 0.9836 - precision_20: 0.9856 - recall_20: 0.9816\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.8553 - acc: 0.7820 - precision_20: 0.7542 - recall_20: 0.8172\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.5668 - acc: 0.7146 - precision_21: 0.7407 - recall_21: 0.6618\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.4851 - acc: 0.7747 - precision_21: 0.7873 - recall_21: 0.7540\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.4593 - acc: 0.7846 - precision_21: 0.7930 - recall_21: 0.7712\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.4371 - acc: 0.7940 - precision_21: 0.8072 - recall_21: 0.7734\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.4194 - acc: 0.8059 - precision_21: 0.8170 - recall_21: 0.7892\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4062 - acc: 0.8081 - precision_21: 0.8130 - recall_21: 0.8011\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3941 - acc: 0.8182 - precision_21: 0.8332 - recall_21: 0.7965\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3761 - acc: 0.8297 - precision_21: 0.8366 - recall_21: 0.8201\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3631 - acc: 0.8365 - precision_21: 0.8437 - recall_21: 0.82662s - loss: 0.3\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3484 - acc: 0.8385 - precision_21: 0.8436 - recall_21: 0.83182s - loss: 0\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3391 - acc: 0.8491 - precision_21: 0.8545 - recall_21: 0.8422\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3171 - acc: 0.8573 - precision_21: 0.8652 - recall_21: 0.8471\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3052 - acc: 0.8647 - precision_21: 0.8706 - recall_21: 0.8573\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2887 - acc: 0.8717 - precision_21: 0.8796 - recall_21: 0.8617\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2765 - acc: 0.8787 - precision_21: 0.8826 - recall_21: 0.8741\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2623 - acc: 0.8854 - precision_21: 0.8885 - recall_21: 0.8818\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2477 - acc: 0.8935 - precision_21: 0.8982 - recall_21: 0.8879\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2422 - acc: 0.8958 - precision_21: 0.8994 - recall_21: 0.8916\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2268 - acc: 0.9045 - precision_21: 0.9089 - recall_21: 0.8996\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2011 - acc: 0.9170 - precision_21: 0.9191 - recall_21: 0.9147\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1991 - acc: 0.9151 - precision_21: 0.9176 - recall_21: 0.9125\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1860 - acc: 0.9227 - precision_21: 0.9221 - recall_21: 0.9237\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1759 - acc: 0.9282 - precision_21: 0.9293 - recall_21: 0.9271\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1739 - acc: 0.9256 - precision_21: 0.9271 - recall_21: 0.9241\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1595 - acc: 0.9338 - precision_21: 0.9373 - recall_21: 0.9300\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1504 - acc: 0.9397 - precision_21: 0.9417 - recall_21: 0.9378\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1373 - acc: 0.9491 - precision_21: 0.9532 - recall_21: 0.9448\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1337 - acc: 0.9451 - precision_21: 0.9477 - recall_21: 0.9424\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1176 - acc: 0.9536 - precision_21: 0.9547 - recall_21: 0.9526\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1214 - acc: 0.9551 - precision_21: 0.9561 - recall_21: 0.9540\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1125 - acc: 0.9570 - precision_21: 0.9588 - recall_21: 0.9553\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1086 - acc: 0.9590 - precision_21: 0.9605 - recall_21: 0.9575\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1014 - acc: 0.9607 - precision_21: 0.9631 - recall_21: 0.9582\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0911 - acc: 0.9659 - precision_21: 0.9660 - recall_21: 0.9660\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0936 - acc: 0.9641 - precision_21: 0.9652 - recall_21: 0.9630\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0874 - acc: 0.9685 - precision_21: 0.9698 - recall_21: 0.9672\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0787 - acc: 0.9705 - precision_21: 0.9708 - recall_21: 0.9703\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0800 - acc: 0.9714 - precision_21: 0.9704 - recall_21: 0.9725\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0689 - acc: 0.9728 - precision_21: 0.9728 - recall_21: 0.9730\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0709 - acc: 0.9744 - precision_21: 0.9752 - recall_21: 0.9737\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0688 - acc: 0.9748 - precision_21: 0.9747 - recall_21: 0.9750\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0647 - acc: 0.9763 - precision_21: 0.9769 - recall_21: 0.9757\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0620 - acc: 0.9777 - precision_21: 0.9779 - recall_21: 0.9776\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0562 - acc: 0.9795 - precision_21: 0.9789 - recall_21: 0.9803\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0581 - acc: 0.9802 - precision_21: 0.9801 - recall_21: 0.9803\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.0602 - acc: 0.9774 - precision_21: 0.9774 - recall_21: 0.9774\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.0552 - acc: 0.9820 - precision_21: 0.9818 - recall_21: 0.98 - 25s 98ms/step - loss: 0.0552 - acc: 0.9820 - precision_21: 0.9818 - recall_21: 0.9823\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0518 - acc: 0.9794 - precision_21: 0.9812 - recall_21: 0.9776\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0479 - acc: 0.9827 - precision_21: 0.9832 - recall_21: 0.9823\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0462 - acc: 0.9838 - precision_21: 0.9839 - recall_21: 0.9837\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.8628 - acc: 0.7941 - precision_21: 0.7787 - recall_21: 0.8133\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 25s 95ms/step - loss: 0.5514 - acc: 0.7247 - precision_22: 0.7408 - recall_22: 0.6858\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4843 - acc: 0.7738 - precision_22: 0.7844 - recall_22: 0.7510\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 28s 110ms/step - loss: 0.4616 - acc: 0.7849 - precision_22: 0.7959 - recall_22: 0.7625\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4352 - acc: 0.7986 - precision_22: 0.8147 - recall_22: 0.7696\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.4167 - acc: 0.8065 - precision_22: 0.8170 - recall_22: 0.7868\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.4035 - acc: 0.8127 - precision_22: 0.8224 - recall_22: 0.7946\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3880 - acc: 0.8228 - precision_22: 0.8347 - recall_22: 0.8022\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3752 - acc: 0.8280 - precision_22: 0.8379 - recall_22: 0.8105\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3598 - acc: 0.8355 - precision_22: 0.8429 - recall_22: 0.8221\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3428 - acc: 0.8443 - precision_22: 0.8523 - recall_22: 0.8304\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3239 - acc: 0.8546 - precision_22: 0.8591 - recall_22: 0.8461\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.3130 - acc: 0.8608 - precision_22: 0.8654 - recall_22: 0.8525\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.3017 - acc: 0.8684 - precision_22: 0.8746 - recall_22: 0.8581\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.2814 - acc: 0.8762 - precision_22: 0.8818 - recall_22: 0.8669\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 24s 95ms/step - loss: 0.2654 - acc: 0.8846 - precision_22: 0.8850 - recall_22: 0.8824\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.2586 - acc: 0.8857 - precision_22: 0.8908 - recall_22: 0.8775\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.2374 - acc: 0.8975 - precision_22: 0.9013 - recall_22: 0.89121s - loss: 0.2386 - acc: 0.8968 \n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2304 - acc: 0.9032 - precision_22: 0.9069 - recall_22: 0.8973\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.2153 - acc: 0.9072 - precision_22: 0.9125 - recall_22: 0.8995\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2012 - acc: 0.9157 - precision_22: 0.9166 - recall_22: 0.9135\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1863 - acc: 0.9238 - precision_22: 0.9279 - recall_22: 0.9179\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1892 - acc: 0.9216 - precision_22: 0.9236 - recall_22: 0.9181\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1719 - acc: 0.9321 - precision_22: 0.9359 - recall_22: 0.9267\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1599 - acc: 0.9362 - precision_22: 0.9351 - recall_22: 0.9365\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1443 - acc: 0.9413 - precision_22: 0.9424 - recall_22: 0.9392\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 25s 96ms/step - loss: 0.1433 - acc: 0.9437 - precision_22: 0.9469 - recall_22: 0.9395\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1321 - acc: 0.9475 - precision_22: 0.9491 - recall_22: 0.9451\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1298 - acc: 0.9486 - precision_22: 0.9505 - recall_22: 0.9458\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1268 - acc: 0.9520 - precision_22: 0.9539 - recall_22: 0.9493\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1120 - acc: 0.9577 - precision_22: 0.9596 - recall_22: 0.9551\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1102 - acc: 0.9590 - precision_22: 0.9618 - recall_22: 0.9554\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1000 - acc: 0.9609 - precision_22: 0.9621 - recall_22: 0.9591\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1006 - acc: 0.9625 - precision_22: 0.9643 - recall_22: 0.9600\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0892 - acc: 0.9671 - precision_22: 0.9674 - recall_22: 0.9664\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0910 - acc: 0.9666 - precision_22: 0.9660 - recall_22: 0.9669\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0893 - acc: 0.9651 - precision_22: 0.9627 - recall_22: 0.9672\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0771 - acc: 0.9725 - precision_22: 0.9730 - recall_22: 0.9716\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0793 - acc: 0.9702 - precision_22: 0.9699 - recall_22: 0.97012s - loss: 0\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0788 - acc: 0.9713 - precision_22: 0.9720 - recall_22: 0.9701\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0740 - acc: 0.9730 - precision_22: 0.9756 - recall_22: 0.9699\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0670 - acc: 0.9767 - precision_22: 0.9774 - recall_22: 0.9757\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0632 - acc: 0.9786 - precision_22: 0.9801 - recall_22: 0.9767\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0651 - acc: 0.9784 - precision_22: 0.9798 - recall_22: 0.9767\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0657 - acc: 0.9755 - precision_22: 0.9771 - recall_22: 0.9735\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0561 - acc: 0.9800 - precision_22: 0.9799 - recall_22: 0.9799\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0550 - acc: 0.9819 - precision_22: 0.9826 - recall_22: 0.9809\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0543 - acc: 0.9811 - precision_22: 0.9818 - recall_22: 0.9801\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0512 - acc: 0.9827 - precision_22: 0.9843 - recall_22: 0.9809\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0445 - acc: 0.9834 - precision_22: 0.9833 - recall_22: 0.9833\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.0471 - acc: 0.9843 - precision_22: 0.9843 - recall_22: 0.9841\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 0.9541 - acc: 0.7941 - precision_22: 0.8041 - recall_22: 0.8075\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.5530 - acc: 0.7232 - precision_23: 0.7307 - recall_23: 0.7066\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4868 - acc: 0.7718 - precision_23: 0.7826 - recall_23: 0.7524\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.4594 - acc: 0.7903 - precision_23: 0.8018 - recall_23: 0.77103s\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.4398 - acc: 0.7963 - precision_23: 0.8069 - recall_23: 0.7788\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.4230 - acc: 0.8064 - precision_23: 0.8150 - recall_23: 0.7924\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4075 - acc: 0.8152 - precision_23: 0.8226 - recall_23: 0.8034\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.3940 - acc: 0.8220 - precision_23: 0.8324 - recall_23: 0.8060\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.3776 - acc: 0.8309 - precision_23: 0.8381 - recall_23: 0.81 - 26s 102ms/step - loss: 0.3776 - acc: 0.8309 - precision_23: 0.8381 - recall_23: 0.8199\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3604 - acc: 0.8371 - precision_23: 0.8430 - recall_23: 0.8282\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3545 - acc: 0.8396 - precision_23: 0.8467 - recall_23: 0.8292\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.3348 - acc: 0.8504 - precision_23: 0.8584 - recall_23: 0.8389\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.3261 - acc: 0.8566 - precision_23: 0.8607 - recall_23: 0.8506\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.3033 - acc: 0.8679 - precision_23: 0.8741 - recall_23: 0.8594\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2964 - acc: 0.8687 - precision_23: 0.8762 - recall_23: 0.8587\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2770 - acc: 0.8769 - precision_23: 0.8829 - recall_23: 0.8689\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2641 - acc: 0.8875 - precision_23: 0.8945 - recall_23: 0.8784\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2564 - acc: 0.8879 - precision_23: 0.8919 - recall_23: 0.8826\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.2392 - acc: 0.8980 - precision_23: 0.9028 - recall_23: 0.8918\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2206 - acc: 0.9088 - precision_23: 0.9135 - recall_23: 0.9030\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2028 - acc: 0.9174 - precision_23: 0.9246 - recall_23: 0.9089\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1913 - acc: 0.9211 - precision_23: 0.9242 - recall_23: 0.9174\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1874 - acc: 0.9239 - precision_23: 0.9281 - recall_23: 0.9189\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 25s 97ms/step - loss: 0.1765 - acc: 0.9273 - precision_23: 0.9335 - recall_23: 0.9201\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1593 - acc: 0.9374 - precision_23: 0.9419 - recall_23: 0.9323\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1530 - acc: 0.9395 - precision_23: 0.9396 - recall_23: 0.9393\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1376 - acc: 0.9453 - precision_23: 0.9458 - recall_23: 0.9447\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1377 - acc: 0.9446 - precision_23: 0.9473 - recall_23: 0.9415\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1296 - acc: 0.9501 - precision_23: 0.9536 - recall_23: 0.9462\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1210 - acc: 0.9536 - precision_23: 0.9566 - recall_23: 0.9503\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1167 - acc: 0.9547 - precision_23: 0.9558 - recall_23: 0.9535\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1041 - acc: 0.9603 - precision_23: 0.9605 - recall_23: 0.9600\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1016 - acc: 0.9610 - precision_23: 0.9630 - recall_23: 0.9588\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.1021 - acc: 0.9604 - precision_23: 0.9637 - recall_23: 0.9569\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0944 - acc: 0.9652 - precision_23: 0.9672 - recall_23: 0.9630\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0799 - acc: 0.9702 - precision_23: 0.9700 - recall_23: 0.9703\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0842 - acc: 0.9682 - precision_23: 0.9688 - recall_23: 0.9676\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0842 - acc: 0.9691 - precision_23: 0.9704 - recall_23: 0.9676\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0772 - acc: 0.9724 - precision_23: 0.9748 - recall_23: 0.9698\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0829 - acc: 0.9686 - precision_23: 0.9697 - recall_23: 0.9673\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0719 - acc: 0.9731 - precision_23: 0.9746 - recall_23: 0.9715\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.0639 - acc: 0.9777 - precision_23: 0.9790 - recall_23: 0.9764\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0668 - acc: 0.9752 - precision_23: 0.9756 - recall_23: 0.97473s -\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0628 - acc: 0.9776 - precision_23: 0.9769 - recall_23: 0.9783\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0594 - acc: 0.9780 - precision_23: 0.9790 - recall_23: 0.9769\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.0581 - acc: 0.9784 - precision_23: 0.9779 - recall_23: 0.9790\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.0511 - acc: 0.9822 - precision_23: 0.9824 - recall_23: 0.9820\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0508 - acc: 0.9831 - precision_23: 0.9829 - recall_23: 0.9832\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0479 - acc: 0.9830 - precision_23: 0.9837 - recall_23: 0.9822\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0475 - acc: 0.9826 - precision_23: 0.9827 - recall_23: 0.9825\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0450 - acc: 0.9837 - precision_23: 0.9846 - recall_23: 0.9827\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 0.8199 - acc: 0.8061 - precision_23: 0.7754 - recall_23: 0.8649\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.5597 - acc: 0.7123 - precision_24: 0.7263 - recall_24: 0.6778\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4839 - acc: 0.7734 - precision_24: 0.7847 - recall_24: 0.7512\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.4578 - acc: 0.7829 - precision_24: 0.7960 - recall_24: 0.7585\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.4388 - acc: 0.7939 - precision_24: 0.8045 - recall_24: 0.7744\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4190 - acc: 0.8076 - precision_24: 0.8107 - recall_24: 0.8008\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.4058 - acc: 0.8101 - precision_24: 0.8182 - recall_24: 0.7954\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3881 - acc: 0.8204 - precision_24: 0.8272 - recall_24: 0.8084\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3744 - acc: 0.8249 - precision_24: 0.8312 - recall_24: 0.8137\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3611 - acc: 0.8364 - precision_24: 0.8448 - recall_24: 0.8225\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3426 - acc: 0.8428 - precision_24: 0.8507 - recall_24: 0.8301\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3276 - acc: 0.8536 - precision_24: 0.8603 - recall_24: 0.8431\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3138 - acc: 0.8597 - precision_24: 0.8651 - recall_24: 0.8511\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3079 - acc: 0.8580 - precision_24: 0.8641 - recall_24: 0.8484\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2875 - acc: 0.8735 - precision_24: 0.8768 - recall_24: 0.8680\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2666 - acc: 0.8827 - precision_24: 0.8858 - recall_24: 0.8778\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2511 - acc: 0.8893 - precision_24: 0.8907 - recall_24: 0.8866\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2402 - acc: 0.8980 - precision_24: 0.9035 - recall_24: 0.8902\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2316 - acc: 0.9006 - precision_24: 0.9034 - recall_24: 0.8964\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2209 - acc: 0.9036 - precision_24: 0.9074 - recall_24: 0.8981\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2034 - acc: 0.9168 - precision_24: 0.9189 - recall_24: 0.9137\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1849 - acc: 0.9226 - precision_24: 0.9266 - recall_24: 0.9171\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1781 - acc: 0.9254 - precision_24: 0.9260 - recall_24: 0.9240\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1683 - acc: 0.9329 - precision_24: 0.9345 - recall_24: 0.9306\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1639 - acc: 0.9333 - precision_24: 0.9358 - recall_24: 0.9298\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1462 - acc: 0.9413 - precision_24: 0.9439 - recall_24: 0.9379\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1507 - acc: 0.9377 - precision_24: 0.9383 - recall_24: 0.9364s - loss:\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1363 - acc: 0.9461 - precision_24: 0.9477 - recall_24: 0.9438\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1285 - acc: 0.9485 - precision_24: 0.9502 - recall_24: 0.9462\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1180 - acc: 0.9525 - precision_24: 0.9548 - recall_24: 0.9496\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1236 - acc: 0.9503 - precision_24: 0.9493 - recall_24: 0.9511\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1075 - acc: 0.9577 - precision_24: 0.9593 - recall_24: 0.9558\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1000 - acc: 0.9614 - precision_24: 0.9634 - recall_24: 0.9589\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1006 - acc: 0.9613 - precision_24: 0.9643 - recall_24: 0.9577\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0953 - acc: 0.9620 - precision_24: 0.9623 - recall_24: 0.9614\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0931 - acc: 0.9647 - precision_24: 0.9673 - recall_24: 0.9616\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0828 - acc: 0.9690 - precision_24: 0.9708 - recall_24: 0.9668\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0805 - acc: 0.9682 - precision_24: 0.9687 - recall_24: 0.9675\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0773 - acc: 0.9708 - precision_24: 0.9727 - recall_24: 0.9685\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0776 - acc: 0.9713 - precision_24: 0.9732 - recall_24: 0.9690\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0784 - acc: 0.9687 - precision_24: 0.9694 - recall_24: 0.9677\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0654 - acc: 0.9763 - precision_24: 0.9758 - recall_24: 0.9765\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0625 - acc: 0.9749 - precision_24: 0.9748 - recall_24: 0.9748\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0613 - acc: 0.9782 - precision_24: 0.9804 - recall_24: 0.9758\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0655 - acc: 0.9746 - precision_24: 0.9750 - recall_24: 0.9738\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0573 - acc: 0.9806 - precision_24: 0.9797 - recall_24: 0.9814\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0560 - acc: 0.9788 - precision_24: 0.9787 - recall_24: 0.9787\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0594 - acc: 0.9803 - precision_24: 0.9814 - recall_24: 0.9790\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0558 - acc: 0.9791 - precision_24: 0.9802 - recall_24: 0.9778\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.0531 - acc: 0.9819 - precision_24: 0.9848 - recall_24: 0.9787\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0455 - acc: 0.9851 - precision_24: 0.9844 - recall_24: 0.9858\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 0.8410 - acc: 0.7974 - precision_24: 0.7786 - recall_24: 0.8496\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.5570 - acc: 0.7232 - precision_25: 0.7400 - recall_25: 0.6879\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.4868 - acc: 0.7744 - precision_25: 0.7887 - recall_25: 0.7493\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.4589 - acc: 0.7908 - precision_25: 0.8025 - recall_25: 0.7712\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4348 - acc: 0.8006 - precision_25: 0.8118 - recall_25: 0.7822\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4216 - acc: 0.8041 - precision_25: 0.8143 - recall_25: 0.7875\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4092 - acc: 0.8122 - precision_25: 0.8190 - recall_25: 0.8014\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3972 - acc: 0.8172 - precision_25: 0.8281 - recall_25: 0.8004\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.3792 - acc: 0.8273 - precision_25: 0.8376 - recall_25: 0.8119\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.3649 - acc: 0.8322 - precision_25: 0.8394 - recall_25: 0.8214\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3434 - acc: 0.8446 - precision_25: 0.8530 - recall_25: 0.8326\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.3324 - acc: 0.8523 - precision_25: 0.8622 - recall_25: 0.8385\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3214 - acc: 0.8550 - precision_25: 0.8597 - recall_25: 0.8482\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3007 - acc: 0.8701 - precision_25: 0.8786 - recall_25: 0.8587\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.2897 - acc: 0.8747 - precision_25: 0.8797 - recall_25: 0.8679\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2722 - acc: 0.8825 - precision_25: 0.8882 - recall_25: 0.8750\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2619 - acc: 0.8875 - precision_25: 0.8901 - recall_25: 0.8840\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.2429 - acc: 0.8974 - precision_25: 0.9019 - recall_25: 0.8916\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2309 - acc: 0.9013 - precision_25: 0.9039 - recall_25: 0.8979\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.2118 - acc: 0.9064 - precision_25: 0.9100 - recall_25: 0.9018\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.2038 - acc: 0.9157 - precision_25: 0.9185 - recall_25: 0.9123\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 28s 107ms/step - loss: 0.1966 - acc: 0.9179 - precision_25: 0.9247 - recall_25: 0.9098\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.1801 - acc: 0.9243 - precision_25: 0.9267 - recall_25: 0.9213\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.1728 - acc: 0.9276 - precision_25: 0.9270 - recall_25: 0.9281\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1583 - acc: 0.9367 - precision_25: 0.9366 - recall_25: 0.9366\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1563 - acc: 0.9347 - precision_25: 0.9358 - recall_25: 0.9335\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1416 - acc: 0.9435 - precision_25: 0.9441 - recall_25: 0.9427\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1371 - acc: 0.9475 - precision_25: 0.9500 - recall_25: 0.9447\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1317 - acc: 0.9465 - precision_25: 0.9468 - recall_25: 0.9462\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1162 - acc: 0.9539 - precision_25: 0.9562 - recall_25: 0.9513\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1117 - acc: 0.9559 - precision_25: 0.9559 - recall_25: 0.9559\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1076 - acc: 0.9582 - precision_25: 0.9581 - recall_25: 0.9583\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0965 - acc: 0.9658 - precision_25: 0.9677 - recall_25: 0.9637\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0911 - acc: 0.9651 - precision_25: 0.9656 - recall_25: 0.9644\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1037 - acc: 0.9615 - precision_25: 0.9624 - recall_25: 0.9605\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.0896 - acc: 0.9660 - precision_25: 0.9670 - recall_25: 0.9649\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0835 - acc: 0.9691 - precision_25: 0.9697 - recall_25: 0.9683\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0750 - acc: 0.9716 - precision_25: 0.9729 - recall_25: 0.9703\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0790 - acc: 0.9699 - precision_25: 0.9705 - recall_25: 0.9693\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0689 - acc: 0.9742 - precision_25: 0.9756 - recall_25: 0.9727\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0775 - acc: 0.9716 - precision_25: 0.9720 - recall_25: 0.9712\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0688 - acc: 0.9744 - precision_25: 0.9753 - recall_25: 0.9734\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0625 - acc: 0.9781 - precision_25: 0.9785 - recall_25: 0.9776\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0614 - acc: 0.9781 - precision_25: 0.9783 - recall_25: 0.9778\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 27s 106ms/step - loss: 0.0620 - acc: 0.9776 - precision_25: 0.9767 - recall_25: 0.9786\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0552 - acc: 0.9806 - precision_25: 0.9833 - recall_25: 0.9778\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0594 - acc: 0.9800 - precision_25: 0.9791 - recall_25: 0.9810\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0514 - acc: 0.9811 - precision_25: 0.9838 - recall_25: 0.9783\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0503 - acc: 0.9838 - precision_25: 0.9837 - recall_25: 0.9839\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0488 - acc: 0.9840 - precision_25: 0.9830 - recall_25: 0.9851\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0474 - acc: 0.9834 - precision_25: 0.9841 - recall_25: 0.9827\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.7668 - acc: 0.7919 - precision_25: 0.7844 - recall_25: 0.8083\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.5559 - acc: 0.7246 - precision_26: 0.7444 - recall_26: 0.6900\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4776 - acc: 0.7766 - precision_26: 0.7837 - recall_26: 0.7684\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.4592 - acc: 0.7895 - precision_26: 0.8010 - recall_26: 0.7744\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.4313 - acc: 0.8055 - precision_26: 0.8160 - recall_26: 0.7923\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.4171 - acc: 0.8109 - precision_26: 0.8222 - recall_26: 0.7969\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4069 - acc: 0.8141 - precision_26: 0.8200 - recall_26: 0.8083\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3923 - acc: 0.8216 - precision_26: 0.8308 - recall_26: 0.8109\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3760 - acc: 0.8266 - precision_26: 0.8343 - recall_26: 0.8182\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3614 - acc: 0.8353 - precision_26: 0.8420 - recall_26: 0.8283\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3516 - acc: 0.8460 - precision_26: 0.8507 - recall_26: 0.8419\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3344 - acc: 0.8529 - precision_26: 0.8636 - recall_26: 0.8407\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3166 - acc: 0.8578 - precision_26: 0.8648 - recall_26: 0.8506\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3097 - acc: 0.8626 - precision_26: 0.8684 - recall_26: 0.8569\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2953 - acc: 0.8711 - precision_26: 0.8770 - recall_26: 0.8653\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2825 - acc: 0.8757 - precision_26: 0.8787 - recall_26: 0.8738\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.2752 - acc: 0.8814 - precision_26: 0.8879 - recall_26: 0.8750\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.2474 - acc: 0.8955 - precision_26: 0.8994 - recall_26: 0.8924\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2412 - acc: 0.8972 - precision_26: 0.9054 - recall_26: 0.8888\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2278 - acc: 0.9037 - precision_26: 0.9110 - recall_26: 0.8963\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2112 - acc: 0.9106 - precision_26: 0.9135 - recall_26: 0.9086\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2003 - acc: 0.9138 - precision_26: 0.9170 - recall_26: 0.9113\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1872 - acc: 0.9223 - precision_26: 0.9258 - recall_26: 0.9195\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1782 - acc: 0.9268 - precision_26: 0.9293 - recall_26: 0.9250\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1651 - acc: 0.9306 - precision_26: 0.9362 - recall_26: 0.9253\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1546 - acc: 0.9401 - precision_26: 0.9424 - recall_26: 0.9383\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1502 - acc: 0.9388 - precision_26: 0.9425 - recall_26: 0.9354\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1416 - acc: 0.9416 - precision_26: 0.9478 - recall_26: 0.9354\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1363 - acc: 0.9440 - precision_26: 0.9461 - recall_26: 0.9425\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1270 - acc: 0.9463 - precision_26: 0.9505 - recall_26: 0.9425\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1168 - acc: 0.9554 - precision_26: 0.9602 - recall_26: 0.9509\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1108 - acc: 0.9565 - precision_26: 0.9596 - recall_26: 0.9538\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1086 - acc: 0.9580 - precision_26: 0.9584 - recall_26: 0.9582\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1036 - acc: 0.9621 - precision_26: 0.9641 - recall_26: 0.9606\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0921 - acc: 0.9660 - precision_26: 0.9657 - recall_26: 0.9669\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0904 - acc: 0.9652 - precision_26: 0.9688 - recall_26: 0.9618\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0850 - acc: 0.9673 - precision_26: 0.9671 - recall_26: 0.9678\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0805 - acc: 0.9690 - precision_26: 0.9716 - recall_26: 0.9666\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0969 - acc: 0.9645 - precision_26: 0.9665 - recall_26: 0.9628\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.0825 - acc: 0.9708 - precision_26: 0.9724 - recall_26: 0.9695\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0784 - acc: 0.9710 - precision_26: 0.9705 - recall_26: 0.9720\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0687 - acc: 0.9758 - precision_26: 0.9763 - recall_26: 0.9756\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0640 - acc: 0.9765 - precision_26: 0.9759 - recall_26: 0.9775\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0689 - acc: 0.9753 - precision_26: 0.9777 - recall_26: 0.9732\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0649 - acc: 0.9758 - precision_26: 0.9784 - recall_26: 0.9734\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0600 - acc: 0.9791 - precision_26: 0.9804 - recall_26: 0.9780\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0541 - acc: 0.9810 - precision_26: 0.9814 - recall_26: 0.9809\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0529 - acc: 0.9819 - precision_26: 0.9833 - recall_26: 0.9807\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0498 - acc: 0.9836 - precision_26: 0.9831 - recall_26: 0.9843\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0457 - acc: 0.9837 - precision_26: 0.9840 - recall_26: 0.9836\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0540 - acc: 0.9800 - precision_26: 0.9811 - recall_26: 0.9792\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.8427 - acc: 0.7796 - precision_26: 0.7344 - recall_26: 0.8290\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.5614 - acc: 0.7166 - precision_27: 0.7257 - recall_27: 0.6960\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4861 - acc: 0.7699 - precision_27: 0.7799 - recall_27: 0.7518\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4572 - acc: 0.7859 - precision_27: 0.8000 - recall_27: 0.7620\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.4304 - acc: 0.8007 - precision_27: 0.8145 - recall_27: 0.7786\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.4188 - acc: 0.8041 - precision_27: 0.8152 - recall_27: 0.7864\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.4032 - acc: 0.8123 - precision_27: 0.8235 - recall_27: 0.7946\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3845 - acc: 0.8276 - precision_27: 0.8371 - recall_27: 0.8134\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3725 - acc: 0.8322 - precision_27: 0.8439 - recall_27: 0.8151\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3593 - acc: 0.8395 - precision_27: 0.8464 - recall_27: 0.8295\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3438 - acc: 0.8483 - precision_27: 0.8593 - recall_27: 0.8329\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.3297 - acc: 0.8511 - precision_27: 0.8574 - recall_27: 0.8421\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 27s 106ms/step - loss: 0.3120 - acc: 0.8583 - precision_27: 0.8623 - recall_27: 0.8526\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2989 - acc: 0.8682 - precision_27: 0.8727 - recall_27: 0.8619\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.2838 - acc: 0.8764 - precision_27: 0.8820 - recall_27: 0.8689\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2657 - acc: 0.8841 - precision_27: 0.8913 - recall_27: 0.8748\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2506 - acc: 0.8919 - precision_27: 0.8955 - recall_27: 0.8872\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2351 - acc: 0.8955 - precision_27: 0.9002 - recall_27: 0.8896\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2284 - acc: 0.9026 - precision_27: 0.9065 - recall_27: 0.8977\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2138 - acc: 0.9086 - precision_27: 0.9120 - recall_27: 0.9043\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.1949 - acc: 0.9166 - precision_27: 0.9185 - recall_27: 0.9143\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1906 - acc: 0.9229 - precision_27: 0.9228 - recall_27: 0.9230\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1793 - acc: 0.9252 - precision_27: 0.9252 - recall_27: 0.9252\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1725 - acc: 0.9284 - precision_27: 0.9311 - recall_27: 0.9252\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.1582 - acc: 0.9361 - precision_27: 0.9415 - recall_27: 0.9298\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 27s 106ms/step - loss: 0.1437 - acc: 0.9422 - precision_27: 0.9431 - recall_27: 0.9410\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.1394 - acc: 0.9428 - precision_27: 0.9456 - recall_27: 0.9396\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1368 - acc: 0.9431 - precision_27: 0.9461 - recall_27: 0.9398\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1217 - acc: 0.9513 - precision_27: 0.9535 - recall_27: 0.9488\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1194 - acc: 0.9536 - precision_27: 0.9557 - recall_27: 0.9513\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.1172 - acc: 0.9562 - precision_27: 0.9582 - recall_27: 0.9540\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1076 - acc: 0.9591 - precision_27: 0.9586 - recall_27: 0.9596\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1041 - acc: 0.9596 - precision_27: 0.9598 - recall_27: 0.9593\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0978 - acc: 0.9649 - precision_27: 0.9674 - recall_27: 0.9622\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0954 - acc: 0.9632 - precision_27: 0.9619 - recall_27: 0.9647\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.0894 - acc: 0.9669 - precision_27: 0.9694 - recall_27: 0.9642\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.0866 - acc: 0.9654 - precision_27: 0.9675 - recall_27: 0.9632\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.0811 - acc: 0.9692 - precision_27: 0.9704 - recall_27: 0.9678\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0813 - acc: 0.9680 - precision_27: 0.9701 - recall_27: 0.9657\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0731 - acc: 0.9729 - precision_27: 0.9743 - recall_27: 0.9713\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0733 - acc: 0.9744 - precision_27: 0.9735 - recall_27: 0.9754\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0703 - acc: 0.9739 - precision_27: 0.9730 - recall_27: 0.9749\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0668 - acc: 0.9746 - precision_27: 0.9749 - recall_27: 0.9742\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0701 - acc: 0.9721 - precision_27: 0.9722 - recall_27: 0.9720\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0608 - acc: 0.9780 - precision_27: 0.9785 - recall_27: 0.9773\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0627 - acc: 0.9781 - precision_27: 0.9776 - recall_27: 0.9786\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0543 - acc: 0.9806 - precision_27: 0.9815 - recall_27: 0.9798\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0514 - acc: 0.9810 - precision_27: 0.9817 - recall_27: 0.9803\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0520 - acc: 0.9815 - precision_27: 0.9827 - recall_27: 0.9803\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0535 - acc: 0.9804 - precision_27: 0.9814 - recall_27: 0.9793\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0490 - acc: 0.9832 - precision_27: 0.9813 - recall_27: 0.9851\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 0.7192 - acc: 0.8070 - precision_27: 0.7962 - recall_27: 0.8275\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.5567 - acc: 0.7145 - precision_28: 0.7351 - recall_28: 0.6689\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.4844 - acc: 0.7726 - precision_28: 0.7835 - recall_28: 0.7521\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.4483 - acc: 0.7925 - precision_28: 0.8048 - recall_28: 0.7714\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.4365 - acc: 0.8006 - precision_28: 0.8137 - recall_28: 0.7787\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.4174 - acc: 0.8089 - precision_28: 0.8204 - recall_28: 0.7899\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3982 - acc: 0.8163 - precision_28: 0.8246 - recall_28: 0.8026\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 27s 106ms/step - loss: 0.3837 - acc: 0.8237 - precision_28: 0.8300 - recall_28: 0.8134\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.3707 - acc: 0.8307 - precision_28: 0.8424 - recall_28: 0.8126\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.3595 - acc: 0.8393 - precision_28: 0.8459 - recall_28: 0.8290\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3388 - acc: 0.8478 - precision_28: 0.8516 - recall_28: 0.8417\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3331 - acc: 0.8482 - precision_28: 0.8540 - recall_28: 0.8392\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3150 - acc: 0.8607 - precision_28: 0.8651 - recall_28: 0.8541\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3036 - acc: 0.8658 - precision_28: 0.8719 - recall_28: 0.8570\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2803 - acc: 0.8787 - precision_28: 0.8834 - recall_28: 0.8722\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2694 - acc: 0.8823 - precision_28: 0.8878 - recall_28: 0.8746\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2612 - acc: 0.8876 - precision_28: 0.8950 - recall_28: 0.8778\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.2396 - acc: 0.8946 - precision_28: 0.9000 - recall_28: 0.8873\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2242 - acc: 0.9089 - precision_28: 0.9150 - recall_28: 0.9012\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2205 - acc: 0.9093 - precision_28: 0.9167 - recall_28: 0.9000\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.2029 - acc: 0.9160 - precision_28: 0.9203 - recall_28: 0.9105\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1927 - acc: 0.9190 - precision_28: 0.9225 - recall_28: 0.9146\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1905 - acc: 0.9204 - precision_28: 0.9204 - recall_28: 0.9200\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1739 - acc: 0.9278 - precision_28: 0.9316 - recall_28: 0.9232\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1636 - acc: 0.9350 - precision_28: 0.9376 - recall_28: 0.9317\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1552 - acc: 0.9374 - precision_28: 0.9414 - recall_28: 0.9327\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1392 - acc: 0.9466 - precision_28: 0.9474 - recall_28: 0.9454\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1375 - acc: 0.9487 - precision_28: 0.9514 - recall_28: 0.9456\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1273 - acc: 0.9501 - precision_28: 0.9518 - recall_28: 0.9480\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1163 - acc: 0.9552 - precision_28: 0.9567 - recall_28: 0.9534\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.1166 - acc: 0.9554 - precision_28: 0.9571 - recall_28: 0.9534\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1075 - acc: 0.9590 - precision_28: 0.9579 - recall_28: 0.9600\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.1033 - acc: 0.9612 - precision_28: 0.9610 - recall_28: 0.9612\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0979 - acc: 0.9629 - precision_28: 0.9647 - recall_28: 0.9607\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0879 - acc: 0.9686 - precision_28: 0.9690 - recall_28: 0.9680\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0947 - acc: 0.9645 - precision_28: 0.9664 - recall_28: 0.9622\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0792 - acc: 0.9709 - precision_28: 0.9728 - recall_28: 0.9688\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0809 - acc: 0.9718 - precision_28: 0.9724 - recall_28: 0.9710\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0771 - acc: 0.9716 - precision_28: 0.9717 - recall_28: 0.9715\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0747 - acc: 0.9724 - precision_28: 0.9715 - recall_28: 0.9732\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0765 - acc: 0.9729 - precision_28: 0.9722 - recall_28: 0.9734\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0659 - acc: 0.9761 - precision_28: 0.9761 - recall_28: 0.9761\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0695 - acc: 0.9754 - precision_28: 0.9737 - recall_28: 0.9771\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0631 - acc: 0.9775 - precision_28: 0.9778 - recall_28: 0.9771\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0586 - acc: 0.9791 - precision_28: 0.9804 - recall_28: 0.9776\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0568 - acc: 0.9792 - precision_28: 0.9793 - recall_28: 0.9790\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0539 - acc: 0.9809 - precision_28: 0.9807 - recall_28: 0.9810\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0503 - acc: 0.9842 - precision_28: 0.9844 - recall_28: 0.9839\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0558 - acc: 0.9792 - precision_28: 0.9793 - recall_28: 0.9790\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 27s 104ms/step - loss: 0.0462 - acc: 0.9853 - precision_28: 0.9851 - recall_28: 0.9854\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1496 - acc: 0.9453 - precision_28: 0.9469 - recall_28: 0.9434\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 0.7829 - acc: 0.7840 - precision_28: 0.7633 - recall_28: 0.8341\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.5565 - acc: 0.7180 - precision_29: 0.7224 - recall_29: 0.7101\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.4882 - acc: 0.7720 - precision_29: 0.7850 - recall_29: 0.7504\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.4593 - acc: 0.7885 - precision_29: 0.7996 - recall_29: 0.7711\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.4369 - acc: 0.7963 - precision_29: 0.8097 - recall_29: 0.7757\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.4241 - acc: 0.8057 - precision_29: 0.8150 - recall_29: 0.7920\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.4060 - acc: 0.8147 - precision_29: 0.8231 - recall_29: 0.8027\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3951 - acc: 0.8184 - precision_29: 0.8333 - recall_29: 0.7968\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.3783 - acc: 0.8237 - precision_29: 0.8335 - recall_29: 0.8100\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.3613 - acc: 0.8358 - precision_29: 0.8417 - recall_29: 0.8279\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.3457 - acc: 0.8445 - precision_29: 0.8500 - recall_29: 0.8374\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.3353 - acc: 0.8476 - precision_29: 0.8560 - recall_29: 0.8365\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.3191 - acc: 0.8534 - precision_29: 0.8613 - recall_29: 0.8433\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 27s 103ms/step - loss: 0.3058 - acc: 0.8628 - precision_29: 0.8673 - recall_29: 0.8574\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2935 - acc: 0.8728 - precision_29: 0.8746 - recall_29: 0.8710\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2716 - acc: 0.8795 - precision_29: 0.8846 - recall_29: 0.8734\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.2555 - acc: 0.8881 - precision_29: 0.8930 - recall_29: 0.8824\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.2435 - acc: 0.8940 - precision_29: 0.8975 - recall_29: 0.8899\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 25s 98ms/step - loss: 0.2323 - acc: 0.9004 - precision_29: 0.9043 - recall_29: 0.8960\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2179 - acc: 0.9070 - precision_29: 0.9078 - recall_29: 0.9064\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.2069 - acc: 0.9111 - precision_29: 0.9131 - recall_29: 0.9091\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.1850 - acc: 0.9254 - precision_29: 0.9290 - recall_29: 0.92 - 26s 100ms/step - loss: 0.1850 - acc: 0.9254 - precision_29: 0.9290 - recall_29: 0.9215\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1883 - acc: 0.9244 - precision_29: 0.9280 - recall_29: 0.9205\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 26s 99ms/step - loss: 0.1704 - acc: 0.9311 - precision_29: 0.9314 - recall_29: 0.9310\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1571 - acc: 0.9377 - precision_29: 0.9397 - recall_29: 0.9356\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1526 - acc: 0.9369 - precision_29: 0.9368 - recall_29: 0.9373\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 27s 105ms/step - loss: 0.1426 - acc: 0.9452 - precision_29: 0.9458 - recall_29: 0.9448\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1358 - acc: 0.9464 - precision_29: 0.9481 - recall_29: 0.9448\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.1317 - acc: 0.9489 - precision_29: 0.9496 - recall_29: 0.9482\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1190 - acc: 0.9518 - precision_29: 0.9510 - recall_29: 0.9529\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.1081 - acc: 0.9569 - precision_29: 0.9572 - recall_29: 0.9567\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.1089 - acc: 0.9567 - precision_29: 0.9590 - recall_29: 0.9543\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0937 - acc: 0.9648 - precision_29: 0.9630 - recall_29: 0.9670\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0986 - acc: 0.9624 - precision_29: 0.9630 - recall_29: 0.9618\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0851 - acc: 0.9679 - precision_29: 0.9675 - recall_29: 0.9684\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0915 - acc: 0.9663 - precision_29: 0.9674 - recall_29: 0.9652\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0848 - acc: 0.9693 - precision_29: 0.9696 - recall_29: 0.9691\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 26s 103ms/step - loss: 0.0724 - acc: 0.9739 - precision_29: 0.9742 - recall_29: 0.9738\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0656 - acc: 0.9748 - precision_29: 0.9747 - recall_29: 0.9750\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0725 - acc: 0.9716 - precision_29: 0.9727 - recall_29: 0.9706\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0650 - acc: 0.9754 - precision_29: 0.9768 - recall_29: 0.9740\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 25s 99ms/step - loss: 0.0727 - acc: 0.9733 - precision_29: 0.9747 - recall_29: 0.9721\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0716 - acc: 0.9742 - precision_29: 0.9747 - recall_29: 0.9738\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0625 - acc: 0.9776 - precision_29: 0.9756 - recall_29: 0.9798\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0500 - acc: 0.9816 - precision_29: 0.9818 - recall_29: 0.9815\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0547 - acc: 0.9805 - precision_29: 0.9796 - recall_29: 0.9815\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0549 - acc: 0.9814 - precision_29: 0.9827 - recall_29: 0.9801\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0528 - acc: 0.9819 - precision_29: 0.9806 - recall_29: 0.9832\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 26s 100ms/step - loss: 0.0494 - acc: 0.9826 - precision_29: 0.9837 - recall_29: 0.9815\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 26s 102ms/step - loss: 0.0595 - acc: 0.9783 - precision_29: 0.9795 - recall_29: 0.9772\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 26s 101ms/step - loss: 0.0511 - acc: 0.9817 - precision_29: 0.9815 - recall_29: 0.9820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 28ms/step - loss: 0.7944 - acc: 0.8026 - precision_29: 0.7851 - recall_29: 0.8237\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=1)\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "\n",
    "    modelLSTM = Sequential()\n",
    "    modelLSTM.add(embedding_layer)\n",
    "    modelLSTM.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    modelLSTM.add(Dense(1, activation='sigmoid'))\n",
    "    modelLSTM.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelLSTM.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelLSTM.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.793885\n",
      "test precision: 0.775448\n",
      "test recall: 0.827498\n",
      "test f1_score: 0.800373\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn+lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.5588 - acc: 0.7124 - precision_30: 0.7266 - recall_30: 0.6858\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.4348 - acc: 0.8014 - precision_30: 0.8163 - recall_30: 0.7805\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3468 - acc: 0.8448 - precision_30: 0.8564 - recall_30: 0.8304\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2747 - acc: 0.8829 - precision_30: 0.8888 - recall_30: 0.8767\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2061 - acc: 0.9207 - precision_30: 0.9235 - recall_30: 0.9184\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1488 - acc: 0.9417 - precision_30: 0.9410 - recall_30: 0.9431\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1165 - acc: 0.9560 - precision_30: 0.9566 - recall_30: 0.9559\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0994 - acc: 0.9608 - precision_30: 0.9610 - recall_30: 0.9610\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0852 - acc: 0.9677 - precision_30: 0.9671 - recall_30: 0.9688\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0643 - acc: 0.9743 - precision_30: 0.9732 - recall_30: 0.9758\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0672 - acc: 0.9758 - precision_30: 0.9765 - recall_30: 0.9753\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0524 - acc: 0.9799 - precision_30: 0.9792 - recall_30: 0.9809\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0508 - acc: 0.9814 - precision_30: 0.9807 - recall_30: 0.9823\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0474 - acc: 0.9822 - precision_30: 0.9835 - recall_30: 0.9811\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0504 - acc: 0.9805 - precision_30: 0.9809 - recall_30: 0.9804\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0449 - acc: 0.9837 - precision_30: 0.9840 - recall_30: 0.9835\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0445 - acc: 0.9828 - precision_30: 0.9819 - recall_30: 0.9840\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0401 - acc: 0.9855 - precision_30: 0.9869 - recall_30: 0.9843\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0360 - acc: 0.9860 - precision_30: 0.9852 - recall_30: 0.9869\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0353 - acc: 0.9873 - precision_30: 0.9886 - recall_30: 0.9862\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0269 - acc: 0.9905 - precision_30: 0.9910 - recall_30: 0.9901\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0289 - acc: 0.9898 - precision_30: 0.9898 - recall_30: 0.9898\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0366 - acc: 0.9859 - precision_30: 0.9881 - recall_30: 0.9838\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0323 - acc: 0.9860 - precision_30: 0.9862 - recall_30: 0.9859\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0304 - acc: 0.9889 - precision_30: 0.9879 - recall_30: 0.9901\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0293 - acc: 0.9892 - precision_30: 0.9891 - recall_30: 0.9893\n",
      "Epoch 00026: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.2854 - acc: 0.7448 - precision_30: 0.7036 - recall_30: 0.8023\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.5388 - acc: 0.7330 - precision_31: 0.7371 - recall_31: 0.7269\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4073 - acc: 0.8178 - precision_31: 0.8314 - recall_31: 0.7987\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3270 - acc: 0.8579 - precision_31: 0.8679 - recall_31: 0.8454\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2397 - acc: 0.9033 - precision_31: 0.9076 - recall_31: 0.8988\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1834 - acc: 0.9284 - precision_31: 0.9301 - recall_31: 0.9269\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1302 - acc: 0.9515 - precision_31: 0.9523 - recall_31: 0.9510\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0984 - acc: 0.9646 - precision_31: 0.9657 - recall_31: 0.9636\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0717 - acc: 0.9744 - precision_31: 0.9745 - recall_31: 0.9745\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0525 - acc: 0.9819 - precision_31: 0.9818 - recall_31: 0.9820\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0649 - acc: 0.9767 - precision_31: 0.9762 - recall_31: 0.9774\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0489 - acc: 0.9827 - precision_31: 0.9821 - recall_31: 0.9835\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0438 - acc: 0.9855 - precision_31: 0.9861 - recall_31: 0.9849\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0363 - acc: 0.9887 - precision_31: 0.9884 - recall_31: 0.9891\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0351 - acc: 0.9886 - precision_31: 0.9881 - recall_31: 0.9891\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0336 - acc: 0.9877 - precision_31: 0.9879 - recall_31: 0.9876\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0342 - acc: 0.9879 - precision_31: 0.9888 - recall_31: 0.9871\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0348 - acc: 0.9900 - precision_31: 0.9915 - recall_31: 0.9886\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0266 - acc: 0.9910 - precision_31: 0.9913 - recall_31: 0.9908\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0258 - acc: 0.9914 - precision_31: 0.9903 - recall_31: 0.9925\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0239 - acc: 0.9928 - precision_31: 0.9920 - recall_31: 0.9937\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0377 - acc: 0.9866 - precision_31: 0.9864 - recall_31: 0.9869\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0240 - acc: 0.9925 - precision_31: 0.9932 - recall_31: 0.9917\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0169 - acc: 0.9942 - precision_31: 0.9942 - recall_31: 0.9942\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0194 - acc: 0.9927 - precision_31: 0.9922 - recall_31: 0.9932\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0284 - acc: 0.9915 - precision_31: 0.9915 - recall_31: 0.9915\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0229 - acc: 0.9918 - precision_31: 0.9927 - recall_31: 0.9910\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0255 - acc: 0.9909 - precision_31: 0.9903 - recall_31: 0.9915\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0145 - acc: 0.9959 - precision_31: 0.9964 - recall_31: 0.9954\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0231 - acc: 0.9926 - precision_31: 0.9932 - recall_31: 0.9920\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0150 - acc: 0.9946 - precision_31: 0.9947 - recall_31: 0.9947\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0228 - acc: 0.9921 - precision_31: 0.9927 - recall_31: 0.9915\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0133 - acc: 0.9953 - precision_31: 0.9954 - recall_31: 0.9951\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0205 - acc: 0.9929 - precision_31: 0.9925 - recall_31: 0.9934\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0238 - acc: 0.9922 - precision_31: 0.9915 - recall_31: 0.9930\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0161 - acc: 0.9945 - precision_31: 0.9947 - recall_31: 0.9944\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0140 - acc: 0.9956 - precision_31: 0.9956 - recall_31: 0.9956\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0126 - acc: 0.9949 - precision_31: 0.9947 - recall_31: 0.9951\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0282 - acc: 0.9888 - precision_31: 0.9900 - recall_31: 0.9876\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0107 - acc: 0.9961 - precision_31: 0.9956 - recall_31: 0.9966\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0166 - acc: 0.9956 - precision_31: 0.9951 - recall_31: 0.9961\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0171 - acc: 0.9944 - precision_31: 0.9939 - recall_31: 0.9949\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0094 - acc: 0.9973 - precision_31: 0.9966 - recall_31: 0.9981\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0159 - acc: 0.9940 - precision_31: 0.9939 - recall_31: 0.9942\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0130 - acc: 0.9955 - precision_31: 0.9956 - recall_31: 0.9954\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0180 - acc: 0.9933 - precision_31: 0.9939 - recall_31: 0.9927\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0128 - acc: 0.9946 - precision_31: 0.9944 - recall_31: 0.9949\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0126 - acc: 0.9959 - precision_31: 0.9964 - recall_31: 0.9954\n",
      "Epoch 00047: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.2276 - acc: 0.7798 - precision_31: 0.7297 - recall_31: 0.8694\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.5598 - acc: 0.7175 - precision_32: 0.7152 - recall_32: 0.7236\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4353 - acc: 0.7992 - precision_32: 0.8110 - recall_32: 0.7808\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.3485 - acc: 0.8435 - precision_32: 0.8504 - recall_32: 0.8341\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2686 - acc: 0.8859 - precision_32: 0.8918 - recall_32: 0.8786\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1998 - acc: 0.9215 - precision_32: 0.9237 - recall_32: 0.9190\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1395 - acc: 0.9444 - precision_32: 0.9458 - recall_32: 0.9428\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1093 - acc: 0.9579 - precision_32: 0.9575 - recall_32: 0.9584\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1051 - acc: 0.9570 - precision_32: 0.9578 - recall_32: 0.9562\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0789 - acc: 0.9700 - precision_32: 0.9703 - recall_32: 0.9698\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0614 - acc: 0.9743 - precision_32: 0.9738 - recall_32: 0.9749\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0605 - acc: 0.9771 - precision_32: 0.9785 - recall_32: 0.9757\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0524 - acc: 0.9782 - precision_32: 0.9786 - recall_32: 0.9779\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0547 - acc: 0.9793 - precision_32: 0.9800 - recall_32: 0.9786\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0488 - acc: 0.9810 - precision_32: 0.9806 - recall_32: 0.9815\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0477 - acc: 0.9819 - precision_32: 0.9827 - recall_32: 0.9810\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0375 - acc: 0.9865 - precision_32: 0.9869 - recall_32: 0.9861\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0300 - acc: 0.9893 - precision_32: 0.9891 - recall_32: 0.9895\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0425 - acc: 0.9830 - precision_32: 0.9834 - recall_32: 0.9825\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0346 - acc: 0.9869 - precision_32: 0.9866 - recall_32: 0.9871\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0379 - acc: 0.9853 - precision_32: 0.9856 - recall_32: 0.9849\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0255 - acc: 0.9894 - precision_32: 0.9900 - recall_32: 0.9888\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0411 - acc: 0.9855 - precision_32: 0.9852 - recall_32: 0.9859\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0269 - acc: 0.9900 - precision_32: 0.9922 - recall_32: 0.9878\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0373 - acc: 0.9870 - precision_32: 0.9871 - recall_32: 0.9869\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0260 - acc: 0.9895 - precision_32: 0.9893 - recall_32: 0.9898\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0328 - acc: 0.9859 - precision_32: 0.9849 - recall_32: 0.9869\n",
      "Epoch 00026: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0956 - acc: 0.7612 - precision_32: 0.7463 - recall_32: 0.7859\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5596 - acc: 0.7164 - precision_33: 0.7216 - recall_33: 0.7046\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4302 - acc: 0.8025 - precision_33: 0.8125 - recall_33: 0.7864\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.3590 - acc: 0.8394 - precision_33: 0.8467 - recall_33: 0.8288\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2789 - acc: 0.8836 - precision_33: 0.8887 - recall_33: 0.8770\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2034 - acc: 0.9174 - precision_33: 0.9236 - recall_33: 0.9101\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1574 - acc: 0.9355 - precision_33: 0.9329 - recall_33: 0.9384\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1172 - acc: 0.9556 - precision_33: 0.9546 - recall_33: 0.9566\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0921 - acc: 0.9635 - precision_33: 0.9648 - recall_33: 0.9620\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0838 - acc: 0.9690 - precision_33: 0.9670 - recall_33: 0.9710\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0743 - acc: 0.9715 - precision_33: 0.9727 - recall_33: 0.9703\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0546 - acc: 0.9802 - precision_33: 0.9826 - recall_33: 0.9776\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0493 - acc: 0.9823 - precision_33: 0.9827 - recall_33: 0.9820\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0572 - acc: 0.9756 - precision_33: 0.9752 - recall_33: 0.9761\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0485 - acc: 0.9812 - precision_33: 0.9817 - recall_33: 0.9808\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0485 - acc: 0.9825 - precision_33: 0.9832 - recall_33: 0.9817\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0410 - acc: 0.9843 - precision_33: 0.9832 - recall_33: 0.9854\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0392 - acc: 0.9854 - precision_33: 0.9856 - recall_33: 0.9851\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0466 - acc: 0.9826 - precision_33: 0.9829 - recall_33: 0.9822\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0374 - acc: 0.9871 - precision_33: 0.9880 - recall_33: 0.9861\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0358 - acc: 0.9864 - precision_33: 0.9878 - recall_33: 0.9849\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0288 - acc: 0.9892 - precision_33: 0.9898 - recall_33: 0.9886\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0229 - acc: 0.9911 - precision_33: 0.9915 - recall_33: 0.9907\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0418 - acc: 0.9858 - precision_33: 0.9847 - recall_33: 0.9868\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0318 - acc: 0.9884 - precision_33: 0.9897 - recall_33: 0.9871\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0310 - acc: 0.9886 - precision_33: 0.9895 - recall_33: 0.9876\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0267 - acc: 0.9901 - precision_33: 0.9893 - recall_33: 0.9910\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0346 - acc: 0.9853 - precision_33: 0.9861 - recall_33: 0.9844\n",
      "Epoch 00027: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1155 - acc: 0.7601 - precision_33: 0.7469 - recall_33: 0.7877\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.5594 - acc: 0.7108 - precision_34: 0.7223 - recall_34: 0.6848\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.4290 - acc: 0.8029 - precision_34: 0.8123 - recall_34: 0.7876\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3488 - acc: 0.8444 - precision_34: 0.8500 - recall_34: 0.8363\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2724 - acc: 0.8802 - precision_34: 0.8843 - recall_34: 0.8748\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1966 - acc: 0.9205 - precision_34: 0.9249 - recall_34: 0.9152\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1401 - acc: 0.9448 - precision_34: 0.9462 - recall_34: 0.9432\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1145 - acc: 0.9535 - precision_34: 0.9511 - recall_34: 0.9562\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0959 - acc: 0.9636 - precision_34: 0.9623 - recall_34: 0.9649\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0815 - acc: 0.9671 - precision_34: 0.9669 - recall_34: 0.9674\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0649 - acc: 0.9746 - precision_34: 0.9751 - recall_34: 0.9739\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0617 - acc: 0.9781 - precision_34: 0.9785 - recall_34: 0.9776\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0552 - acc: 0.9797 - precision_34: 0.9802 - recall_34: 0.9790\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0487 - acc: 0.9812 - precision_34: 0.9810 - recall_34: 0.9815\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0418 - acc: 0.9830 - precision_34: 0.9827 - recall_34: 0.9832\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0434 - acc: 0.9833 - precision_34: 0.9856 - recall_34: 0.9810\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0434 - acc: 0.9842 - precision_34: 0.9858 - recall_34: 0.9825\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0345 - acc: 0.9864 - precision_34: 0.9878 - recall_34: 0.9849\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0384 - acc: 0.9833 - precision_34: 0.9837 - recall_34: 0.9829\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0347 - acc: 0.9871 - precision_34: 0.9869 - recall_34: 0.9873\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0387 - acc: 0.9856 - precision_34: 0.9861 - recall_34: 0.9851\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0279 - acc: 0.9901 - precision_34: 0.9912 - recall_34: 0.9890\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0342 - acc: 0.9877 - precision_34: 0.9885 - recall_34: 0.9868\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0296 - acc: 0.9884 - precision_34: 0.9890 - recall_34: 0.9878\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0248 - acc: 0.9898 - precision_34: 0.9907 - recall_34: 0.9888\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0296 - acc: 0.9886 - precision_34: 0.9893 - recall_34: 0.9878\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0245 - acc: 0.9909 - precision_34: 0.9910 - recall_34: 0.9907\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0234 - acc: 0.9904 - precision_34: 0.9900 - recall_34: 0.9907\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0339 - acc: 0.9876 - precision_34: 0.9869 - recall_34: 0.9883\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0301 - acc: 0.9883 - precision_34: 0.9897 - recall_34: 0.9868\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0263 - acc: 0.9903 - precision_34: 0.9907 - recall_34: 0.9898\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0254 - acc: 0.9898 - precision_34: 0.9912 - recall_34: 0.9883\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0238 - acc: 0.9904 - precision_34: 0.9907 - recall_34: 0.9900\n",
      "Epoch 00032: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.2802 - acc: 0.7612 - precision_34: 0.7510 - recall_34: 0.7838 0s - loss: 1.3663 - acc: 0.7515 - precision_34: 0.7349 - recall_34: \n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5624 - acc: 0.7133 - precision_35: 0.7285 - recall_35: 0.6775\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.4383 - acc: 0.7987 - precision_35: 0.8079 - recall_35: 0.7825\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.3548 - acc: 0.8409 - precision_35: 0.8431 - recall_35: 0.8367\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2709 - acc: 0.8888 - precision_35: 0.8923 - recall_35: 0.8838\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2066 - acc: 0.9140 - precision_35: 0.9146 - recall_35: 0.9128\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1455 - acc: 0.9386 - precision_35: 0.9393 - recall_35: 0.9375\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.1139 - acc: 0.9552 - precision_35: 0.9529 - recall_35: 0.9575\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0920 - acc: 0.9642 - precision_35: 0.9643 - recall_35: 0.9639\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0766 - acc: 0.9699 - precision_35: 0.9679 - recall_35: 0.9719\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0654 - acc: 0.9775 - precision_35: 0.9766 - recall_35: 0.9783\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0545 - acc: 0.9787 - precision_35: 0.9781 - recall_35: 0.9792\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0581 - acc: 0.9761 - precision_35: 0.9747 - recall_35: 0.9775\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0443 - acc: 0.9822 - precision_35: 0.9815 - recall_35: 0.9829\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0482 - acc: 0.9811 - precision_35: 0.9798 - recall_35: 0.9824\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0480 - acc: 0.9804 - precision_35: 0.9795 - recall_35: 0.9812\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0445 - acc: 0.9843 - precision_35: 0.9839 - recall_35: 0.9846\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0361 - acc: 0.9872 - precision_35: 0.9883 - recall_35: 0.9861\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0367 - acc: 0.9861 - precision_35: 0.9854 - recall_35: 0.9868\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0374 - acc: 0.9851 - precision_35: 0.9837 - recall_35: 0.9866\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0309 - acc: 0.9890 - precision_35: 0.9890 - recall_35: 0.9890\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0313 - acc: 0.9875 - precision_35: 0.9880 - recall_35: 0.9868\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0277 - acc: 0.9894 - precision_35: 0.9905 - recall_35: 0.9883\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0216 - acc: 0.9915 - precision_35: 0.9917 - recall_35: 0.9912\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0316 - acc: 0.9881 - precision_35: 0.9885 - recall_35: 0.9875\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0337 - acc: 0.9876 - precision_35: 0.9878 - recall_35: 0.9873\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0322 - acc: 0.9879 - precision_35: 0.9892 - recall_35: 0.9866\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0221 - acc: 0.9911 - precision_35: 0.9907 - recall_35: 0.9915\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0307 - acc: 0.9873 - precision_35: 0.9866 - recall_35: 0.9880\n",
      "Epoch 00028: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1170 - acc: 0.7788 - precision_35: 0.7634 - recall_35: 0.8223\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5631 - acc: 0.7101 - precision_36: 0.7201 - recall_36: 0.6792\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.4351 - acc: 0.7992 - precision_36: 0.8050 - recall_36: 0.7851\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3497 - acc: 0.8456 - precision_36: 0.8475 - recall_36: 0.8396\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.2698 - acc: 0.8830 - precision_36: 0.8878 - recall_36: 0.8745\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1942 - acc: 0.9223 - precision_36: 0.9241 - recall_36: 0.9187\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1457 - acc: 0.9430 - precision_36: 0.9456 - recall_36: 0.9391\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1157 - acc: 0.9543 - precision_36: 0.9523 - recall_36: 0.9558\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0870 - acc: 0.9663 - precision_36: 0.9668 - recall_36: 0.9651\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0806 - acc: 0.9690 - precision_36: 0.9706 - recall_36: 0.9666\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0645 - acc: 0.9763 - precision_36: 0.9769 - recall_36: 0.9752\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0606 - acc: 0.9775 - precision_36: 0.9779 - recall_36: 0.9767\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0571 - acc: 0.9780 - precision_36: 0.9786 - recall_36: 0.9769\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0455 - acc: 0.9838 - precision_36: 0.9852 - recall_36: 0.9821\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0465 - acc: 0.9832 - precision_36: 0.9835 - recall_36: 0.9826\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0373 - acc: 0.9860 - precision_36: 0.9862 - recall_36: 0.9855\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0399 - acc: 0.9854 - precision_36: 0.9867 - recall_36: 0.9838\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0373 - acc: 0.9849 - precision_36: 0.9852 - recall_36: 0.9843\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0353 - acc: 0.9873 - precision_36: 0.9879 - recall_36: 0.9865\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0379 - acc: 0.9862 - precision_36: 0.9867 - recall_36: 0.9855\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0329 - acc: 0.9886 - precision_36: 0.9877 - recall_36: 0.9892\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0289 - acc: 0.9887 - precision_36: 0.9894 - recall_36: 0.9877\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0308 - acc: 0.9895 - precision_36: 0.9919 - recall_36: 0.9870\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0310 - acc: 0.9882 - precision_36: 0.9887 - recall_36: 0.9875\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0339 - acc: 0.9877 - precision_36: 0.9877 - recall_36: 0.9875\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0249 - acc: 0.9918 - precision_36: 0.9921 - recall_36: 0.9914\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0244 - acc: 0.9906 - precision_36: 0.9914 - recall_36: 0.9897\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0315 - acc: 0.9881 - precision_36: 0.9889 - recall_36: 0.9870\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0213 - acc: 0.9928 - precision_36: 0.9948 - recall_36: 0.9907\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0213 - acc: 0.9923 - precision_36: 0.9936 - recall_36: 0.9909\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0346 - acc: 0.9873 - precision_36: 0.9901 - recall_36: 0.9843\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0279 - acc: 0.9898 - precision_36: 0.9906 - recall_36: 0.9887\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0255 - acc: 0.9903 - precision_36: 0.9907 - recall_36: 0.9897\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0207 - acc: 0.9928 - precision_36: 0.9938 - recall_36: 0.9916\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0186 - acc: 0.9925 - precision_36: 0.9941 - recall_36: 0.9907\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0181 - acc: 0.9931 - precision_36: 0.9941 - recall_36: 0.9919\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0215 - acc: 0.9922 - precision_36: 0.9929 - recall_36: 0.9914\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0150 - acc: 0.9939 - precision_36: 0.9948 - recall_36: 0.9929\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0219 - acc: 0.9927 - precision_36: 0.9938 - recall_36: 0.9914\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0286 - acc: 0.9892 - precision_36: 0.9909 - recall_36: 0.9872\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0160 - acc: 0.9948 - precision_36: 0.9963 - recall_36: 0.9931\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0310 - acc: 0.9892 - precision_36: 0.9894 - recall_36: 0.9887\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0176 - acc: 0.9943 - precision_36: 0.9958 - recall_36: 0.9926\n",
      "Epoch 00042: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.3575 - acc: 0.7478 - precision_36: 0.7641 - recall_36: 0.7703\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5591 - acc: 0.7168 - precision_37: 0.7248 - recall_37: 0.7026\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4301 - acc: 0.7974 - precision_37: 0.8118 - recall_37: 0.7764\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3526 - acc: 0.8430 - precision_37: 0.8525 - recall_37: 0.8309\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2703 - acc: 0.8850 - precision_37: 0.8912 - recall_37: 0.8780\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2069 - acc: 0.9153 - precision_37: 0.9172 - recall_37: 0.9137\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1495 - acc: 0.9393 - precision_37: 0.9407 - recall_37: 0.9382\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1161 - acc: 0.9540 - precision_37: 0.9562 - recall_37: 0.9520\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1049 - acc: 0.9603 - precision_37: 0.9598 - recall_37: 0.9612\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0760 - acc: 0.9692 - precision_37: 0.9694 - recall_37: 0.9692\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0696 - acc: 0.9709 - precision_37: 0.9716 - recall_37: 0.9704\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0619 - acc: 0.9749 - precision_37: 0.9759 - recall_37: 0.9740\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0535 - acc: 0.9809 - precision_37: 0.9808 - recall_37: 0.9811\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0526 - acc: 0.9795 - precision_37: 0.9806 - recall_37: 0.9787\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0468 - acc: 0.9823 - precision_37: 0.9823 - recall_37: 0.9825\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0415 - acc: 0.9849 - precision_37: 0.9840 - recall_37: 0.9859\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0543 - acc: 0.9791 - precision_37: 0.9796 - recall_37: 0.9787\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0394 - acc: 0.9853 - precision_37: 0.9871 - recall_37: 0.9835\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0274 - acc: 0.9898 - precision_37: 0.9905 - recall_37: 0.9891\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0351 - acc: 0.9869 - precision_37: 0.9878 - recall_37: 0.9859\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0346 - acc: 0.9879 - precision_37: 0.9898 - recall_37: 0.9862\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0403 - acc: 0.9842 - precision_37: 0.9849 - recall_37: 0.9835\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0345 - acc: 0.9876 - precision_37: 0.9876 - recall_37: 0.9876\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0249 - acc: 0.9917 - precision_37: 0.9937 - recall_37: 0.9898\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0330 - acc: 0.9877 - precision_37: 0.9881 - recall_37: 0.9874\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0281 - acc: 0.9903 - precision_37: 0.9905 - recall_37: 0.9901\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0255 - acc: 0.9899 - precision_37: 0.9896 - recall_37: 0.9903\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0250 - acc: 0.9910 - precision_37: 0.9922 - recall_37: 0.9898\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0330 - acc: 0.9889 - precision_37: 0.9910 - recall_37: 0.9869\n",
      "Epoch 00028: early stopping\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1976 - acc: 0.7730 - precision_37: 0.7618 - recall_37: 0.7705\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.5597 - acc: 0.7089 - precision_38: 0.7202 - recall_38: 0.6807\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4353 - acc: 0.8051 - precision_38: 0.8167 - recall_38: 0.7854\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.3528 - acc: 0.8442 - precision_38: 0.8529 - recall_38: 0.8308\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2756 - acc: 0.8826 - precision_38: 0.8896 - recall_38: 0.8730\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1932 - acc: 0.9222 - precision_38: 0.9286 - recall_38: 0.9143\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1428 - acc: 0.9435 - precision_38: 0.9438 - recall_38: 0.9429\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1195 - acc: 0.9540 - precision_38: 0.9514 - recall_38: 0.9565\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0878 - acc: 0.9681 - precision_38: 0.9692 - recall_38: 0.9668\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0789 - acc: 0.9687 - precision_38: 0.9669 - recall_38: 0.9705\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0672 - acc: 0.9739 - precision_38: 0.9739 - recall_38: 0.9739\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0559 - acc: 0.9788 - precision_38: 0.9783 - recall_38: 0.9792\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0545 - acc: 0.9777 - precision_38: 0.9766 - recall_38: 0.9788\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0494 - acc: 0.9819 - precision_38: 0.9815 - recall_38: 0.9822\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0529 - acc: 0.9766 - precision_38: 0.9759 - recall_38: 0.9773\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0400 - acc: 0.9855 - precision_38: 0.9858 - recall_38: 0.9851\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0395 - acc: 0.9849 - precision_38: 0.9851 - recall_38: 0.9846\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0379 - acc: 0.9856 - precision_38: 0.9861 - recall_38: 0.9851\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0421 - acc: 0.9837 - precision_38: 0.9834 - recall_38: 0.9839\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0367 - acc: 0.9864 - precision_38: 0.9868 - recall_38: 0.9858\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0371 - acc: 0.9841 - precision_38: 0.9839 - recall_38: 0.9841\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0328 - acc: 0.9865 - precision_38: 0.9870 - recall_38: 0.9858\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0295 - acc: 0.9877 - precision_38: 0.9885 - recall_38: 0.9868\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0380 - acc: 0.9862 - precision_38: 0.9870 - recall_38: 0.9854\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0296 - acc: 0.9882 - precision_38: 0.9876 - recall_38: 0.9888\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0355 - acc: 0.9860 - precision_38: 0.9866 - recall_38: 0.9854\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0313 - acc: 0.9901 - precision_38: 0.9914 - recall_38: 0.9888\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0266 - acc: 0.9897 - precision_38: 0.9902 - recall_38: 0.9890\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0250 - acc: 0.9903 - precision_38: 0.9907 - recall_38: 0.9897\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0338 - acc: 0.9877 - precision_38: 0.9887 - recall_38: 0.9866\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0186 - acc: 0.9923 - precision_38: 0.9924 - recall_38: 0.9922\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0219 - acc: 0.9905 - precision_38: 0.9910 - recall_38: 0.9900\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0325 - acc: 0.9872 - precision_38: 0.9864 - recall_38: 0.9880\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0253 - acc: 0.9895 - precision_38: 0.9897 - recall_38: 0.9893\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0256 - acc: 0.9905 - precision_38: 0.9900 - recall_38: 0.9910\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0155 - acc: 0.9929 - precision_38: 0.9936 - recall_38: 0.9922\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0196 - acc: 0.9923 - precision_38: 0.9929 - recall_38: 0.9917\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0239 - acc: 0.9904 - precision_38: 0.9912 - recall_38: 0.9895\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0161 - acc: 0.9935 - precision_38: 0.9944 - recall_38: 0.9927\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0271 - acc: 0.9884 - precision_38: 0.9888 - recall_38: 0.9880\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0243 - acc: 0.9915 - precision_38: 0.9919 - recall_38: 0.9910\n",
      "Epoch 00040: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.2531 - acc: 0.7697 - precision_38: 0.8142 - recall_38: 0.7131\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.5561 - acc: 0.7121 - precision_39: 0.7177 - recall_39: 0.7005\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.4306 - acc: 0.8019 - precision_39: 0.8112 - recall_39: 0.7877\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3564 - acc: 0.8423 - precision_39: 0.8496 - recall_39: 0.8325\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.2706 - acc: 0.8830 - precision_39: 0.8907 - recall_39: 0.8736\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1998 - acc: 0.9150 - precision_39: 0.9156 - recall_39: 0.9147\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1450 - acc: 0.9419 - precision_39: 0.9417 - recall_39: 0.9424\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1013 - acc: 0.9596 - precision_39: 0.9590 - recall_39: 0.9604\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1059 - acc: 0.9567 - precision_39: 0.9574 - recall_39: 0.9560\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0774 - acc: 0.9699 - precision_39: 0.9710 - recall_39: 0.9689\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0606 - acc: 0.9767 - precision_39: 0.9767 - recall_39: 0.9769\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0668 - acc: 0.9749 - precision_39: 0.9717 - recall_39: 0.9784\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0537 - acc: 0.9792 - precision_39: 0.9784 - recall_39: 0.9801\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0464 - acc: 0.9832 - precision_39: 0.9816 - recall_39: 0.9849\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0473 - acc: 0.9817 - precision_39: 0.9822 - recall_39: 0.9813\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0428 - acc: 0.9838 - precision_39: 0.9844 - recall_39: 0.9832\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0423 - acc: 0.9842 - precision_39: 0.9851 - recall_39: 0.9832\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0395 - acc: 0.9851 - precision_39: 0.9856 - recall_39: 0.9847\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0331 - acc: 0.9875 - precision_39: 0.9874 - recall_39: 0.9876\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0330 - acc: 0.9872 - precision_39: 0.9862 - recall_39: 0.9883\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0392 - acc: 0.9837 - precision_39: 0.9835 - recall_39: 0.9840\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0299 - acc: 0.9888 - precision_39: 0.9888 - recall_39: 0.9888\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0254 - acc: 0.9909 - precision_39: 0.9915 - recall_39: 0.9903\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0300 - acc: 0.9890 - precision_39: 0.9903 - recall_39: 0.9878\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0324 - acc: 0.9876 - precision_39: 0.9888 - recall_39: 0.9864\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0344 - acc: 0.9872 - precision_39: 0.9864 - recall_39: 0.9881\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0342 - acc: 0.9861 - precision_39: 0.9861 - recall_39: 0.9861\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0271 - acc: 0.9903 - precision_39: 0.9900 - recall_39: 0.9905\n",
      "Epoch 00027: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1797 - acc: 0.7610 - precision_39: 0.7231 - recall_39: 0.8356\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= fasttext (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNNLSTM = Sequential() #cnn\n",
    "\n",
    "    modelCNNLSTM.add(embedding_layer)\n",
    "    modelCNNLSTM.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "    modelCNNLSTM.add(MaxPooling1D(pool_size=4))\n",
    "    modelCNNLSTM.add(Dropout(0.25))\n",
    "    modelCNNLSTM.add(LSTM(128))                            \n",
    "    modelCNNLSTM.add(Flatten())\n",
    "    modelCNNLSTM.add(Dense(1, activation='sigmoid'))\n",
    "    modelCNNLSTM.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNNLSTM.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelCNNLSTM.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.763752\n",
      "test precision: 0.750416\n",
      "test recall: 0.794080\n",
      "test f1_score: 0.770320\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
