{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['tweets','duygu','preprocessing']\n",
    "#df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "\n",
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hayatimda verdigim en en dogru uc karar arasin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yil 2015 oldu hala internet çekmiyor  turkcell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kaan_terzioglu yanında kalıyoruz turkcell fat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jasoniks ooo buram buram turkcell plaza çalış...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>size 20 yıldır dünyaları ödedim ama siz platin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>turkcell'den köylere 4,5g hizmeti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>turkcell adam akıllı tek bir reklamın yok amk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>turkcell:turkiye'nin cekim gucu amerika'yi gec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>birideçıkıpdemiyorki bu kızın televizyonu yok ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell canlı hizmet diye bir şey var ne güze...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     hayatimda verdigim en en dogru uc karar arasin...     0\n",
       "1        yil 2015 oldu hala internet çekmiyor  turkcell     0\n",
       "2     @kaan_terzioglu yanında kalıyoruz turkcell fat...     0\n",
       "3     @jasoniks ooo buram buram turkcell plaza çalış...     1\n",
       "4     size 20 yıldır dünyaları ödedim ama siz platin...     0\n",
       "...                                                 ...   ...\n",
       "9121                  turkcell'den köylere 4,5g hizmeti     1\n",
       "9122      turkcell adam akıllı tek bir reklamın yok amk     0\n",
       "9123  turkcell:turkiye'nin cekim gucu amerika'yi gec...     0\n",
       "9124  birideçıkıpdemiyorki bu kızın televizyonu yok ...     1\n",
       "9125  turkcell canlı hizmet diye bir şey var ne güze...     1\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=df['tweets'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tokenizer\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "# Building word indices\n",
    "tokenizer.fit_on_texts(X_t)\n",
    "# Tokenizing sentences\n",
    "sentences = tokenizer.texts_to_sequences(X_t)\n",
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "# Creating texts \n",
    "X_t = list(map(sequence_to_text, sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.21199584007263\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "start=time.time()\n",
    "n_features=32\n",
    "window_size=5\n",
    "min_count=1\n",
    "epoch=50\n",
    "n_workers=8\n",
    "\n",
    "wordembeddings = Word2Vec(size = n_features,\n",
    "            window = window_size, \n",
    "            min_count= min_count,\n",
    "            workers = n_workers, \n",
    "            sg=1)\n",
    "wordembeddings.build_vocab(X_t)\n",
    "wordembeddings.train(X_t, \n",
    "            total_examples=wordembeddings.corpus_count,  \n",
    "            epochs = epoch)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec (X_train,y_train,X_test,y_test):\n",
    "    #Create a tokenizer, configured to only take into account the 20 most common words çok küçük olursa kelimeleri \n",
    "    #kaybederiz underfit yaparız\n",
    "    #tokenizer = Tokenizer(lower=True) #en yaygın kaç kelimeyi dikkate alacağı. Belirtilecek en iyi kelime sayısı #1000 yapan da var\n",
    "    tokenizer.fit_on_texts(X_train) #keras tokenizer ile metni dictionary haline getiriyor.\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train) #kelimelerin dictionarydeki karşılığı \n",
    "    #[[2, 1, 3], [2, 1], [4, 1], [5, 6]] şekline getiriliyor. 2-machine 1- learning 3-Knowledge \n",
    "    word_index = tokenizer.word_index #dictionarydeki kelimelerin sayısal karşılığı 'unk': 1, 'ürün': 2,\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)): #len(sequences_X_train) ile kaç tane [[2,3,4],[2,6]] var bulunuyor burda 2\n",
    "        numberofwords=len(sequences_X_train[review_number]) #[2,3,4] içinde kaç tane şey var 3 burda\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords #tüm kelimelere bakıp en uzun olanı buluyor\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length) #ikili boyutlu matrise çevirip her cümelnin uzunluğunu eşit yapıyor.\n",
    "    #En uzun cümle uzunluğuna tamamlanıyor.[[2 1 3] [0 2 1]] alt alta gelecek şekilde en uzun 6 ise 6x6 matris oluyor\n",
    "    y_train = np.asarray(y_train) #tek boyutlu bir matris oluyor [1 1 0 ... 0 1 0] gibi\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test) #train için yapılan gibi dictionary alınıyor\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length) #en uzun olana göre pad sequence yapılıyor\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    unique_words = len(word_index) #word_index ile unique olan kelimeler alınıyor 0 dan başladığı için bir arttırılıyor\n",
    "    total_words = unique_words + 1\n",
    "    skipped_words = 0\n",
    "    embedding_dim = 32 #embedding dim vector size ile aynı \n",
    "    embedding_vector=0\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items(): #kelime ve kelimenin dictionarydeki karşılığı alınıyor\n",
    "        try:\n",
    "            embedding_vector = wordembeddings[word]#wordembeddings.word_vectors[wordembeddings.dictionary[word]] #kelimenin word2vec karşılığı vektör olarak\n",
    "\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector #dictionarydeki indexine word2vec teki sayısal hali yazılır\n",
    "            \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    \n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-7d0886ed6bc1>:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_vector = wordembeddings[word]#wordembeddings.word_vectors[wordembeddings.dictionary[word]] #kelimenin word2vec karşılığı vektör olarak\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 16s 63ms/step - loss: 0.5759 - acc: 0.6924 - precision_2: 0.7038 - recall_2: 0.6640\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4828 - acc: 0.7726 - precision_2: 0.7808 - recall_2: 0.7576\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4452 - acc: 0.7924 - precision_2: 0.8048 - recall_2: 0.7717\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.4232 - acc: 0.8085 - precision_2: 0.8168 - recall_2: 0.7951: \n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.3880 - acc: 0.8209 - precision_2: 0.8266 - recall_2: 0.8119\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.3592 - acc: 0.8357 - precision_2: 0.8446 - recall_2: 0.8226\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.3252 - acc: 0.8549 - precision_2: 0.8677 - recall_2: 0.83720s - loss: 0.3250 - acc: 0.8550 - precision_2: 0.8680 - recall_2: 0.\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.2999 - acc: 0.8680 - precision_2: 0.8716 - recall_2: 0.8631\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2709 - acc: 0.8849 - precision_2: 0.8878 - recall_2: 0.88112s - loss: 0 - ETA: 0s - loss: 0.2694 - acc: 0.8855 - precision_2: 0.888\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.2430 - acc: 0.8948 - precision_2: 0.8988 - recall_2: 0.8896\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.2269 - acc: 0.9103 - precision_2: 0.9154 - recall_2: 0.90400s - loss: 0.2265 - acc: 0.9107 - precision_2: 0.9149 - re\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2176 - acc: 0.9094 - precision_2: 0.9142 - recall_2: 0.9035\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1878 - acc: 0.9249 - precision_2: 0.9249 - recall_2: 0.9247\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1764 - acc: 0.9300 - precision_2: 0.9309 - recall_2: 0.9288\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1659 - acc: 0.9364 - precision_2: 0.9364 - recall_2: 0.93642s - loss: 0.1633 - acc: 0.9378 - precision_2: 0.9359 - recall_2 - ETA: 2s - loss: 0.1631 - acc: 0.9381 - precision_2: 0.936 - ETA: 1s - loss: 0\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1469 - acc: 0.9429 - precision_2: 0.9410 - recall_2: 0.9449\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1463 - acc: 0.9437 - precision_2: 0.9435 - recall_2: 0.9440\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.1361 - acc: 0.9480 - precision_2: 0.9479 - recall_2: 0.94810s - loss: 0.1362 - acc: 0.9479 - precision_2: 0.9480 - recall_2: 0.\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1291 - acc: 0.9500 - precision_2: 0.9492 - recall_2: 0.9508\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1206 - acc: 0.9532 - precision_2: 0.9515 - recall_2: 0.9552\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.1226 - acc: 0.9524 - precision_2: 0.9525 - recall_2: 0.95220s - loss: 0.1210 - acc: 0.9535 - precision_\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1062 - acc: 0.9607 - precision_2: 0.9603 - recall_2: 0.9610\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1042 - acc: 0.9601 - precision_2: 0.9600 - recall_2: 0.96001s - loss: 0.1025 - acc: 0.9607 - precision_2: 0.960 - ETA: 1s - loss: 0.1030 - acc: 0.960\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0981 - acc: 0.9626 - precision_2: 0.9614 - recall_2: 0.9639\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1041 - acc: 0.9612 - precision_2: 0.9610 - recall_2: 0.9613\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0940 - acc: 0.9663 - precision_2: 0.9659 - recall_2: 0.9666\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0987 - acc: 0.9632 - precision_2: 0.9641 - recall_2: 0.9622\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0922 - acc: 0.9641 - precision_2: 0.9660 - recall_2: 0.9620\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.0911 - acc: 0.9693 - precision_2: 0.9693 - recall_2: 0.9693\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0832 - acc: 0.9705 - precision_2: 0.9719 - recall_2: 0.9691\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0826 - acc: 0.9700 - precision_2: 0.9693 - recall_2: 0.9708\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0817 - acc: 0.9703 - precision_2: 0.9714 - recall_2: 0.96912s - los\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0856 - acc: 0.9686 - precision_2: 0.9702 - recall_2: 0.9669\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0892 - acc: 0.9677 - precision_2: 0.9671 - recall_2: 0.9683\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0712 - acc: 0.9727 - precision_2: 0.9732 - recall_2: 0.9722\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0740 - acc: 0.9709 - precision_2: 0.9696 - recall_2: 0.9722\n",
      "Epoch 37/50\n",
      "212/257 [=======================>......] - ETA: 2s - loss: 0.0760 - acc: 0.9720 - precision_2: 0.9725 - recall_2: 0.9714 ETA: 6s - los - ETA: 3s - loss: 0.0746 - acc: 0.972------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.5932 - acc: 0.6794 - precision_3: 0.6898 - recall_3: 0.65446s - loss: 0.6 - ETA: 4s - loss: 0.6160 - acc: 0.6550 - precision_3: 0.6635 - recall_3:  - ETA: 4s - loss:\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.5034 - acc: 0.7596 - precision_3: 0.7751 - recall_3: 0.7329\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.4684 - acc: 0.7839 - precision_3: 0.8042 - recall_3: 0.75164s - loss: 0\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 16s 62ms/step - loss: 0.4282 - acc: 0.8009 - precision_3: 0.8191 - recall_3: 0.77351s - loss: 0.4264 - acc: 0.8035 - precision_ - ETA: 0s - loss: 0.4272 - acc: 0.8021 - precision_3: 0.8\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 16s 60ms/step - loss: 0.4044 - acc: 0.8182 - precision_3: 0.8301 - recall_3: 0.8012\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.3717 - acc: 0.8326 - precision_3: 0.8456 - recall_3: 0.8146\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.3330 - acc: 0.8543 - precision_3: 0.8653 - recall_3: 0.83991s - loss: 0.333\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.3086 - acc: 0.8661 - precision_3: 0.8772 - recall_3: 0.8520\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.2784 - acc: 0.8815 - precision_3: 0.8860 - recall_3: 0.8763\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 49ms/step - loss: 0.2441 - acc: 0.8992 - precision_3: 0.9043 - recall_3: 0.8933\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.2225 - acc: 0.9052 - precision_3: 0.9076 - recall_3: 0.9026\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.2008 - acc: 0.9116 - precision_3: 0.9173 - recall_3: 0.9052\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1885 - acc: 0.9209 - precision_3: 0.9245 - recall_3: 0.9169: 12s \n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 13s 51ms/step - loss: 0.1813 - acc: 0.9299 - precision_3: 0.9306 - recall_3: 0.9293\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1693 - acc: 0.9332 - precision_3: 0.9383 - recall_3: 0.9276\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1575 - acc: 0.9406 - precision_3: 0.9420 - recall_3: 0.9392\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1419 - acc: 0.9422 - precision_3: 0.9430 - recall_3: 0.94145s - los - ETA: \n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1354 - acc: 0.9498 - precision_3: 0.9508 - recall_3: 0.9490\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.1356 - acc: 0.9476 - precision_3: 0.9484 - recall_3: 0.9470\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.1202 - acc: 0.9528 - precision_3: 0.9551 - recall_3: 0.9504\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1204 - acc: 0.9531 - precision_3: 0.9527 - recall_3: 0.9538\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.1221 - acc: 0.9539 - precision_3: 0.9527 - recall_3: 0.9553\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.1115 - acc: 0.9567 - precision_3: 0.9565 - recall_3: 0.95701s - loss: 0.1125 - acc: 0.9\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 16s 60ms/step - loss: 0.1087 - acc: 0.9609 - precision_3: 0.9622 - recall_3: 0.9597: 12s - loss: 0.1080 - acc: 0. - ETA: 10s - loss: 0.0951 - acc: 0.9671 - p - ETA: 1s - loss: 0.1077 - acc: 0.961\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.1119 - acc: 0.9579 - precision_3: 0.9597 - recall_3: 0.9560\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.0949 - acc: 0.9636 - precision_3: 0.9618 - recall_3: 0.9657\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.0871 - acc: 0.9677 - precision_3: 0.9684 - recall_3: 0.9672\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0851 - acc: 0.9696 - precision_3: 0.9701 - recall_3: 0.96910s - loss: 0.0843 - acc: 0.9695 - precision_3: 0.9704 - recall\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0899 - acc: 0.9671 - precision_3: 0.9679 - recall_3: 0.9665\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0838 - acc: 0.9699 - precision_3: 0.9710 - recall_3: 0.9689\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0820 - acc: 0.9690 - precision_3: 0.9700 - recall_3: 0.96791s - loss: - ETA: 0s - loss: 0.0820 - acc: 0.9690 - precision_3: 0.9700 - recall_3: 0.96\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0829 - acc: 0.9687 - precision_3: 0.9682 - recall_3: 0.9694\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0798 - acc: 0.9714 - precision_3: 0.9718 - recall_3: 0.9711\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0772 - acc: 0.9715 - precision_3: 0.9741 - recall_3: 0.9689\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.0690 - acc: 0.9748 - precision_3: 0.9780 - recall_3: 0.97160s - loss: 0.0690 - acc: 0.9749 - precision_3: 0.9779 - recall_3: 0.97\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0766 - acc: 0.9748 - precision_3: 0.9761 - recall_3: 0.9735\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0735 - acc: 0.9726 - precision_3: 0.9760 - recall_3: 0.9691\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0751 - acc: 0.9720 - precision_3: 0.9727 - recall_3: 0.97132s - loss: 0.073\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.4062 - acc: 0.8098 - precision_4: 0.8181 - recall_4: 0.7932\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.3660 - acc: 0.8309 - precision_4: 0.8389 - recall_4: 0.81608s - loss: 0.3663 - \n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 16s 60ms/step - loss: 0.3549 - acc: 0.8415 - precision_4: 0.8528 - recall_4: 0.8227\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.3109 - acc: 0.8647 - precision_4: 0.8689 - recall_4: 0.85685s - loss: 0.3113 - acc: 0 - ETA: 1s - loss: 0.3123 \n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2811 - acc: 0.8711 - precision_4: 0.8756 - recall_4: 0.86291s - loss: 0.2847 - acc: 0.8692 - pr\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.2589 - acc: 0.8885 - precision_4: 0.8929 - recall_4: 0.88101s - loss: 0.2574 - acc: 0\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.2381 - acc: 0.8981 - precision_4: 0.8969 - recall_4: 0.8980\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.2225 - acc: 0.9086 - precision_4: 0.9100 - recall_4: 0.9053\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.1946 - acc: 0.9224 - precision_4: 0.9220 - recall_4: 0.9218\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1885 - acc: 0.9249 - precision_4: 0.9261 - recall_4: 0.92227s - loss: 0.1846 - acc: 0.9247 - precision_4: 0.9298 - recall_4: 0.91 - ETA: 6s - loss: 0.1869 - acc: 0.9241 - pr - ETA: 6s - los - ETA: 1s - loss: 0.1861 - \n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1664 - acc: 0.9338 - precision_4: 0.9337 - recall_4: 0.93281s - loss: 0.1666 - acc: 0\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1731 - acc: 0.9335 - precision_4: 0.9350 - recall_4: 0.9308\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1624 - acc: 0.9399 - precision_4: 0.9401 - recall_4: 0.9387\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1500 - acc: 0.9453 - precision_4: 0.9442 - recall_4: 0.94581s - loss: 0.1507 \n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.1321 - acc: 0.9475 - precision_4: 0.9479 - recall_4: 0.94631s - loss: 0.1336 - acc: 0.9472 - prec\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 12s 48ms/step - loss: 0.1404 - acc: 0.9455 - precision_4: 0.9451 - recall_4: 0.9451: 12s - loss: 0.1576 - acc: 0.9062 - precis - ETA: \n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1158 - acc: 0.9528 - precision_4: 0.9526 - recall_4: 0.9522\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1135 - acc: 0.9548 - precision_4: 0.9569 - recall_4: 0.9519\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1170 - acc: 0.9560 - precision_4: 0.9561 - recall_4: 0.9554\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1173 - acc: 0.9562 - precision_4: 0.9541 - recall_4: 0.9578\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1120 - acc: 0.9567 - precision_4: 0.9575 - recall_4: 0.9551\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1049 - acc: 0.9604 - precision_4: 0.9614 - recall_4: 0.9588\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.1064 - acc: 0.9582 - precision_4: 0.9587 - recall_4: 0.95710s - loss: 0.1064 - acc: 0.9588 - precision_\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0882 - acc: 0.9674 - precision_4: 0.9687 - recall_4: 0.96540s - loss: 0.0892 - acc: 0.9670 - precision_4: 0.967\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1020 - acc: 0.9606 - precision_4: 0.9623 - recall_4: 0.9581\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0864 - acc: 0.9685 - precision_4: 0.9700 - recall_4: 0.9664\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1009 - acc: 0.9619 - precision_4: 0.9638 - recall_4: 0.95935s - loss: 0.0939 -  - ETA:  - ETA: 2s -\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0885 - acc: 0.9664 - precision_4: 0.9675 - recall_4: 0.9647\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0928 - acc: 0.9649 - precision_4: 0.9640 - recall_4: 0.9654\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0883 - acc: 0.9671 - precision_4: 0.9683 - recall_4: 0.9654\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0853 - acc: 0.9691 - precision_4: 0.9693 - recall_4: 0.9684\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0875 - acc: 0.9658 - precision_4: 0.9652 - recall_4: 0.96594s - loss: 0.0862 - acc: 0.9648  - ETA: 2s - loss: 0.0893 - acc: 0.9640 - precision_4: 0.9\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0851 - acc: 0.9680 - precision_4: 0.9692 - recall_4: 0.9662\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0845 - acc: 0.9702 - precision_4: 0.9724 - recall_4: 0.9674\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0812 - acc: 0.9725 - precision_4: 0.9711 - recall_4: 0.97352s -\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.0794 - acc: 0.9709 - precision_4: 0.9713 - recall_4: 0.9701\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4949 - acc: 0.7627 - precision_5: 0.7750 - recall_5: 0.7448\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4599 - acc: 0.7774 - precision_5: 0.7918 - recall_5: 0.7569\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 13s 49ms/step - loss: 0.4293 - acc: 0.7981 - precision_5: 0.8077 - recall_5: 0.78620s - loss: 0.4293 - acc: 0.7981 - precision_5: 0.8077 - recall_5: 0.78\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.4050 - acc: 0.8133 - precision_5: 0.8315 - recall_5: 0.7891\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.3693 - acc: 0.8371 - precision_5: 0.8464 - recall_5: 0.82634s - l - ETA: 1s - loss: 0.3624 - acc: 0.8412 - precision_5: 0.8484 -  - ETA: 1s - loss: 0.3645 - acc: 0.8406 - prec\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.3422 - acc: 0.8494 - precision_5: 0.8611 - recall_5: 0.8355\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.3104 - acc: 0.8628 - precision_5: 0.8711 - recall_5: 0.8537\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.2817 - acc: 0.8746 - precision_5: 0.8817 - recall_5: 0.8672\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2570 - acc: 0.8927 - precision_5: 0.8999 - recall_5: 0.8853\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.2306 - acc: 0.9014 - precision_5: 0.9060 - recall_5: 0.8972\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.2222 - acc: 0.9067 - precision_5: 0.9117 - recall_5: 0.9020: 13s \n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.2017 - acc: 0.9199 - precision_5: 0.9241 - recall_5: 0.9161\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1801 - acc: 0.9283 - precision_5: 0.9297 - recall_5: 0.92771s - loss: 0.1767 \n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1663 - acc: 0.9317 - precision_5: 0.9323 - recall_5: 0.93201s - loss: 0.1632 - \n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1308 - acc: 0.9512 - precision_5: 0.9554 - recall_5: 0.9473\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.1182 - acc: 0.9560 - precision_5: 0.9582 - recall_5: 0.9543\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1120 - acc: 0.9570 - precision_5: 0.9603 - recall_5: 0.9540\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1083 - acc: 0.9562 - precision_5: 0.9593 - recall_5: 0.95330s - loss: 0.1079 - acc: 0.9563 - precision_5: 0\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1060 - acc: 0.9592 - precision_5: 0.9643 - recall_5: 0.9543\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1107 - acc: 0.9607 - precision_5: 0.9633 - recall_5: 0.9584\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0970 - acc: 0.9632 - precision_5: 0.9664 - recall_5: 0.96030s - loss: 0.0973 - acc: 0.9631 - precision_5:\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0967 - acc: 0.9660 - precision_5: 0.9668 - recall_5: 0.9657\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0970 - acc: 0.9626 - precision_5: 0.9646 - recall_5: 0.9611\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0741 - acc: 0.9705 - precision_5: 0.9739 - recall_5: 0.96730s - loss: 0.0753 - acc: 0.9704 - precision_\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0648 - acc: 0.9761 - precision_5: 0.9768 - recall_5: 0.9758\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.0787 - acc: 0.9722 - precision_5: 0.9743 - recall_5: 0.9705\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0714 - acc: 0.9743 - precision_5: 0.9774 - recall_5: 0.97150s - loss: 0.0714 - acc: 0.9746 - precision_5: 0.9778 - recall_5\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0706 - acc: 0.9738 - precision_5: 0.9741 - recall_5: 0.97391s - l\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0763 - acc: 0.9709 - precision_5: 0.9740 - recall_5: 0.9681\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.0745 - acc: 0.9724 - precision_5: 0.9752 - recall_5: 0.96981s - loss: 0.0750 - acc: 0.9727 \n",
      "Epoch 00049: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1017 - acc: 0.7700 - precision_5: 0.7626 - recall_5: 0.7413\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.5876 - acc: 0.6857 - precision_6: 0.6919 - recall_6: 0.6709\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4986 - acc: 0.7628 - precision_6: 0.7688 - recall_6: 0.7524\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4671 - acc: 0.7824 - precision_6: 0.7896 - recall_6: 0.77061s - loss: 0.4\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4294 - acc: 0.7984 - precision_6: 0.8097 - recall_6: 0.7806\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.3355 - acc: 0.8513 - precision_6: 0.8589 - recall_6: 0.8412\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.3095 - acc: 0.8627 - precision_6: 0.8644 - recall_6: 0.8606\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2880 - acc: 0.8728 - precision_6: 0.8750 - recall_6: 0.87010s - loss: 0.2887 - acc: 0.8723 - precision_6: 0.8742 \n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2416 - acc: 0.8976 - precision_6: 0.8996 - recall_6: 0.89542s - loss: 0.2440 - acc: 0.8971  - ETA: 1s - loss: 0.2432 - acc: 0.8969 - pr\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.2434 - acc: 0.8967 - precision_6: 0.8969 - recall_6: 0.8969\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.2072 - acc: 0.9153 - precision_6: 0.9172 - recall_6: 0.9132\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1990 - acc: 0.9199 - precision_6: 0.9226 - recall_6: 0.9168TA: 0s - loss: 0.1993 - acc: 0.9201 - precision_6: 0.9227 - recall_6\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1920 - acc: 0.9196 - precision_6: 0.9218 - recall_6: 0.9173\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1612 - acc: 0.9350 - precision_6: 0.9334 - recall_6: 0.9370: 10s - loss: 0.1467 - acc: 0.94 - ETA: 9s - l - ETA: 7s\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.1600 - acc: 0.9386 - precision_6: 0.9349 - recall_6: 0.94311s - loss: 0 - ETA: 0s - loss: 0.1600 - acc: 0.9387 - precision_6: 0.9350 - recall_6: 0.94\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0968 - acc: 0.9657 - precision_6: 0.9652 - recall_6: 0.9662\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0939 - acc: 0.9655 - precision_6: 0.9677 - recall_6: 0.9633\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0977 - acc: 0.9609 - precision_6: 0.9624 - recall_6: 0.95941s - loss: 0.0993 - acc: 0.9604 - precisio\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0995 - acc: 0.9641 - precision_6: 0.9642 - recall_6: 0.9640\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0953 - acc: 0.9652 - precision_6: 0.9652 - recall_6: 0.9652\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.0810 - acc: 0.9708 - precision_6: 0.9710 - recall_6: 0.9706\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0934 - acc: 0.9640 - precision_6: 0.9647 - recall_6: 0.96332s - loss: 0.0929 - acc: 0.9645 - precision_6: 0.9655 - recall_6: 0. - ETA: 1s - los\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0801 - acc: 0.9677 - precision_6: 0.9686 - recall_6: 0.9669\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0914 - acc: 0.9683 - precision_6: 0.9716 - recall_6: 0.9650: 12s - loss: 0.\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0824 - acc: 0.9698 - precision_6: 0.9719 - recall_6: 0.9676\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.0786 - acc: 0.9722 - precision_6: 0.9714 - recall_6: 0.9732: 12s - loss: 0.0454 - acc: 0.9864 - precision_6: 0.9851 - - ETA: 11s - loss: 0.0527 - acc: 0.9816 - ETA: 4s -\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.0872 - acc: 0.9685 - precision_6: 0.9682 - recall_6: 0.9689\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 12s 47ms/step - loss: 0.0681 - acc: 0.9780 - precision_6: 0.9790 - recall_6: 0.9769: 13s - loss: 0.0608 - acc: 0.9821 - precision_6\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0714 - acc: 0.9748 - precision_6: 0.9770 - recall_6: 0.9725\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0644 - acc: 0.9760 - precision_6: 0.9759 - recall_6: 0.9762\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 14s 53ms/step - loss: 0.0688 - acc: 0.9738 - precision_6: 0.9770 - recall_6: 0.97061s - loss:\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0441 - acc: 0.7492 - precision_6: 0.7823 - recall_6: 0.6836\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.5872 - acc: 0.6821 - precision_7: 0.6993 - recall_7: 0.6396\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4958 - acc: 0.7637 - precision_7: 0.7744 - recall_7: 0.74458s - ETA: 1s - loss: 0.4975 - acc: 0.7\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.4590 - acc: 0.7825 - precision_7: 0.7987 - recall_7: 0.75591s - loss: 0.4580 - acc: 0.7839 - precision_7: 0.8000 - recall_7: 0. - ETA: 0s - loss: 0.4586 - acc: 0.7832 - precisio\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.4315 - acc: 0.7978 - precision_7: 0.8086 - recall_7: 0.78050s - loss: 0.4308 - acc: 0.7977 - precision_7: 0.8087 - recall\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.3966 - acc: 0.8205 - precision_7: 0.8325 - recall_7: 0.80291s - loss: 0.3928 - acc: 0.822\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.3712 - acc: 0.8331 - precision_7: 0.8426 - recall_7: 0.8194\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.3414 - acc: 0.8478 - precision_7: 0.8560 - recall_7: 0.8365\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.3115 - acc: 0.8657 - precision_7: 0.8773 - recall_7: 0.85060s - loss: 0.3104 - acc: 0.8664 - precision_7: 0.8780 - recall\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2688 - acc: 0.8831 - precision_7: 0.8896 - recall_7: 0.8749\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2263 - acc: 0.9034 - precision_7: 0.9050 - recall_7: 0.90170s - loss: 0.2264 - acc: 0.9040 - precision_7:\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2044 - acc: 0.9157 - precision_7: 0.9148 - recall_7: 0.91702s - loss: 0\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1784 - acc: 0.9245 - precision_7: 0.9250 - recall_7: 0.9241\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1676 - acc: 0.9301 - precision_7: 0.9295 - recall_7: 0.9309\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 13s 50ms/step - loss: 0.1718 - acc: 0.9340 - precision_7: 0.9326 - recall_7: 0.9358\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.1467 - acc: 0.9388 - precision_7: 0.9370 - recall_7: 0.94091s - loss: 0\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1445 - acc: 0.9442 - precision_7: 0.9443 - recall_7: 0.94433s - loss: 0.1443 - acc: 0.9444 - precisio\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1305 - acc: 0.9512 - precision_7: 0.9515 - recall_7: 0.9508\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1267 - acc: 0.9504 - precision_7: 0.9499 - recall_7: 0.9511\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1308 - acc: 0.9493 - precision_7: 0.9518 - recall_7: 0.9467\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1134 - acc: 0.9593 - precision_7: 0.9587 - recall_7: 0.96010s - loss: 0.1151 - acc: 0.9586 - precision_7: 0.9\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.1221 - acc: 0.9535 - precision_7: 0.9529 - recall_7: 0.95421s - loss: 0.1210 - acc: 0.9539 - prec\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0957 - acc: 0.9648 - precision_7: 0.9654 - recall_7: 0.9642\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0994 - acc: 0.9620 - precision_7: 0.9596 - recall_7: 0.9647\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.0814 - acc: 0.9687 - precision_7: 0.9691 - recall_7: 0.9684\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0771 - acc: 0.9724 - precision_7: 0.9716 - recall_7: 0.9732\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0915 - acc: 0.9669 - precision_7: 0.9683 - recall_7: 0.9654\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0884 - acc: 0.9664 - precision_7: 0.9639 - recall_7: 0.9691\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0823 - acc: 0.9714 - precision_7: 0.9738 - recall_7: 0.96880s - loss: 0.0806 - acc: 0.9718 - precision_7: 0\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.0752 - acc: 0.9739 - precision_7: 0.9719 - recall_7: 0.97610s - loss: 0.0744 - acc: 0.9747 - precis\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0779 - acc: 0.9719 - precision_7: 0.9739 - recall_7: 0.9698\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0738 - acc: 0.9724 - precision_7: 0.9730 - recall_7: 0.9718\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.0896 - acc: 0.9660 - precision_7: 0.9659 - recall_7: 0.96620s - loss: 0.0896 - acc: 0.9660 - precision_7: 0.9664 - re\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0704 - acc: 0.9728 - precision_7: 0.9721 - recall_7: 0.9737: 13s - loss: 0.0473 - acc: 0.9861 - precisi - ETA: 1s - loss: 0.0681 - acc: 0.9738 - precision_\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0688 - acc: 0.9761 - precision_7: 0.9780 - recall_7: 0.9742\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1769 - acc: 0.7678 - precision_7: 0.7814 - recall_7: 0.7401\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 15s 56ms/step - loss: 0.6053 - acc: 0.6575 - precision_8: 0.6605 - recall_8: 0.64591s - loss: 0.6155 - acc: 0.6482 - precision_8: 0.6477 - reca - ETA: 1s - loss: 0.6130 - acc: 0.6\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.4996 - acc: 0.7563 - precision_8: 0.7704 - recall_8: 0.7290\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.4703 - acc: 0.7785 - precision_8: 0.7969 - recall_8: 0.74662s - loss: 0.4679 - acc: 0.7814 - precision_8: 0.7991 - reca - ETA:  - ETA: 0s - loss: 0.4703 - acc: 0.7779 - precision_8: 0.7957 - recall_8\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.4304 - acc: 0.7951 - precision_8: 0.8132 - recall_8: 0.7654\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.4041 - acc: 0.8145 - precision_8: 0.8308 - recall_8: 0.7890\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 16s 61ms/step - loss: 0.3742 - acc: 0.8304 - precision_8: 0.8464 - recall_8: 0.8066\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 15s 60ms/step - loss: 0.3419 - acc: 0.8496 - precision_8: 0.8589 - recall_8: 0.8361\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.3248 - acc: 0.8535 - precision_8: 0.8677 - recall_8: 0.8337\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.2804 - acc: 0.8769 - precision_8: 0.8856 - recall_8: 0.8651\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.2234 - acc: 0.9071 - precision_8: 0.9135 - recall_8: 0.8990\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 15s 57ms/step - loss: 0.2052 - acc: 0.9139 - precision_8: 0.9161 - recall_8: 0.9110\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 14s 56ms/step - loss: 0.1913 - acc: 0.9216 - precision_8: 0.9299 - recall_8: 0.9117\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1796 - acc: 0.9276 - precision_8: 0.9348 - recall_8: 0.9190\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1628 - acc: 0.9361 - precision_8: 0.9374 - recall_8: 0.9344\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1480 - acc: 0.9439 - precision_8: 0.9498 - recall_8: 0.93711s - loss: 0.1473 - acc: 0.9441 - precision_8: 0.9496 - recall_8:  - ETA: 1s - loss: 0.1472 - acc: 0\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 15s 59ms/step - loss: 0.1465 - acc: 0.9405 - precision_8: 0.9405 - recall_8: 0.94027s - loss: 0.1333 - acc: 0.9463 - precisio - ETA: 6s - loss: 0.1367 - acc: 0.9459 - precision_8: 0.949 - ETA: 6s - loss: 0.1381  - ETA: 4s - los\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1412 - acc: 0.9435 - precision_8: 0.9471 - recall_8: 0.9393\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 15s 58ms/step - loss: 0.1241 - acc: 0.9530 - precision_8: 0.9531 - recall_8: 0.9527\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0804 - acc: 0.9692 - precision_8: 0.9695 - recall_8: 0.9688\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0877 - acc: 0.9660 - precision_8: 0.9650 - recall_8: 0.9671\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0798 - acc: 0.9707 - precision_8: 0.9735 - recall_8: 0.9676\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0790 - acc: 0.9707 - precision_8: 0.9714 - recall_8: 0.9698\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0769 - acc: 0.9726 - precision_8: 0.9752 - recall_8: 0.9698\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0791 - acc: 0.9716 - precision_8: 0.9729 - recall_8: 0.9702\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0710 - acc: 0.9729 - precision_8: 0.9762 - recall_8: 0.96931s - loss: 0.0695 - acc: 0.9735 \n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0815 - acc: 0.9709 - precision_8: 0.9733 - recall_8: 0.9683\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0707 - acc: 0.9732 - precision_8: 0.9739 - recall_8: 0.9724\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0785 - acc: 0.9729 - precision_8: 0.9743 - recall_8: 0.97121s - loss: 0.0787 - acc: 0.9732 - \n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0742 - acc: 0.9720 - precision_8: 0.9733 - recall_8: 0.97052s - loss: 0.0738 - acc:\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0714 - acc: 0.9735 - precision_8: 0.9760 - recall_8: 0.9707\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0753 - acc: 0.9729 - precision_8: 0.9764 - recall_8: 0.96900s - loss: 0.0758 - acc: 0.9726 - precision_8: 0.9760 - recall\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0723 - acc: 0.9736 - precision_8: 0.9771 - recall_8: 0.96983s - loss: 0.0751 - acc: 0.9723 - precision_8: 0.9759 - recall - ETA: 2s - l\n",
      "Epoch 00049: early stopping\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.2640 - acc: 0.7346 - precision_8: 0.7625 - recall_8: 0.6933\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.5809 - acc: 0.6837 - precision_9: 0.6744 - recall_9: 0.7063\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.5007 - acc: 0.7631 - precision_9: 0.7779 - recall_9: 0.7342\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.4611 - acc: 0.7781 - precision_9: 0.7931 - recall_9: 0.7503\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.4353 - acc: 0.7972 - precision_9: 0.8111 - recall_9: 0.77304s - loss: 0 - ETA: 1s - loss: 0.4344 - acc: 0\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.3992 - acc: 0.8159 - precision_9: 0.8310 - recall_9: 0.7916\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.3859 - acc: 0.8221 - precision_9: 0.8399 - recall_9: 0.79458s - loss: 0.3572 - acc: 0.8403 - precis - ETA: 7s - loss: 0.3713 - acc: 0.8299 - precision_9: 0.8445 - recall_9 - ETA: 7s - loss: 0.376 - ETA: 1s - loss: 0.3859 - acc: 0.822\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.3433 - acc: 0.8479 - precision_9: 0.8567 - recall_9: 0.83448s - - ETA: 1s - loss: 0.3412 - acc: 0.8\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.3113 - acc: 0.8617 - precision_9: 0.8664 - recall_9: 0.8541\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.2921 - acc: 0.8753 - precision_9: 0.8839 - recall_9: 0.8632\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.2650 - acc: 0.8817 - precision_9: 0.8848 - recall_9: 0.87666s - loss: 0.2473 - acc: 0 - ETA: 4s - loss: 0.2508 - acc: 0.8900 - precision_9: 0.8929  - ETA: 3s - loss: 0.2569 - acc: 0.8883 -  - ETA: 2s - loss: 0.262 - ETA: 0s - loss: 0.2651 - acc: 0.8819 - precision_9: 0.8844 - recall\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 45ms/step - loss: 0.2334 - acc: 0.9009 - precision_9: 0.9053 - recall_9: 0.89474s - loss: 0.2340  - ETA: 2s - loss: 0\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.2197 - acc: 0.9042 - precision_9: 0.9032 - recall_9: 0.90472s - loss:\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.2044 - acc: 0.9145 - precision_9: 0.9167 - recall_9: 0.91136s - loss: 0.199 - ETA: 4s - loss: 0.2043 - acc: 0.9156 - precision_9: 0.9186 - recall_9: 0. - ETA: 4s - loss: 0.2038 - acc: 0.9158 - precision_9: - ETA: 3s - loss: 0.2038 - acc: 0.9144 - precision_9: 0.917 - ETA: 2s - loss:\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1851 - acc: 0.9268 - precision_9: 0.9290 - recall_9: 0.9238\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1734 - acc: 0.9308 - precision_9: 0.9325 - recall_9: 0.92849s - loss: 0.1580 - acc: 0.9427 - pr - ETA: 8s - loss: 0.1526 - ac\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.1553 - acc: 0.9385 - precision_9: 0.9378 - recall_9: 0.93891s - loss: 0.1489 - acc: 0.9422 - \n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1526 - acc: 0.9390 - precision_9: 0.9404 - recall_9: 0.93702s - loss: 0.150\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1509 - acc: 0.9444 - precision_9: 0.9436 - recall_9: 0.94482s - los\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.1300 - acc: 0.9481 - precision_9: 0.9506 - recall_9: 0.94502s - loss: 0.1244 - \n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.1190 - acc: 0.9573 - precision_9: 0.9572 - recall_9: 0.9570\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.1279 - acc: 0.9503 - precision_9: 0.9508 - recall_9: 0.9494\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.1136 - acc: 0.9575 - precision_9: 0.9555 - recall_9: 0.9594\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1183 - acc: 0.9567 - precision_9: 0.9563 - recall_9: 0.95681s - loss: 0.1171 - acc: 0.9579 - precision_9:\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1085 - acc: 0.9581 - precision_9: 0.9593 - recall_9: 0.9565\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1032 - acc: 0.9603 - precision_9: 0.9629 - recall_9: 0.9572\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1069 - acc: 0.9597 - precision_9: 0.9610 - recall_9: 0.9580\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0998 - acc: 0.9626 - precision_9: 0.9617 - recall_9: 0.96348s - loss: 0.0819 - acc:\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0958 - acc: 0.9651 - precision_9: 0.9664 - recall_9: 0.96344s - loss: 0.0987 - acc: 0.9628 - precision_9: 0.963 - ETA: 4s - loss: 0.0993 - acc: 0.9630  - ETA: 2s - loss: 0.095\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0998 - acc: 0.9614 - precision_9: 0.9643 - recall_9: 0.9580\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0843 - acc: 0.9696 - precision_9: 0.9715 - recall_9: 0.9673\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0917 - acc: 0.9640 - precision_9: 0.9638 - recall_9: 0.96380s - loss: 0.0913 - acc: 0.9642 - precision_9: 0.965\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1044 - acc: 0.9587 - precision_9: 0.9549 - recall_9: 0.9626\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0942 - acc: 0.9642 - precision_9: 0.9652 - recall_9: 0.9629\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0944 - acc: 0.9651 - precision_9: 0.9630 - recall_9: 0.9670\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0872 - acc: 0.9688 - precision_9: 0.9685 - recall_9: 0.9690\n",
      "Epoch 00035: early stopping\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0695 - acc: 0.7522 - precision_9: 0.7202 - recall_9: 0.8489\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.5911 - acc: 0.6849 - precision_10: 0.6907 - recall_10: 0.6671\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.4953 - acc: 0.7632 - precision_10: 0.7755 - recall_10: 0.7393\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4578 - acc: 0.7839 - precision_10: 0.8003 - recall_10: 0.7552\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4260 - acc: 0.8014 - precision_10: 0.8141 - recall_10: 0.7801\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.3928 - acc: 0.8219 - precision_10: 0.8346 - recall_10: 0.8018\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.3658 - acc: 0.8363 - precision_10: 0.8478 - recall_10: 0.8186\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.3330 - acc: 0.8521 - precision_10: 0.8610 - recall_10: 0.8389\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2996 - acc: 0.8679 - precision_10: 0.8774 - recall_10: 0.8545\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2784 - acc: 0.8798 - precision_10: 0.8851 - recall_10: 0.8723\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.2473 - acc: 0.8951 - precision_10: 0.8977 - recall_10: 0.8911\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.2231 - acc: 0.9049 - precision_10: 0.9096 - recall_10: 0.8987\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2051 - acc: 0.9138 - precision_10: 0.9156 - recall_10: 0.9112\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1876 - acc: 0.9245 - precision_10: 0.9258 - recall_10: 0.9226\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1790 - acc: 0.9302 - precision_10: 0.9312 - recall_10: 0.9287\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1580 - acc: 0.9386 - precision_10: 0.9400 - recall_10: 0.9368\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1494 - acc: 0.9403 - precision_10: 0.9393 - recall_10: 0.9412\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1454 - acc: 0.9438 - precision_10: 0.9447 - recall_10: 0.9424\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1253 - acc: 0.9520 - precision_10: 0.9546 - recall_10: 0.9490\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1226 - acc: 0.9505 - precision_10: 0.9513 - recall_10: 0.9492\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1108 - acc: 0.9564 - precision_10: 0.9561 - recall_10: 0.9566\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1232 - acc: 0.9533 - precision_10: 0.9516 - recall_10: 0.9548\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1104 - acc: 0.9582 - precision_10: 0.9571 - recall_10: 0.9592\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1115 - acc: 0.9571 - precision_10: 0.9575 - recall_10: 0.9566\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1089 - acc: 0.9590 - precision_10: 0.9570 - recall_10: 0.9609\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0944 - acc: 0.9653 - precision_10: 0.9672 - recall_10: 0.96310s - loss: 0.0937 - acc: 0.9660 - precision_10: 0.9682\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1023 - acc: 0.9621 - precision_10: 0.9622 - recall_10: 0.9619\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0896 - acc: 0.9674 - precision_10: 0.9675 - recall_10: 0.9670\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0987 - acc: 0.9621 - precision_10: 0.9640 - recall_10: 0.9600\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0869 - acc: 0.9685 - precision_10: 0.9694 - recall_10: 0.9673\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0796 - acc: 0.9697 - precision_10: 0.9695 - recall_10: 0.9697\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0962 - acc: 0.9617 - precision_10: 0.9633 - recall_10: 0.9597\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0755 - acc: 0.9720 - precision_10: 0.9706 - recall_10: 0.9734\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0851 - acc: 0.9692 - precision_10: 0.9706 - recall_10: 0.96752s - l\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0835 - acc: 0.9692 - precision_10: 0.9688 - recall_10: 0.9695\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0776 - acc: 0.9708 - precision_10: 0.9709 - recall_10: 0.97050s - loss: 0.0778 - acc: 0.9709 - precision_10: 0.\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0770 - acc: 0.9692 - precision_10: 0.9674 - recall_10: 0.9710\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0762 - acc: 0.9696 - precision_10: 0.9725 - recall_10: 0.96632s - loss: 0.0743 \n",
      "Epoch 00037: early stopping\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0698 - acc: 0.7434 - precision_10: 0.7566 - recall_10: 0.7339\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.5861 - acc: 0.6797 - precision_11: 0.6740 - recall_11: 0.7020\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.4984 - acc: 0.7632 - precision_11: 0.7841 - recall_11: 0.7296\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.4611 - acc: 0.7855 - precision_11: 0.8013 - recall_11: 0.7621\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.4303 - acc: 0.7971 - precision_11: 0.8046 - recall_11: 0.7873\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4044 - acc: 0.8128 - precision_11: 0.8237 - recall_11: 0.7982\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.3737 - acc: 0.8355 - precision_11: 0.8500 - recall_11: 0.8168\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.3410 - acc: 0.8521 - precision_11: 0.8611 - recall_11: 0.8413\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.3094 - acc: 0.8645 - precision_11: 0.8679 - recall_11: 0.8614\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2769 - acc: 0.8776 - precision_11: 0.8837 - recall_11: 0.8711\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2582 - acc: 0.8948 - precision_11: 0.8994 - recall_11: 0.8902\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2327 - acc: 0.9009 - precision_11: 0.9016 - recall_11: 0.9011\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2205 - acc: 0.9071 - precision_11: 0.9079 - recall_11: 0.9072\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.2084 - acc: 0.9117 - precision_11: 0.9135 - recall_11: 0.9106\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1823 - acc: 0.9257 - precision_11: 0.9280 - recall_11: 0.9239\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1729 - acc: 0.9323 - precision_11: 0.9316 - recall_11: 0.9339\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1639 - acc: 0.9354 - precision_11: 0.9347 - recall_11: 0.9368\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1501 - acc: 0.9396 - precision_11: 0.9393 - recall_11: 0.9406\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1475 - acc: 0.9423 - precision_11: 0.9421 - recall_11: 0.9431\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1290 - acc: 0.9501 - precision_11: 0.9492 - recall_11: 0.9515\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1318 - acc: 0.9485 - precision_11: 0.9467 - recall_11: 0.9511\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1228 - acc: 0.9512 - precision_11: 0.9498 - recall_11: 0.95323s - loss: 0.1244 -  - ETA: 1s - loss: 0.1229 - acc: 0.951\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1306 - acc: 0.9489 - precision_11: 0.9478 - recall_11: 0.95062s - los\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1178 - acc: 0.9554 - precision_11: 0.9581 - recall_11: 0.9530\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1127 - acc: 0.9559 - precision_11: 0.9544 - recall_11: 0.9581\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1082 - acc: 0.9575 - precision_11: 0.9547 - recall_11: 0.9610\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1090 - acc: 0.9621 - precision_11: 0.9633 - recall_11: 0.9612\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1057 - acc: 0.9602 - precision_11: 0.9603 - recall_11: 0.9605\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1013 - acc: 0.9630 - precision_11: 0.9643 - recall_11: 0.9620\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1137 - acc: 0.9562 - precision_11: 0.9564 - recall_11: 0.9564\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0933 - acc: 0.9685 - precision_11: 0.9681 - recall_11: 0.9692\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0928 - acc: 0.9659 - precision_11: 0.9650 - recall_11: 0.9673\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0897 - acc: 0.9666 - precision_11: 0.9661 - recall_11: 0.9675\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0911 - acc: 0.9681 - precision_11: 0.9710 - recall_11: 0.9654\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0954 - acc: 0.9651 - precision_11: 0.9669 - recall_11: 0.9634\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0909 - acc: 0.9651 - precision_11: 0.9674 - recall_11: 0.9629\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0876 - acc: 0.9658 - precision_11: 0.9647 - recall_11: 0.9673\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0882 - acc: 0.9671 - precision_11: 0.9664 - recall_11: 0.9683\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0914 - acc: 0.9690 - precision_11: 0.9701 - recall_11: 0.9680\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0742 - acc: 0.9730 - precision_11: 0.9738 - recall_11: 0.9724\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0842 - acc: 0.9688 - precision_11: 0.9688 - recall_11: 0.9692\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0884 - acc: 0.9653 - precision_11: 0.9660 - recall_11: 0.9649\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0678 - acc: 0.9752 - precision_11: 0.9751 - recall_11: 0.9755\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0721 - acc: 0.9730 - precision_11: 0.9759 - recall_11: 0.9702\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0836 - acc: 0.9688 - precision_11: 0.9710 - recall_11: 0.96685s - loss: 0.0788 - acc: 0\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0767 - acc: 0.9731 - precision_11: 0.9747 - recall_11: 0.97171s - loss: 0.0776 - acc: 0.9721 - precision_11\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0738 - acc: 0.9732 - precision_11: 0.9757 - recall_11: 0.9709\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0747 - acc: 0.9729 - precision_11: 0.9729 - recall_11: 0.9731\n",
      "Epoch 00047: early stopping\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8771 - acc: 0.7752 - precision_11: 0.7743 - recall_11: 0.7477\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "    \n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= word2vec (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNN = Sequential() #cnn\n",
    "\n",
    "    modelCNN.add(embedding_layer)\n",
    "    modelCNN.add(Conv1D(filters=256, kernel_size=5, activation='relu')) #kernal size 5 yan yana beş kelimeye bakması\n",
    "    modelCNN.add(MaxPooling1D(pool_size=2)) #tek satırlık 1d olduğu için\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(360, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(300, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(260, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(150, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(120, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Dense(80, activation='relu'))\n",
    "    modelCNN.add(Dropout(0.3))\n",
    "    modelCNN.add(Flatten()) #düzgünleştirmek için\n",
    "    modelCNN.add(Dense(1, activation='sigmoid'))\n",
    "    modelCNN.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNN.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelCNN.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.761775\n",
      "test precision: 0.768378\n",
      "test recall: 0.751735\n",
      "test f1_score: 0.758809\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
