{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column = ['tweets','duygu','preprocessing']\n",
    "#df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "\n",
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "\n",
    "\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artık dm lere bakmıyorum o bile turkcell den g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>az önce benim eskisi mesaj attı yok geri dön f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@vaampirellaa ebeni sikem turkcell sdfdfds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bir tek benim mı internetim bozuk turkcell ben...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ulan dalga geciyorum kiziyorum felan ama tek m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>rt @bursasporfann: bursa'da birçok turkcell ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>turkcell superonline pişmanlıktır hiç bir şeki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>@eyganjaa turkcell sağolsun 18gb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>turkcell ne yaptın ne ettin beni kaybettin bil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell terbiyesizlik yapma, telefonlarimiz c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     artık dm lere bakmıyorum o bile turkcell den g...     0\n",
       "1     az önce benim eskisi mesaj attı yok geri dön f...     1\n",
       "2            @vaampirellaa ebeni sikem turkcell sdfdfds     0\n",
       "3     bir tek benim mı internetim bozuk turkcell ben...     0\n",
       "4     ulan dalga geciyorum kiziyorum felan ama tek m...     1\n",
       "...                                                 ...   ...\n",
       "9121  rt @bursasporfann: bursa'da birçok turkcell ba...     1\n",
       "9122  turkcell superonline pişmanlıktır hiç bir şeki...     0\n",
       "9123                   @eyganjaa turkcell sağolsun 18gb     1\n",
       "9124  turkcell ne yaptın ne ettin beni kaybettin bil...     0\n",
       "9125  turkcell terbiyesizlik yapma, telefonlarimiz c...     0\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=df['tweets'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tokenizer\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "# Building word indices\n",
    "tokenizer.fit_on_texts(X_t)\n",
    "# Tokenizing sentences\n",
    "sentences = tokenizer.texts_to_sequences(X_t)\n",
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "# Creating texts \n",
    "X_t = list(map(sequence_to_text, sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.60600161552429\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "start=time.time()\n",
    "n_features=32\n",
    "window_size=5\n",
    "min_count=1\n",
    "epoch=50\n",
    "n_workers=8\n",
    "\n",
    "wordembeddings = Word2Vec(size = n_features,\n",
    "            window = window_size, \n",
    "            min_count= min_count,\n",
    "            workers = n_workers, \n",
    "            sg=1)\n",
    "wordembeddings.build_vocab(X_t)\n",
    "wordembeddings.train(X_t, \n",
    "            total_examples=wordembeddings.corpus_count,  \n",
    "            epochs = epoch)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=df['tweets'].to_numpy()\n",
    "targets=df['duygu'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec (X_train,y_train,X_test,y_test):\n",
    "    #Create a tokenizer, configured to only take into account the 20 most common words çok küçük olursa kelimeleri \n",
    "    #kaybederiz underfit yaparız\n",
    "    #tokenizer = Tokenizer(lower=True) #en yaygın kaç kelimeyi dikkate alacağı. Belirtilecek en iyi kelime sayısı #1000 yapan da var\n",
    "    tokenizer.fit_on_texts(X_train) #keras tokenizer ile metni dictionary haline getiriyor.\n",
    "    sequences_X_train = tokenizer.texts_to_sequences(X_train) #kelimelerin dictionarydeki karşılığı \n",
    "    #[[2, 1, 3], [2, 1], [4, 1], [5, 6]] şekline getiriliyor. 2-machine 1- learning 3-Knowledge \n",
    "    word_index = tokenizer.word_index #dictionarydeki kelimelerin sayısal karşılığı 'unk': 1, 'ürün': 2,\n",
    "    max_length = 0\n",
    "    for review_number in range(len(sequences_X_train)): #len(sequences_X_train) ile kaç tane [[2,3,4],[2,6]] var bulunuyor burda 2\n",
    "        numberofwords=len(sequences_X_train[review_number]) #[2,3,4] içinde kaç tane şey var 3 burda\n",
    "        if (numberofwords) > (max_length):\n",
    "            max_length = numberofwords #tüm kelimelere bakıp en uzun olanı buluyor\n",
    "\n",
    "    X_train = pad_sequences(sequences_X_train, maxlen=max_length) #ikili boyutlu matrise çevirip her cümelnin uzunluğunu eşit yapıyor.\n",
    "    #En uzun cümle uzunluğuna tamamlanıyor.[[2 1 3] [0 2 1]] alt alta gelecek şekilde en uzun 6 ise 6x6 matris oluyor\n",
    "    y_train = np.asarray(y_train) #tek boyutlu bir matris oluyor [1 1 0 ... 0 1 0] gibi\n",
    "\n",
    "    sequences_X_test = tokenizer.texts_to_sequences(X_test) #train için yapılan gibi dictionary alınıyor\n",
    "    X_test = pad_sequences(sequences_X_test, maxlen=max_length) #en uzun olana göre pad sequence yapılıyor\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "\n",
    "    unique_words = len(word_index) #word_index ile unique olan kelimeler alınıyor 0 dan başladığı için bir arttırılıyor\n",
    "    total_words = unique_words + 1\n",
    "    skipped_words = 0\n",
    "    embedding_dim = 32 #embedding dim vector size ile aynı \n",
    "    embedding_vector=0\n",
    "    embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "    for word, index in tokenizer.word_index.items(): #kelime ve kelimenin dictionarydeki karşılığı alınıyor\n",
    "        try:\n",
    "            embedding_vector = wordembeddings[word]#wordembeddings.word_vectors[wordembeddings.dictionary[word]] #kelimenin word2vec karşılığı vektör olarak\n",
    "\n",
    "        except:\n",
    "            skipped_words = skipped_words+1\n",
    "            pass\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector #dictionarydeki indexine word2vec teki sayısal hali yazılır\n",
    "            \n",
    "    embedding_layer = Embedding(total_words, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    \n",
    "    return embedding_layer,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-7d0886ed6bc1>:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_vector = wordembeddings[word]#wordembeddings.word_vectors[wordembeddings.dictionary[word]] #kelimenin word2vec karşılığı vektör olarak\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.5278 - acc: 0.7314 - precision_1: 0.7379 - recall_1: 0.7204\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.4558 - acc: 0.7824 - precision_1: 0.7970 - recall_1: 0.7597\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 6s 23ms/step - loss: 0.4131 - acc: 0.8058 - precision_1: 0.8170 - recall_1: 0.7898\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 6s 23ms/step - loss: 0.3589 - acc: 0.8327 - precision_1: 0.8395 - recall_1: 0.8240 0s - loss: 0.3565 - acc: 0.8333 - precision_1: 0.8401 \n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.3058 - acc: 0.8674 - precision_1: 0.8732 - recall_1: 0.8607\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2447 - acc: 0.8924 - precision_1: 0.8973 - recall_1: 0.8869\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.2133 - acc: 0.9065 - precision_1: 0.9082 - recall_1: 0.9051\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1777 - acc: 0.9273 - precision_1: 0.9279 - recall_1: 0.9272\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.1542 - acc: 0.9371 - precision_1: 0.9393 - recall_1: 0.9350\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.1232 - acc: 0.9496 - precision_1: 0.9504 - recall_1: 0.9490\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.1028 - acc: 0.9613 - precision_1: 0.9612 - recall_1: 0.9617\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0972 - acc: 0.9607 - precision_1: 0.9634 - recall_1: 0.9580\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0896 - acc: 0.9651 - precision_1: 0.9669 - recall_1: 0.9633\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0866 - acc: 0.9653 - precision_1: 0.9660 - recall_1: 0.9648\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0741 - acc: 0.9691 - precision_1: 0.9715 - recall_1: 0.9667\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0717 - acc: 0.9730 - precision_1: 0.9747 - recall_1: 0.9714\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0777 - acc: 0.9713 - precision_1: 0.9727 - recall_1: 0.9699\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0619 - acc: 0.9765 - precision_1: 0.9800 - recall_1: 0.9731\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0567 - acc: 0.9784 - precision_1: 0.9791 - recall_1: 0.9779\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0607 - acc: 0.9764 - precision_1: 0.9783 - recall_1: 0.9745\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0585 - acc: 0.9774 - precision_1: 0.9795 - recall_1: 0.9752\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0566 - acc: 0.9771 - precision_1: 0.9797 - recall_1: 0.9745\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0532 - acc: 0.9797 - precision_1: 0.9805 - recall_1: 0.9789\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0469 - acc: 0.9833 - precision_1: 0.9863 - recall_1: 0.9803\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0463 - acc: 0.9826 - precision_1: 0.9839 - recall_1: 0.9813\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0424 - acc: 0.9850 - precision_1: 0.9871 - recall_1: 0.9830\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0452 - acc: 0.9815 - precision_1: 0.9837 - recall_1: 0.9794\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0532 - acc: 0.9800 - precision_1: 0.9806 - recall_1: 0.9796\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0433 - acc: 0.9819 - precision_1: 0.9832 - recall_1: 0.9806\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0429 - acc: 0.9844 - precision_1: 0.9868 - recall_1: 0.9820\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0390 - acc: 0.9856 - precision_1: 0.9883 - recall_1: 0.9830\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0398 - acc: 0.9845 - precision_1: 0.9859 - recall_1: 0.9833\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0348 - acc: 0.9872 - precision_1: 0.9902 - recall_1: 0.9842\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0462 - acc: 0.9842 - precision_1: 0.9854 - recall_1: 0.9830\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0352 - acc: 0.9862 - precision_1: 0.9878 - recall_1: 0.9847\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0341 - acc: 0.9881 - precision_1: 0.9900 - recall_1: 0.9862\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0391 - acc: 0.9848 - precision_1: 0.9871 - recall_1: 0.9825\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0365 - acc: 0.9861 - precision_1: 0.9871 - recall_1: 0.9852\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0307 - acc: 0.9882 - precision_1: 0.9898 - recall_1: 0.9867\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0336 - acc: 0.9871 - precision_1: 0.9886 - recall_1: 0.9857\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0263 - acc: 0.9907 - precision_1: 0.9934 - recall_1: 0.9881\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0413 - acc: 0.9843 - precision_1: 0.9868 - recall_1: 0.9818\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0321 - acc: 0.9867 - precision_1: 0.9897 - recall_1: 0.9837\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0324 - acc: 0.9873 - precision_1: 0.9888 - recall_1: 0.9859\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0254 - acc: 0.9898 - precision_1: 0.9908 - recall_1: 0.9888\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0318 - acc: 0.9870 - precision_1: 0.9881 - recall_1: 0.9859\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0287 - acc: 0.9894 - precision_1: 0.9905 - recall_1: 0.9883\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0389 - acc: 0.9847 - precision_1: 0.9852 - recall_1: 0.98420s - loss: 0.0390 - acc: 0.9846 - precision_1: 0.9851 - recall_1: 0.98\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0312 - acc: 0.9886 - precision_1: 0.9905 - recall_1: 0.9867\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0240 - acc: 0.9901 - precision_1: 0.9912 - recall_1: 0.9891\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.3931 - acc: 0.7612 - precision_1: 0.7462 - recall_1: 0.7698\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.5353 - acc: 0.7296 - precision_2: 0.7357 - recall_2: 0.7187\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.4623 - acc: 0.7762 - precision_2: 0.7861 - recall_2: 0.7605\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.4168 - acc: 0.8018 - precision_2: 0.8057 - recall_2: 0.7967\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3699 - acc: 0.8299 - precision_2: 0.8342 - recall_2: 0.8246\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3253 - acc: 0.8502 - precision_2: 0.8549 - recall_2: 0.8445\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.2614 - acc: 0.8865 - precision_2: 0.8859 - recall_2: 0.8880\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 8s 31ms/step - loss: 0.2098 - acc: 0.9078 - precision_2: 0.9052 - recall_2: 0.9116\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 7s 26ms/step - loss: 0.1736 - acc: 0.9276 - precision_2: 0.9274 - recall_2: 0.9281\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 7s 26ms/step - loss: 0.1500 - acc: 0.9380 - precision_2: 0.9362 - recall_2: 0.9405\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 6s 25ms/step - loss: 0.1316 - acc: 0.9474 - precision_2: 0.9475 - recall_2: 0.9475\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.1079 - acc: 0.9579 - precision_2: 0.9586 - recall_2: 0.9573\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.1030 - acc: 0.9579 - precision_2: 0.9580 - recall_2: 0.9580 0s - loss: 0.1035 - acc: 0.9577 - precision_2: 0.9582 - recall_2: \n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 7s 26ms/step - loss: 0.0907 - acc: 0.9659 - precision_2: 0.9674 - recall_2: 0.9645\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 8s 32ms/step - loss: 0.0830 - acc: 0.9663 - precision_2: 0.9678 - recall_2: 0.9648\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0773 - acc: 0.9697 - precision_2: 0.9703 - recall_2: 0.9692\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0756 - acc: 0.9693 - precision_2: 0.9703 - recall_2: 0.9684\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0738 - acc: 0.9708 - precision_2: 0.9722 - recall_2: 0.9694\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0719 - acc: 0.9726 - precision_2: 0.9723 - recall_2: 0.9730\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0519 - acc: 0.9798 - precision_2: 0.9834 - recall_2: 0.9762\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0637 - acc: 0.9761 - precision_2: 0.9785 - recall_2: 0.9738\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0548 - acc: 0.9792 - precision_2: 0.9819 - recall_2: 0.9764\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0543 - acc: 0.9803 - precision_2: 0.9787 - recall_2: 0.9820\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0496 - acc: 0.9817 - precision_2: 0.9823 - recall_2: 0.98130s - loss: 0.0490 - acc: 0.9818 - precision_2: 0.9822 - recall\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0525 - acc: 0.9797 - precision_2: 0.9805 - recall_2: 0.9789\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0513 - acc: 0.9806 - precision_2: 0.9817 - recall_2: 0.9796\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0533 - acc: 0.9794 - precision_2: 0.9812 - recall_2: 0.9777\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0513 - acc: 0.9797 - precision_2: 0.9810 - recall_2: 0.9784\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0469 - acc: 0.9820 - precision_2: 0.9823 - recall_2: 0.9818\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.0366 - acc: 0.9865 - precision_2: 0.9888 - recall_2: 0.9842\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.0371 - acc: 0.9848 - precision_2: 0.9852 - recall_2: 0.9845\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.0425 - acc: 0.9842 - precision_2: 0.9854 - recall_2: 0.9830\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0431 - acc: 0.9838 - precision_2: 0.9861 - recall_2: 0.9815\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.0432 - acc: 0.9846 - precision_2: 0.9868 - recall_2: 0.98 - 10s 38ms/step - loss: 0.0431 - acc: 0.9847 - precision_2: 0.9868 - recall_2: 0.9825\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0400 - acc: 0.9838 - precision_2: 0.9866 - recall_2: 0.9811\n",
      "Epoch 00034: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1015 - acc: 0.7766 - precision_2: 0.8087 - recall_2: 0.7108\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.5275 - acc: 0.7338 - precision_3: 0.7359 - recall_3: 0.7269\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.4616 - acc: 0.7771 - precision_3: 0.7884 - recall_3: 0.7555\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.4192 - acc: 0.8002 - precision_3: 0.8037 - recall_3: 0.7929\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3665 - acc: 0.8320 - precision_3: 0.8381 - recall_3: 0.8217\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.3094 - acc: 0.8653 - precision_3: 0.8680 - recall_3: 0.8608\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0676 - acc: 0.9719 - precision_3: 0.9735 - recall_3: 0.9700\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0647 - acc: 0.9750 - precision_3: 0.9769 - recall_3: 0.9729\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0546 - acc: 0.9788 - precision_3: 0.9802 - recall_3: 0.9773\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0467 - acc: 0.9833 - precision_3: 0.9839 - recall_3: 0.98271s - loss: 0.0463 - acc: 0.9836 - precision_\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0505 - acc: 0.9803 - precision_3: 0.9814 - recall_3: 0.9790\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0528 - acc: 0.9800 - precision_3: 0.9821 - recall_3: 0.9778\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0552 - acc: 0.9789 - precision_3: 0.9778 - recall_3: 0.9800\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0529 - acc: 0.9816 - precision_3: 0.9831 - recall_3: 0.9800\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0464 - acc: 0.9834 - precision_3: 0.9843 - recall_3: 0.9824\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0429 - acc: 0.9837 - precision_3: 0.9851 - recall_3: 0.9822\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0441 - acc: 0.9832 - precision_3: 0.9841 - recall_3: 0.9822\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0434 - acc: 0.9839 - precision_3: 0.9853 - recall_3: 0.9824\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0451 - acc: 0.9844 - precision_3: 0.9851 - recall_3: 0.9836\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0386 - acc: 0.9850 - precision_3: 0.9851 - recall_3: 0.9849\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0354 - acc: 0.9858 - precision_3: 0.9873 - recall_3: 0.9841\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0405 - acc: 0.9853 - precision_3: 0.9872 - recall_3: 0.9831\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0397 - acc: 0.9861 - precision_3: 0.9870 - recall_3: 0.9851\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0420 - acc: 0.9834 - precision_3: 0.9832 - recall_3: 0.9836\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0414 - acc: 0.9847 - precision_3: 0.9863 - recall_3: 0.9829\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0375 - acc: 0.9860 - precision_3: 0.9873 - recall_3: 0.9846\n",
      "Epoch 00038: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1098 - acc: 0.7722 - precision_3: 0.7986 - recall_3: 0.7441 0s - loss: 1.1282 - acc: 0.7587 - precision_3: 0.7881 - recall_3: \n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 7s 26ms/step - loss: 0.5307 - acc: 0.7365 - precision_4: 0.7366 - recall_4: 0.7391\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.4650 - acc: 0.7762 - precision_4: 0.7857 - recall_4: 0.7617\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.4176 - acc: 0.8024 - precision_4: 0.8114 - recall_4: 0.7896\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 8s 33ms/step - loss: 0.3782 - acc: 0.8243 - precision_4: 0.8306 - recall_4: 0.8163\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 9s 35ms/step - loss: 0.3300 - acc: 0.8456 - precision_4: 0.8500 - recall_4: 0.8405\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.2661 - acc: 0.8866 - precision_4: 0.8899 - recall_4: 0.8833\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 33ms/step - loss: 0.2242 - acc: 0.9039 - precision_4: 0.9067 - recall_4: 0.9012\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.1833 - acc: 0.9227 - precision_4: 0.9214 - recall_4: 0.9248\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 9s 34ms/step - loss: 0.1493 - acc: 0.9386 - precision_4: 0.9390 - recall_4: 0.9386\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1318 - acc: 0.9486 - precision_4: 0.9503 - recall_4: 0.9471\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1222 - acc: 0.9512 - precision_4: 0.9519 - recall_4: 0.9507\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.1065 - acc: 0.9592 - precision_4: 0.9617 - recall_4: 0.9568\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0922 - acc: 0.9638 - precision_4: 0.9657 - recall_4: 0.9621\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0866 - acc: 0.9652 - precision_4: 0.9651 - recall_4: 0.9655\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0811 - acc: 0.9697 - precision_4: 0.9701 - recall_4: 0.9694\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0729 - acc: 0.9719 - precision_4: 0.9730 - recall_4: 0.9709\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0661 - acc: 0.9736 - precision_4: 0.9740 - recall_4: 0.9733\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0700 - acc: 0.9715 - precision_4: 0.9737 - recall_4: 0.96940s - loss: 0.0688 - acc: 0.9721 - precision_4: 0.9738 - recall_4\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0649 - acc: 0.9750 - precision_4: 0.9762 - recall_4: 0.9740\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0624 - acc: 0.9752 - precision_4: 0.9769 - recall_4: 0.9735\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0575 - acc: 0.9771 - precision_4: 0.9786 - recall_4: 0.9757\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0745 - acc: 0.9697 - precision_5: 0.9698 - recall_5: 0.9696\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0721 - acc: 0.9713 - precision_5: 0.9754 - recall_5: 0.9669\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0738 - acc: 0.9714 - precision_5: 0.9726 - recall_5: 0.9700\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0663 - acc: 0.9713 - precision_5: 0.9726 - recall_5: 0.9698\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0569 - acc: 0.9782 - precision_5: 0.9793 - recall_5: 0.9771\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0557 - acc: 0.9783 - precision_5: 0.9809 - recall_5: 0.9756\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0562 - acc: 0.9784 - precision_5: 0.9795 - recall_5: 0.9774\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0585 - acc: 0.9774 - precision_5: 0.9783 - recall_5: 0.9764\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0502 - acc: 0.9787 - precision_5: 0.9812 - recall_5: 0.9761\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0574 - acc: 0.9771 - precision_5: 0.9799 - recall_5: 0.9742\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0468 - acc: 0.9834 - precision_5: 0.9865 - recall_5: 0.9803\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0502 - acc: 0.9827 - precision_5: 0.9848 - recall_5: 0.9805\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0430 - acc: 0.9825 - precision_5: 0.9844 - recall_5: 0.9805\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0418 - acc: 0.9837 - precision_5: 0.9853 - recall_5: 0.9820\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0459 - acc: 0.9817 - precision_5: 0.9848 - recall_5: 0.9786\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0443 - acc: 0.9839 - precision_5: 0.9846 - recall_5: 0.9832\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0382 - acc: 0.9849 - precision_5: 0.9875 - recall_5: 0.9822\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0431 - acc: 0.9839 - precision_5: 0.9875 - recall_5: 0.9803\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0366 - acc: 0.9860 - precision_5: 0.9892 - recall_5: 0.9827\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0357 - acc: 0.9865 - precision_5: 0.9890 - recall_5: 0.9839\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0350 - acc: 0.9871 - precision_5: 0.9883 - recall_5: 0.9859\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.0468 - acc: 0.9825 - precision_5: 0.9851 - recall_5: 0.9798\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 6s 25ms/step - loss: 0.0339 - acc: 0.9867 - precision_5: 0.9907 - recall_5: 0.9827\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 6s 24ms/step - loss: 0.0340 - acc: 0.9861 - precision_5: 0.9883 - recall_5: 0.9839\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.4580 - acc: 0.7780 - precision_6: 0.7858 - recall_6: 0.7622\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.4107 - acc: 0.8081 - precision_6: 0.8165 - recall_6: 0.7930\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.3617 - acc: 0.8315 - precision_6: 0.8366 - recall_6: 0.8223\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.3061 - acc: 0.8619 - precision_6: 0.8681 - recall_6: 0.8524\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.2605 - acc: 0.8883 - precision_6: 0.8878 - recall_6: 0.8880\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2133 - acc: 0.9123 - precision_6: 0.9142 - recall_6: 0.90930s - loss: 0.2133 - acc: 0.9123 - precision_6: 0.9142 - recall_6: 0.90\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1667 - acc: 0.9333 - precision_6: 0.9337 - recall_6: 0.9323\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1563 - acc: 0.9361 - precision_6: 0.9357 - recall_6: 0.93600s - loss: 0.1551 - acc: 0.9375 - precision_6: 0.9\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1318 - acc: 0.9464 - precision_6: 0.9464 - recall_6: 0.9460\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1072 - acc: 0.9565 - precision_6: 0.9578 - recall_6: 0.9548\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.1038 - acc: 0.9581 - precision_6: 0.9595 - recall_6: 0.9562\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0875 - acc: 0.9677 - precision_6: 0.9673 - recall_6: 0.9680\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0887 - acc: 0.9627 - precision_6: 0.9642 - recall_6: 0.9609\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0786 - acc: 0.9686 - precision_6: 0.9719 - recall_6: 0.9648\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0735 - acc: 0.9733 - precision_6: 0.9750 - recall_6: 0.97145s - loss: 0.071\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0644 - acc: 0.9763 - precision_6: 0.9770 - recall_6: 0.9753\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0660 - acc: 0.9736 - precision_6: 0.9731 - recall_6: 0.9738\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0690 - acc: 0.9735 - precision_6: 0.9747 - recall_6: 0.97190s - loss: 0.0660 - acc: 0.9746 - precision_6: 0.9757 - \n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0498 - acc: 0.9820 - precision_6: 0.9829 - recall_6: 0.9809\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.0456 - acc: 0.9827 - precision_6: 0.9855 - recall_6: 0.9797\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0387 - acc: 0.9867 - precision_6: 0.9868 - recall_6: 0.9866\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0468 - acc: 0.9805 - precision_6: 0.9828 - recall_6: 0.9780\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0452 - acc: 0.9827 - precision_6: 0.9834 - recall_6: 0.9819\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0500 - acc: 0.9808 - precision_6: 0.9823 - recall_6: 0.97902s - l\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0428 - acc: 0.9831 - precision_6: 0.9857 - recall_6: 0.9802\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0363 - acc: 0.9866 - precision_6: 0.9889 - recall_6: 0.9841\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0356 - acc: 0.9867 - precision_6: 0.9887 - recall_6: 0.9846\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0332 - acc: 0.9876 - precision_6: 0.9885 - recall_6: 0.9866\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0425 - acc: 0.9831 - precision_6: 0.9853 - recall_6: 0.9807\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0384 - acc: 0.9869 - precision_6: 0.9880 - recall_6: 0.9856\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0332 - acc: 0.9892 - precision_6: 0.9902 - recall_6: 0.9880\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0304 - acc: 0.9886 - precision_6: 0.9897 - recall_6: 0.9873\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0339 - acc: 0.9861 - precision_6: 0.9882 - recall_6: 0.9839\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0351 - acc: 0.9877 - precision_6: 0.9885 - recall_6: 0.9868\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0398 - acc: 0.9838 - precision_6: 0.9853 - recall_6: 0.9822\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0361 - acc: 0.9844 - precision_6: 0.9875 - recall_6: 0.9812\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0391 - acc: 0.9850 - precision_6: 0.9884 - recall_6: 0.9814\n",
      "Epoch 00043: early stopping\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.3018 - acc: 0.7382 - precision_6: 0.7505 - recall_6: 0.7394\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5263 - acc: 0.7353 - precision_7: 0.7373 - recall_7: 0.7286\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.4633 - acc: 0.7699 - precision_7: 0.7737 - recall_7: 0.7609\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.4172 - acc: 0.8029 - precision_7: 0.8087 - recall_7: 0.79191s - loss: 0.4185 - acc: 0.8029 - prec\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.3654 - acc: 0.8338 - precision_7: 0.8363 - recall_7: 0.8288\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.3057 - acc: 0.8664 - precision_7: 0.8675 - recall_7: 0.8639\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2609 - acc: 0.8901 - precision_7: 0.8902 - recall_7: 0.8891\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.2073 - acc: 0.9149 - precision_7: 0.9137 - recall_7: 0.9157 3s - loss: 0.1952 - acc: 0.9187 - precision_ - ETA: 2s - l\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.1733 - acc: 0.9301 - precision_7: 0.9301 - recall_7: 0.9297\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.1393 - acc: 0.9418 - precision_7: 0.9418 - recall_7: 0.9414\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.1276 - acc: 0.9498 - precision_7: 0.9497 - recall_7: 0.9497\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.1052 - acc: 0.9589 - precision_7: 0.9598 - recall_7: 0.9575\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.1104 - acc: 0.9537 - precision_7: 0.9538 - recall_7: 0.9533\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.0966 - acc: 0.9632 - precision_7: 0.9645 - recall_7: 0.9617\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0812 - acc: 0.9675 - precision_7: 0.9677 - recall_7: 0.96704s - loss: 0 - ETA: 2s - loss: 0.0775 \n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0869 - acc: 0.9670 - precision_7: 0.9675 - recall_7: 0.9663\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0666 - acc: 0.9737 - precision_7: 0.9757 - recall_7: 0.9714\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0690 - acc: 0.9739 - precision_7: 0.9743 - recall_7: 0.9734\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0673 - acc: 0.9747 - precision_7: 0.9762 - recall_7: 0.9729\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0547 - acc: 0.9788 - precision_7: 0.9806 - recall_7: 0.9768\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0660 - acc: 0.9722 - precision_7: 0.9742 - recall_7: 0.9700\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0569 - acc: 0.9793 - precision_7: 0.9823 - recall_7: 0.97611s - loss: 0.0580 - acc: 0.9797 - prec\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0552 - acc: 0.9783 - precision_7: 0.9799 - recall_7: 0.9766\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0556 - acc: 0.9778 - precision_7: 0.9780 - recall_7: 0.9775\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0513 - acc: 0.9805 - precision_7: 0.9828 - recall_7: 0.97804s - loss: 0.0505 - acc: 0.9809 - pr\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0480 - acc: 0.9836 - precision_7: 0.9829 - recall_7: 0.9841\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0418 - acc: 0.9837 - precision_7: 0.9867 - recall_7: 0.9805\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0504 - acc: 0.9816 - precision_7: 0.9833 - recall_7: 0.9797\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0447 - acc: 0.9825 - precision_7: 0.9843 - recall_7: 0.9805\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0471 - acc: 0.9809 - precision_7: 0.9835 - recall_7: 0.9780\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0455 - acc: 0.9841 - precision_7: 0.9865 - recall_7: 0.9814\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0413 - acc: 0.9866 - precision_7: 0.9880 - recall_7: 0.9851\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0358 - acc: 0.9865 - precision_7: 0.9882 - recall_7: 0.9846\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0435 - acc: 0.9825 - precision_7: 0.9848 - recall_7: 0.9800\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0421 - acc: 0.9838 - precision_7: 0.9848 - recall_7: 0.9827\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0398 - acc: 0.9853 - precision_7: 0.9877 - recall_7: 0.9827\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0364 - acc: 0.9869 - precision_7: 0.9880 - recall_7: 0.9856\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0340 - acc: 0.9867 - precision_7: 0.9892 - recall_7: 0.9841\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0347 - acc: 0.9862 - precision_7: 0.9882 - recall_7: 0.9841\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0367 - acc: 0.9858 - precision_7: 0.9882 - recall_7: 0.9831\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0358 - acc: 0.9873 - precision_7: 0.9885 - recall_7: 0.9861\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0348 - acc: 0.9878 - precision_7: 0.9902 - recall_7: 0.9853\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0312 - acc: 0.9886 - precision_7: 0.9912 - recall_7: 0.9858\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0290 - acc: 0.9881 - precision_7: 0.9902 - recall_7: 0.98588s - loss: 0.033\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0335 - acc: 0.9883 - precision_7: 0.9914 - recall_7: 0.98518s - loss: 0.1883 - acc: 0.9583 - prec\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0295 - acc: 0.9892 - precision_7: 0.9914 - recall_7: 0.9868\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0384 - acc: 0.9861 - precision_7: 0.9877 - recall_7: 0.9844\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0298 - acc: 0.9883 - precision_7: 0.9904 - recall_7: 0.98612s - loss: 0.0291 \n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0308 - acc: 0.9892 - precision_7: 0.9912 - recall_7: 0.9871\n",
      "Epoch 00048: early stopping\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.3289 - acc: 0.7390 - precision_7: 0.7692 - recall_7: 0.7036\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5323 - acc: 0.7295 - precision_8: 0.7292 - recall_8: 0.73703s - loss: 0.5513 - acc: 0.7145 - precisio - ETA: 2s - loss: 0.5\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.4610 - acc: 0.7773 - precision_8: 0.7881 - recall_8: 0.7635\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4198 - acc: 0.8027 - precision_8: 0.8140 - recall_8: 0.7886\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.3739 - acc: 0.8291 - precision_8: 0.8388 - recall_8: 0.8181\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.3160 - acc: 0.8604 - precision_8: 0.8656 - recall_8: 0.8558\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2628 - acc: 0.8826 - precision_8: 0.8839 - recall_8: 0.8831\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2081 - acc: 0.9142 - precision_8: 0.9182 - recall_8: 0.9109\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.1749 - acc: 0.9283 - precision_8: 0.9311 - recall_8: 0.9263\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1480 - acc: 0.9430 - precision_8: 0.9443 - recall_8: 0.9425\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1217 - acc: 0.9501 - precision_8: 0.9505 - recall_8: 0.9505\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1104 - acc: 0.9553 - precision_8: 0.9567 - recall_8: 0.9546\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0923 - acc: 0.9617 - precision_8: 0.9650 - recall_8: 0.9587\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0940 - acc: 0.9615 - precision_8: 0.9634 - recall_8: 0.9601\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0834 - acc: 0.9683 - precision_8: 0.9691 - recall_8: 0.9681\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0771 - acc: 0.9710 - precision_8: 0.9719 - recall_8: 0.9705\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0739 - acc: 0.9708 - precision_8: 0.9728 - recall_8: 0.96910s - loss: 0.0736 - acc: 0.9708 - precision_8: 0.9728 - recall_8: \n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0683 - acc: 0.9724 - precision_8: 0.9743 - recall_8: 0.9708\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0701 - acc: 0.9730 - precision_8: 0.9734 - recall_8: 0.9729\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0631 - acc: 0.9755 - precision_8: 0.9782 - recall_8: 0.9732\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0640 - acc: 0.9752 - precision_8: 0.9763 - recall_8: 0.9744\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0567 - acc: 0.9782 - precision_8: 0.9804 - recall_8: 0.9763\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0575 - acc: 0.9789 - precision_8: 0.9795 - recall_8: 0.9787\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0485 - acc: 0.9822 - precision_8: 0.9847 - recall_8: 0.9800\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 10s 37ms/step - loss: 0.0434 - acc: 0.9839 - precision_8: 0.9841 - recall_8: 0.9841\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 38ms/step - loss: 0.0569 - acc: 0.9777 - precision_8: 0.9792 - recall_8: 0.97661s - loss: 0.0538 \n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 9s 36ms/step - loss: 0.0497 - acc: 0.9803 - precision_8: 0.9830 - recall_8: 0.9778\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.0431 - acc: 0.9842 - precision_8: 0.9843 - recall_8: 0.9843\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.0466 - acc: 0.9826 - precision_8: 0.9845 - recall_8: 0.9809 3s - loss: 0.0368 - acc: 0.9853 - prec - ETA: 2s - loss: 0.0412 - acc: 0.9845 - precis - ETA: 1s\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.0452 - acc: 0.9822 - precision_8: 0.9817 - recall_8: 0.9831\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.0514 - acc: 0.9803 - precision_8: 0.9828 - recall_8: 0.9780\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 7s 27ms/step - loss: 0.0448 - acc: 0.9823 - precision_8: 0.9824 - recall_8: 0.9826\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 9s 37ms/step - loss: 0.0397 - acc: 0.9847 - precision_8: 0.9867 - recall_8: 0.9829\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0460 - acc: 0.9815 - precision_8: 0.9828 - recall_8: 0.9804\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0380 - acc: 0.9858 - precision_8: 0.9874 - recall_8: 0.9843\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0342 - acc: 0.9866 - precision_8: 0.9877 - recall_8: 0.98570s - loss: 0.0332 - acc: 0.9868 - precision_8: 0.988\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0378 - acc: 0.9859 - precision_8: 0.9898 - recall_8: 0.9821\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0323 - acc: 0.9869 - precision_8: 0.9881 - recall_8: 0.9857\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0355 - acc: 0.9867 - precision_8: 0.9886 - recall_8: 0.9850\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0418 - acc: 0.9843 - precision_8: 0.9869 - recall_8: 0.98192s - l\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0335 - acc: 0.9883 - precision_8: 0.9915 - recall_8: 0.9853\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0375 - acc: 0.9865 - precision_8: 0.9881 - recall_8: 0.9850\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0359 - acc: 0.9860 - precision_8: 0.9898 - recall_8: 0.9824\n",
      "Epoch 00042: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1046 - acc: 0.7719 - precision_8: 0.7394 - recall_8: 0.7849\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.5177 - acc: 0.7396 - precision_9: 0.7416 - recall_9: 0.7287\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.4508 - acc: 0.7801 - precision_9: 0.7862 - recall_9: 0.7645\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.3982 - acc: 0.8170 - precision_9: 0.8256 - recall_9: 0.7999\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.3473 - acc: 0.8461 - precision_9: 0.8464 - recall_9: 0.8426\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.2957 - acc: 0.8720 - precision_9: 0.8762 - recall_9: 0.8640\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.2461 - acc: 0.8963 - precision_9: 0.8987 - recall_9: 0.8912\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.2008 - acc: 0.9171 - precision_9: 0.9192 - recall_9: 0.91311s - loss: 0.1969 - ac\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1605 - acc: 0.9332 - precision_9: 0.9325 - recall_9: 0.9327\n",
      "Epoch 9/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1393 - acc: 0.9439 - precision_9: 0.9435 - recall_9: 0.9433\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.1139 - acc: 0.9539 - precision_9: 0.9556 - recall_9: 0.9511\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.1031 - acc: 0.9589 - precision_9: 0.9587 - recall_9: 0.9583\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0910 - acc: 0.9648 - precision_9: 0.9665 - recall_9: 0.96242s - loss: 0.0925 - acc: 0.9654 - precision_9: 0.9677 - recall_9 - ETA: 2s - l\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0829 - acc: 0.9683 - precision_9: 0.9690 - recall_9: 0.9671\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0708 - acc: 0.9735 - precision_9: 0.9746 - recall_9: 0.97181s - loss: 0.0698 - acc:\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0744 - acc: 0.9730 - precision_9: 0.9741 - recall_9: 0.9713\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0613 - acc: 0.9769 - precision_9: 0.9764 - recall_9: 0.9769\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0592 - acc: 0.9778 - precision_9: 0.9784 - recall_9: 0.9769\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0518 - acc: 0.9793 - precision_9: 0.9801 - recall_9: 0.9781\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0491 - acc: 0.9831 - precision_9: 0.9831 - recall_9: 0.9828\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0612 - acc: 0.9777 - precision_9: 0.9795 - recall_9: 0.9754\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0489 - acc: 0.9819 - precision_9: 0.9842 - recall_9: 0.9791\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0510 - acc: 0.9803 - precision_9: 0.9799 - recall_9: 0.9804\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0464 - acc: 0.9826 - precision_9: 0.9833 - recall_9: 0.9816\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0500 - acc: 0.9821 - precision_9: 0.9840 - recall_9: 0.9799\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0396 - acc: 0.9859 - precision_9: 0.9870 - recall_9: 0.9845\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0436 - acc: 0.9831 - precision_9: 0.9823 - recall_9: 0.9836\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0303 - acc: 0.9893 - precision_9: 0.9894 - recall_9: 0.98900s - loss: 0.0306 - acc: 0.9890 - precision_9: 0.9893 - \n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0312 - acc: 0.9892 - precision_9: 0.9904 - recall_9: 0.9877\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0378 - acc: 0.9862 - precision_9: 0.9858 - recall_9: 0.9865\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0411 - acc: 0.9859 - precision_9: 0.9865 - recall_9: 0.9850\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0348 - acc: 0.9873 - precision_9: 0.9877 - recall_9: 0.9867\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - 10s 41ms/step - loss: 0.0291 - acc: 0.9893 - precision_9: 0.9885 - recall_9: 0.9899\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0389 - acc: 0.9858 - precision_9: 0.9848 - recall_9: 0.9865\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 41ms/step - loss: 0.0356 - acc: 0.9878 - precision_9: 0.9882 - recall_9: 0.9872\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0354 - acc: 0.9879 - precision_9: 0.9875 - recall_9: 0.9882\n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.0316 - acc: 0.9878 - precision_9: 0.9887 - recall_9: 0.98670s - loss: 0.0317 - acc: 0.9878 - precision_9: 0.9887 - recall_9: 0.98\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 11s 42ms/step - loss: 0.0367 - acc: 0.9872 - precision_9: 0.9865 - recall_9: 0.9877\n",
      "Epoch 00037: early stopping\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.2022 - acc: 0.7719 - precision_9: 0.8264 - recall_9: 0.7286\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.5307 - acc: 0.7334 - precision_10: 0.7421 - recall_10: 0.7164\n",
      "Epoch 2/50\n",
      "257/257 [==============================] - 10s 40ms/step - loss: 0.4628 - acc: 0.7742 - precision_10: 0.7828 - recall_10: 0.7597\n",
      "Epoch 3/50\n",
      "257/257 [==============================] - 10s 39ms/step - loss: 0.4148 - acc: 0.8048 - precision_10: 0.8074 - recall_10: 0.8013\n",
      "Epoch 4/50\n",
      "257/257 [==============================] - 7s 28ms/step - loss: 0.3668 - acc: 0.8313 - precision_10: 0.8364 - recall_10: 0.8242\n",
      "Epoch 5/50\n",
      "257/257 [==============================] - 8s 29ms/step - loss: 0.3174 - acc: 0.8583 - precision_10: 0.8597 - recall_10: 0.8568 0s - loss: 0.3162 - acc: 0.8589 - precisio\n",
      "Epoch 6/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.2639 - acc: 0.8852 - precision_10: 0.8852 - recall_10: 0.8855\n",
      "Epoch 7/50\n",
      "257/257 [==============================] - 8s 30ms/step - loss: 0.2125 - acc: 0.9084 - precision_10: 0.9106 - recall_10: 0.9061 2s - loss: - ETA: 0s - loss: 0.2118 - acc: 0.9090 - precision_10: 0.9114 - recall_10\n",
      "Epoch 8/50\n",
      "257/257 [==============================] - 7s 29ms/step - loss: 0.1759 - acc: 0.9273 - precision_10: 0.9286 - recall_10: 0.9261\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 11s 43ms/step - loss: 0.1511 - acc: 0.9374 - precision_10: 0.9384 - recall_10: 0.9365\n",
      "Epoch 10/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.1257 - acc: 0.9489 - precision_10: 0.9509 - recall_10: 0.94676s - loss: 0.1121 - acc: 0.9566 - precision_10: 0.9614 - ETA: 5s - l - ETA: 2s - l\n",
      "Epoch 11/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.1075 - acc: 0.9567 - precision_10: 0.9583 - recall_10: 0.95505s - l\n",
      "Epoch 12/50\n",
      "257/257 [==============================] - 11s 43ms/step - loss: 0.0974 - acc: 0.9621 - precision_10: 0.9641 - recall_10: 0.9601\n",
      "Epoch 13/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0863 - acc: 0.9663 - precision_10: 0.9678 - recall_10: 0.9647\n",
      "Epoch 14/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.0836 - acc: 0.9654 - precision_10: 0.9684 - recall_10: 0.9623\n",
      "Epoch 15/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0811 - acc: 0.9686 - precision_10: 0.9709 - recall_10: 0.9662\n",
      "Epoch 16/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0764 - acc: 0.9694 - precision_10: 0.9701 - recall_10: 0.9689\n",
      "Epoch 17/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0672 - acc: 0.9720 - precision_10: 0.9736 - recall_10: 0.9703\n",
      "Epoch 18/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0648 - acc: 0.9736 - precision_10: 0.9747 - recall_10: 0.9725\n",
      "Epoch 19/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0613 - acc: 0.9761 - precision_10: 0.9785 - recall_10: 0.97374s - loss: 0.0640 - acc: 0.9 - ETA: 3s - loss: 0.0605 - acc: 0.9756 - precision_ - ETA: 2s - loss: 0.0613 - acc:\n",
      "Epoch 20/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0644 - acc: 0.9764 - precision_10: 0.9785 - recall_10: 0.9742\n",
      "Epoch 21/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0571 - acc: 0.9777 - precision_10: 0.9809 - recall_10: 0.9745\n",
      "Epoch 22/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0480 - acc: 0.9828 - precision_10: 0.9849 - recall_10: 0.9808\n",
      "Epoch 23/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0523 - acc: 0.9794 - precision_10: 0.9812 - recall_10: 0.9776\n",
      "Epoch 24/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0541 - acc: 0.9794 - precision_10: 0.9810 - recall_10: 0.9779\n",
      "Epoch 25/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0475 - acc: 0.9821 - precision_10: 0.9846 - recall_10: 0.97960s - loss: 0.0470 - acc: 0.9825 - precision_10: 0.\n",
      "Epoch 26/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0520 - acc: 0.9810 - precision_10: 0.9827 - recall_10: 0.97931s - loss: 0.0497 - acc:\n",
      "Epoch 27/50\n",
      "257/257 [==============================] - 12s 46ms/step - loss: 0.0435 - acc: 0.9845 - precision_10: 0.9866 - recall_10: 0.9825\n",
      "Epoch 28/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0416 - acc: 0.9842 - precision_10: 0.9854 - recall_10: 0.9830\n",
      "Epoch 29/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.0476 - acc: 0.9798 - precision_10: 0.9817 - recall_10: 0.9779\n",
      "Epoch 30/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0460 - acc: 0.9827 - precision_10: 0.9839 - recall_10: 0.9815\n",
      "Epoch 31/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0445 - acc: 0.9825 - precision_10: 0.9846 - recall_10: 0.98030s - loss: 0.0446 - acc: 0.9824 - precision_10: 0.9846 - recall_10: 0.98\n",
      "Epoch 32/50\n",
      "257/257 [==============================] - ETA: 0s - loss: 0.0458 - acc: 0.9814 - precision_10: 0.9827 - recall_10: 0.98 - 12s 45ms/step - loss: 0.0458 - acc: 0.9814 - precision_10: 0.9827 - recall_10: 0.9801\n",
      "Epoch 33/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0350 - acc: 0.9864 - precision_10: 0.9876 - recall_10: 0.9852\n",
      "Epoch 34/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0393 - acc: 0.9838 - precision_10: 0.9863 - recall_10: 0.98132s - loss: 0.0\n",
      "Epoch 35/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0385 - acc: 0.9837 - precision_10: 0.9842 - recall_10: 0.98321s - loss: 0.0370 - acc: 0.9840 - \n",
      "Epoch 36/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0358 - acc: 0.9861 - precision_10: 0.9864 - recall_10: 0.98591s - loss: 0.0328 - acc: 0.988\n",
      "Epoch 37/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0379 - acc: 0.9860 - precision_10: 0.9878 - recall_10: 0.9842\n",
      "Epoch 38/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0329 - acc: 0.9870 - precision_10: 0.9876 - recall_10: 0.98642s - loss: 0.0\n",
      "Epoch 39/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0377 - acc: 0.9844 - precision_10: 0.9859 - recall_10: 0.9830\n",
      "Epoch 40/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0371 - acc: 0.9870 - precision_10: 0.9885 - recall_10: 0.98543s - loss: 0.0369 - acc: 0.9884 - precision_10: 0.9896 - r\n",
      "Epoch 41/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0340 - acc: 0.9869 - precision_10: 0.9895 - recall_10: 0.98427s - loss: 0 - ETA:  - ETA: 2s - loss: 0.0336 - acc:\n",
      "Epoch 42/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.0306 - acc: 0.9873 - precision_10: 0.9897 - recall_10: 0.9849\n",
      "Epoch 43/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0322 - acc: 0.9882 - precision_10: 0.9902 - recall_10: 0.9861\n",
      "Epoch 44/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.0395 - acc: 0.9856 - precision_10: 0.9859 - recall_10: 0.9854\n",
      "Epoch 45/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0368 - acc: 0.9854 - precision_10: 0.9871 - recall_10: 0.9837\n",
      "Epoch 46/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0332 - acc: 0.9872 - precision_10: 0.9890 - recall_10: 0.9854\n",
      "Epoch 47/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0292 - acc: 0.9889 - precision_10: 0.9900 - recall_10: 0.98781s - loss: 0.0302 - acc: 0.9885 - pr\n",
      "Epoch 48/50\n",
      "257/257 [==============================] - 12s 45ms/step - loss: 0.0388 - acc: 0.9851 - precision_10: 0.9863 - recall_10: 0.98390s - loss: 0.0388 - acc: 0.9851 - precision_10: 0.9863 - recall_10: 0.98\n",
      "Epoch 49/50\n",
      "257/257 [==============================] - 11s 45ms/step - loss: 0.0319 - acc: 0.9875 - precision_10: 0.9900 - recall_10: 0.98496s - loss: 0.0234 - acc: - ETA: 4s - los - ETA: 2s - loss: 0.0316 - acc: 0.9879 - precision_10: 0. - ETA: 1s - loss: 0.0317 - acc: 0.9877 - precision_\n",
      "Epoch 50/50\n",
      "257/257 [==============================] - 11s 44ms/step - loss: 0.0252 - acc: 0.9909 - precision_10: 0.9920 - recall_10: 0.9898\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 1.1215 - acc: 0.7939 - precision_10: 0.7955 - recall_10: 0.7849\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "pat = 5\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=True)\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "    X_train=inputs[train].tolist()\n",
    "    y_train=targets[train].tolist()\n",
    "    X_test=inputs[test].tolist()\n",
    "    y_test=targets[test].tolist()\n",
    "    \n",
    "    embedding_layer,X_train,y_train,X_test,y_test= word2vec (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    modelCNNLSTM = Sequential() #cnn\n",
    "\n",
    "    modelCNNLSTM.add(embedding_layer)\n",
    "    modelCNNLSTM.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "    modelCNNLSTM.add(MaxPooling1D(pool_size=4))\n",
    "    modelCNNLSTM.add(Dropout(0.25))\n",
    "    modelCNNLSTM.add(LSTM(128))                            \n",
    "    modelCNNLSTM.add(Flatten())\n",
    "    modelCNNLSTM.add(Dense(1, activation='sigmoid'))\n",
    "    modelCNNLSTM.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                         metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    modelCNNLSTM.fit(X_train, y_train, epochs=50,callbacks=early_stopping)\n",
    "\n",
    "    # evaluate\n",
    "    loss, accuracy, precision, recall = modelCNNLSTM.evaluate(X_test, y_test)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.764959\n",
      "test precision: 0.776274\n",
      "test recall: 0.747418\n",
      "test f1_score: 0.760510\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
