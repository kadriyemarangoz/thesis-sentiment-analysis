{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "!pip install utils\n",
    "from utils import *\n",
    "import random\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "warnings.filterwarnings('ignore') \n",
    "import string\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xlsxwriter \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "from spacy.lang.tr import Turkish\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer,precision_score,recall_score,f1_score\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from glove import Corpus, Glove\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import nltk \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu','preprocessing']\n",
    "df = pd.read_excel(\"../dataset/total.xlsx\")\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duygu==1]),len(df[df.duygu==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['duygu'] == \"olumlu\", \"duygu\"] = 1\n",
    "# df.loc[df['duygu'] == \"olumsuz\", \"duygu\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    \n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_precision_score(y_true, y_pred):\n",
    "    \n",
    "    return precision_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_recall_score(y_true, y_pred):\n",
    "    \n",
    "    return recall_score(y_true, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classification_report_with_f1_score(y_true, y_pred):\n",
    "    \n",
    "    return f1_score(y_true, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = [word_tokenize(i) for i in df.tweets.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "n_features=32\n",
    "window_size=5\n",
    "min_count=10\n",
    "epoch=50\n",
    "n_workers=8\n",
    "\n",
    "word2vec = Word2Vec(size = n_features,\n",
    "            window = window_size, \n",
    "            min_count= min_count,\n",
    "            workers = n_workers, \n",
    "            sg=0)\n",
    "word2vec.build_vocab(X_t)\n",
    "word2vec.train(X_t, \n",
    "            total_examples=word2vec.corpus_count,  \n",
    "            epochs = epoch)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= Turkish()\n",
    "def feature_extraction_word2vec(text):\n",
    "    yeniMetin = \"\"\n",
    "    for i in text:\n",
    "        if i not in string.punctuation:\n",
    "            yeniMetin += i\n",
    "    vector=np.zeros(32) #400 uzunluğunda boş sıfırlarla bir vektör oluşturdum\n",
    "    for token in nlp(yeniMetin):\n",
    "        word = token.text.lower()\n",
    "        if word not in ['',' ']:\n",
    "            if word in word2vec.wv.vocab: #word2vec.wv.key_to_index.keys()\n",
    "                vector+= word2vec.wv[word] #gensim modeliyle oluşturulan modeli kullandım\n",
    "                #print(vector)\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_total= []\n",
    "y_total=df.duygu.tolist()\n",
    "\n",
    "X_total = []\n",
    "for element in tqdm(df.tweets):\n",
    "    X_total.append(feature_extraction_word2vec(element))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/SVM: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/SVM: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/SVM: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vec/SVM: \",f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "clf = LogisticRegression()\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/LogisticRegression: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/LogisticRegression: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/LogisticRegression: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vec/LogisticRegression: \",f1.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10, 3), random_state=1)\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/MLPC: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/MLPC: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/MLPC: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vecF/MLPC: \",f1.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
