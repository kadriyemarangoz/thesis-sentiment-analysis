{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
    "!pip install utils\n",
    "from utils import *\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer,precision_score,recall_score,f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from spacy.lang.tr import Turkish\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu']#,'preprocessing'\n",
    "df = pd.read_excel(\"../dataset/kemik_total.xlsx\")\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    \n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_precision_score(y_true, y_pred):\n",
    "    \n",
    "    return precision_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_recall_score(y_true, y_pred):\n",
    "    \n",
    "    return recall_score(y_true, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classification_report_with_f1_score(y_true, y_pred):\n",
    "    \n",
    "    return f1_score(y_true, y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_mcc_score(y_true, y_pred):\n",
    "    \n",
    "    return matthews_corrcoef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_with_c_kappa(y_true, y_pred):\n",
    "\n",
    "    return cohen_kappa_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = df['tweets'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tokenizer\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "# Building word indices\n",
    "tokenizer.fit_on_texts(X_t)\n",
    "# Tokenizing sentences\n",
    "sentences = tokenizer.texts_to_sequences(X_t)\n",
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "# Creating texts \n",
    "X_t = list(map(sequence_to_text, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=128\n",
    "window_size=5\n",
    "min_count=10\n",
    "epoch=50\n",
    "n_workers=8\n",
    "\n",
    "word2vec = Word2Vec(size = n_features,\n",
    "            window = window_size, \n",
    "            min_count= min_count,\n",
    "            workers = n_workers, \n",
    "            sg=1)\n",
    "word2vec.build_vocab(X_t)\n",
    "word2vec.train(X_t, \n",
    "            total_examples=word2vec.corpus_count,  \n",
    "            epochs = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= Turkish()\n",
    "def feature_extraction_word2vec(text):\n",
    "    yeniMetin = \"\"\n",
    "    for i in text:\n",
    "        if i not in string.punctuation:\n",
    "            yeniMetin += i\n",
    "    vector=np.zeros(32) #400 uzunluğunda boş sıfırlarla bir vektör oluşturdum\n",
    "    for token in nlp(yeniMetin):\n",
    "        word = token.text.lower()\n",
    "        if word not in ['',' ']:\n",
    "            if word in word2vec.wv.vocab: #word2vec.wv.key_to_index.keys()\n",
    "                vector+= word2vec.wv[word] #gensim modeliyle oluşturulan modeli kullandım\n",
    "                #print(vector)\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_total= []\n",
    "y_total=df.duygu.tolist()\n",
    "\n",
    "X_total = []\n",
    "for element in tqdm(df.tweets):\n",
    "    X_total.append(feature_extraction_word2vec(element))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested CV with parameter optimization\n",
    "svc = svm.SVC(kernel='linear')\n",
    "clf = OneVsRestClassifier(svc)\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/SVM: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/SVM: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/SVM: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vec/SVM: \",f1.mean())\n",
    "\n",
    "mcc_score = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_mcc_score))\n",
    "\n",
    "print(\"MCC_score for word2vec/SVM: \",mcc_score.mean())\n",
    "\n",
    "c_kappa = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_c_kappa))\n",
    "\n",
    "print(\"C_kappa for word2vec/SVM: \",c_kappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  LogisticRegression(multi_class='ovr')\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/LogisticRegression: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/LogisticRegression: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/LogisticRegression: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vec/LogisticRegression: \",f1.mean())\n",
    "\n",
    "mcc_score = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_mcc_score))\n",
    "\n",
    "print(\"MCC_score for word2vec/LogisticRegression: \",mcc_score.mean())\n",
    "\n",
    "c_kappa = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_c_kappa))\n",
    "\n",
    "print(\"C_kappa for word2vec/LogisticRegression: \",c_kappa.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10, 3), random_state=1)\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/MLPC: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/MLPC: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/MLPC: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vecF/MLPC: \",f1.mean())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "accuracy = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(\"Accurancy for word2vec/NB: \",accuracy.mean())\n",
    "\n",
    "\n",
    "precision = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_precision_score))\n",
    "print(\"Precision for word2vec/NB: \",precision.mean())\n",
    "\n",
    "\n",
    "recall = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_recall_score))\n",
    "print(\"Recall for word2vec/NB: \",recall.mean())\n",
    "\n",
    "\n",
    "f1 = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_f1_score))\n",
    "print(\"F1-Score for word2vec/NB: \",f1.mean())\n",
    "\n",
    "mcc_score = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_mcc_score))\n",
    "\n",
    "print(\"MCC_score for word2vec/NB: \",mcc_score.mean())\n",
    "\n",
    "c_kappa = cross_val_score(clf, X_total, y_total, cv=10, \\\n",
    "               scoring=make_scorer(classification_report_with_c_kappa))\n",
    "\n",
    "print(\"C_kappa for word2vec/NB: \",c_kappa.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
