{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# DEEP LEARNING IMPORTS\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import math\n",
    "import bert\n",
    "from tensorflow.keras import layers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()\n",
    "df['tweets']=df['tweets'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell heryerde çekiyor kesin bilgi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell olmak ayrıcalıktir çünkü kuzenlerin v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allahtan turkcell'liyim amin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avea kaşar yaşasın turkcell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets duygu\n",
       "0              turkcell heryerde çekiyor kesin bilgi     1\n",
       "1  turkcell olmak ayrıcalıktir çünkü kuzenlerin v...     1\n",
       "2                       allahtan turkcell'liyim amin     1\n",
       "3                        avea kaşar yaşasın turkcell     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.duygu==\"olumlu\",\"duygu\"]=1\n",
    "df.loc[df.duygu==\"olumsuz\",\"duygu\"]=0\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>duygu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turkcell'im reklamı ne güzel lan. aynı anda se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>turkcell her ay faturami kesmekten bikmadi ben...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keşke tüm temsilcileriniz , müşteri  memnuniye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkcell benim gibi fakirler için bedava sahur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3g koprude cekmedigi gibi e5'te de cekmiyor. o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>bu arada turkcell e tesekkurler |00 |21 mukemm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>turkcell beni nasıl motive edeceğini biliyor @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>turkcell'den daha cok mesaj atan birileri vars...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>turkcell sana her ay 90 100 tl odemkten bıktım...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>turkcell insafa gelmiş yada benim netimi kesec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets duygu\n",
       "0     turkcell'im reklamı ne güzel lan. aynı anda se...     1\n",
       "1     turkcell her ay faturami kesmekten bikmadi ben...     0\n",
       "2     keşke tüm temsilcileriniz , müşteri  memnuniye...     1\n",
       "3     turkcell benim gibi fakirler için bedava sahur...     1\n",
       "4     3g koprude cekmedigi gibi e5'te de cekmiyor. o...     0\n",
       "...                                                 ...   ...\n",
       "9121  bu arada turkcell e tesekkurler |00 |21 mukemm...     1\n",
       "9122  turkcell beni nasıl motive edeceğini biliyor @...     1\n",
       "9123  turkcell'den daha cok mesaj atan birileri vars...     0\n",
       "9124  turkcell sana her ay 90 100 tl odemkten bıktım...     0\n",
       "9125  turkcell insafa gelmiş yada benim netimi kesec...     1\n",
       "\n",
       "[9126 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(df['tweets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\",do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn+lstm\n",
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=256,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=5,\n",
    "                                        padding=\"same\",\n",
    "                                        activation=\"relu\")\n",
    "        self.lstm_layer1 = layers.LSTM(128,return_sequences=True,recurrent_dropout=0.2)\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2=self.lstm_layer1(l)\n",
    "        l_2 = self.pool(l_2) \n",
    "        \n",
    "        concatenated = tf.concat([l_1,l_2], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 50\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=['acc',tf.keras.metrics.Precision(),\n",
    "                                  tf.keras.metrics.Recall()]) #binary cross çünkü sonucun pozitif yada negatif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 0.4544 - acc: 0.7777 - precision: 0.7566 - recall: 0.8151\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 112s 219ms/step - loss: 0.1846 - acc: 0.9295 - precision: 0.9315 - recall: 0.9263\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 111s 217ms/step - loss: 0.0552 - acc: 0.9827 - precision: 0.9824 - recall: 0.9829\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 113s 220ms/step - loss: 0.0263 - acc: 0.9916 - precision: 0.9914 - recall: 0.9917\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 110s 214ms/step - loss: 0.0205 - acc: 0.9937 - precision: 0.9936 - recall: 0.993636s - loss: 0.0175 - acc: 0.9951 - precision: 0.9957 - recall: 0 - ETA: 35s - loss: 0.0184 - acc: 0.9948 - precision: 0.9950 - recall: 0.9 - ETA:\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 112s 217ms/step - loss: 0.0150 - acc: 0.9961 - precision: 0.9958 - recall: 0.9963\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 102s 199ms/step - loss: 0.0122 - acc: 0.9960 - precision: 0.9956 - recall: 0.9963\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 109s 212ms/step - loss: 0.0064 - acc: 0.9976 - precision: 0.9978 - recall: 0.997351s - loss: 0.0101 - acc: 0.9961 - p\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 112s 219ms/step - loss: 0.0068 - acc: 0.9974 - precision: 0.9973 - recall: 0.9976\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 113s 220ms/step - loss: 0.0134 - acc: 0.9965 - precision: 0.9963 - recall: 0.9966\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 112s 218ms/step - loss: 0.0109 - acc: 0.9966 - precision: 0.9968 - recall: 0.9963\n",
      "Epoch 00011: early stopping\n",
      "58/58 [==============================] - 2s 30ms/step - loss: 1.3161 - acc: 0.8007 - precision: 0.7861 - recall: 0.8518\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 113s 220ms/step - loss: 0.0850 - acc: 0.9756 - precision: 0.9753 - recall: 0.9758\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 114s 222ms/step - loss: 0.0083 - acc: 0.9983 - precision: 0.9985 - recall: 0.9980\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 115s 223ms/step - loss: 0.0026 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 113s 221ms/step - loss: 7.3165e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 117s 227ms/step - loss: 0.0023 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 114s 222ms/step - loss: 0.0015 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 116s 226ms/step - loss: 0.0024 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 00007: early stopping\n",
      "58/58 [==============================] - 2s 30ms/step - loss: 0.0150 - acc: 0.9956 - precision: 0.9979 - recall: 0.9937\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 88s 172ms/step - loss: 0.0149 - acc: 0.9954 - precision: 0.9952 - recall: 0.9956\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 109s 212ms/step - loss: 0.0076 - acc: 0.9976 - precision: 0.9973 - recall: 0.9978\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 110s 214ms/step - loss: 0.0073 - acc: 0.9979 - precision: 0.9978 - recall: 0.9981\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 96s 188ms/step - loss: 0.0018 - acc: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 7.8175e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 109s 212ms/step - loss: 9.0045e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 2.0856e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.000016s - loss: 2.4684e\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 1.9821e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 108s 211ms/step - loss: 2.6579e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 108s 211ms/step - loss: 1.9262e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 4.8428e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 0.0012 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 100s 195ms/step - loss: 0.0015 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 00013: early stopping\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 0.0408 - acc: 0.9858 - precision: 0.9882 - recall: 0.9813\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 0.0334 - acc: 0.9895 - precision: 0.9903 - recall: 0.9888\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 111s 215ms/step - loss: 0.0061 - acc: 0.9985 - precision: 0.9990 - recall: 0.9981\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 108s 209ms/step - loss: 9.6063e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 4.6379e-04 - acc: 0.9998 - precision: 1.0000 - recall: 0.9995\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 5.3214e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 6.9202e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 108s 209ms/step - loss: 0.0014 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 00007: early stopping\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.0201 - acc: 0.9945 - precision: 0.9977 - recall: 0.9909\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 0.0137 - acc: 0.9960 - precision: 0.9961 - recall: 0.9959\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 108s 211ms/step - loss: 0.0040 - acc: 0.9985 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 105s 204ms/step - loss: 4.9289e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 100s 195ms/step - loss: 6.8847e-04 - acc: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 107s 207ms/step - loss: 4.9543e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 93s 182ms/step - loss: 2.5607e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 96s 187ms/step - loss: 3.8029e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 6.6802e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 106s 207ms/step - loss: 3.2173e-04 - acc: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 00009: early stopping\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 0.0161 - acc: 0.9989 - precision: 1.0000 - recall: 0.9978\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 106s 206ms/step - loss: 0.0111 - acc: 0.9968 - precision: 0.9971 - recall: 0.9966\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 98s 191ms/step - loss: 0.0092 - acc: 0.9977 - precision: 0.9978 - recall: 0.9976\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 0.0024 - acc: 0.9993 - precision: 0.9990 - recall: 0.9995\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 106s 207ms/step - loss: 5.7582e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 3.3070e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 107s 207ms/step - loss: 3.7897e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 110s 215ms/step - loss: 3.1365e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 3.6809e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 90s 176ms/step - loss: 3.2956e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998 18s - loss: 4.2607e-04 - acc: 0.9997 - precision: 0.999 \n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 106s 206ms/step - loss: 4.8413e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 00010: early stopping\n",
      "58/58 [==============================] - 1s 26ms/step - loss: 0.0059 - acc: 0.9978 - precision: 0.9978 - recall: 0.9978\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 100s 195ms/step - loss: 0.0083 - acc: 0.9982 - precision: 0.9978 - recall: 0.9985\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 105s 205ms/step - loss: 0.0112 - acc: 0.9976 - precision: 0.9976 - recall: 0.9976\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 0.0032 - acc: 0.9991 - precision: 0.9990 - recall: 0.9993\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 8.7565e-04 - acc: 0.9994 - precision: 0.9995 - recall: 0.9993\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 105s 204ms/step - loss: 0.0034 - acc: 0.9989 - precision: 0.9985 - recall: 0.9993\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 101s 196ms/step - loss: 0.0026 - acc: 0.9993 - precision: 0.9993 - recall: 0.99931 - ETA: 34s - loss: 0.0038 - acc: 0.9990 - precisi - ETA: 29s - los\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 107s 207ms/step - loss: 0.0032 - acc: 0.9994 - precision: 0.9993 - recall: 0.9995\n",
      "Epoch 00007: early stopping\n",
      "57/57 [==============================] - 1s 26ms/step - loss: 6.8873e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 108s 209ms/step - loss: 5.1154e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 3.7351e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 109s 212ms/step - loss: 3.9187e-04 - acc: 0.9996 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 3.5699e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 105s 205ms/step - loss: 3.7703e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 85s 166ms/step - loss: 3.5051e-04 - acc: 0.9998 - precision: 0.9995 - recall: 1.0000 12s - los\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 97s 190ms/step - loss: 3.0480e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 99s 194ms/step - loss: 2.5885e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 3.3116e-04 - acc: 0.9998 - precision: 0.9995 - recall: 1.0000\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 106s 206ms/step - loss: 2.7827e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 107s 209ms/step - loss: 4.2152e-04 - acc: 0.9998 - precision: 0.9995 - recall: 1.0000 -\n",
      "Epoch 00011: early stopping\n",
      "57/57 [==============================] - 1s 25ms/step - loss: 6.3370e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 105s 204ms/step - loss: 1.9528e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 108s 210ms/step - loss: 1.9148e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 1.5034e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 1.3855e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 98s 191ms/step - loss: 2.3225e-04 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 107s 208ms/step - loss: 1.8480e-04 - acc: 0.9999 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 106s 207ms/step - loss: 1.9842e-04 - acc: 0.9999 - precision: 0.9998 - recall: 1.0000\n",
      "Epoch 00007: early stopping\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 0.0097 - acc: 0.9989 - precision: 0.9979 - recall: 1.0000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 106s 207ms/step - loss: 0.0012 - acc: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 93s 180ms/step - loss: 0.0260 - acc: 0.9966 - precision: 0.9966 - recall: 0.9966\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 107s 207ms/step - loss: 0.0116 - acc: 0.9983 - precision: 0.9983 - recall: 0.9983\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 105s 205ms/step - loss: 0.0050 - acc: 0.9985 - precision: 0.9983 - recall: 0.9988\n",
      "Epoch 00004: early stopping\n",
      "57/57 [==============================] - 1s 25ms/step - loss: 0.0040 - acc: 0.9989 - precision: 0.9977 - recall: 1.0000s: 3.9212e-04 - acc: 1.0000 - prec\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "acc,pre,rec,f1=[],[],[],[]\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "for train_index, test_index in kfold.split(df):\n",
    "    # splitting Dataframe (dataset not included)\n",
    "    \n",
    "    train_df = df.iloc[train_index].tweets.tolist()\n",
    "    test_df = df.iloc[test_index].tweets.tolist()\n",
    "    train_y = np.array(df.iloc[train_index].duygu.tolist())\n",
    "    test_y = np.array(df.iloc[test_index].duygu.tolist())\n",
    "\n",
    "    tokenized_reviews_train = [tokenize_reviews(tweet) for tweet in train_df]\n",
    "    tokenized_reviews_test = [tokenize_reviews(tweet) for tweet in test_df] \n",
    "    \n",
    "    reviews_with_len_train = [[review, train_y[i], len(review)]\n",
    "                     for i, review in enumerate(tokenized_reviews_train)]\n",
    "    \n",
    "    reviews_with_len_test = [[review, test_y[i], len(review)]\n",
    "                     for i, review in enumerate(tokenized_reviews_test)]\n",
    "\n",
    "    random.shuffle(reviews_with_len_train)\n",
    "    random.shuffle(reviews_with_len_test)\n",
    "    \n",
    "    reviews_with_len_train.sort(key=lambda x: x[2])\n",
    "    reviews_with_len_test.sort(key=lambda x: x[2])\n",
    "    \n",
    "    sorted_reviews_train = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len_train]\n",
    "    sorted_reviews_test = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len_test]\n",
    "    \n",
    "    processed_dataset_test = tf.data.Dataset.from_generator(lambda: sorted_reviews_test, output_types=(tf.int32, tf.int32))\n",
    "    processed_dataset_train = tf.data.Dataset.from_generator(lambda: sorted_reviews_train, output_types=(tf.int32, tf.int32))\n",
    "\n",
    "    test_data = processed_dataset_test.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "    train_data = processed_dataset_train.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    text_model.fit(train_data, epochs=50,callbacks=early_stopping)\n",
    "    \n",
    "    loss, accuracy, precision, recall = text_model.evaluate(test_data)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    acc.append(accuracy)\n",
    "    pre.append(precision)\n",
    "    rec.append(recall)\n",
    "    f1.append(f1_score)\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.977108\n",
      "test precision: 0.976340\n",
      "test recall: 0.981338\n",
      "test f1_score: 0.978704\n"
     ]
    }
   ],
   "source": [
    "print('test Accuracy: %f' % (Average(acc)))\n",
    "print('test precision: %f' % (Average(pre)))\n",
    "print('test recall: %f' % (Average(rec)))\n",
    "print('test f1_score: %f' % (Average(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
