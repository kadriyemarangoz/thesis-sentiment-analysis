{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in d:\\program\\anaconda\\lib\\site-packages (1.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\program\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\program\\anaconda\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.2; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'd:\\program\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#Kütüphanelerin eklenmesi\n",
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_predict, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "!pip install utils\n",
    "from utils import *\n",
    "import json\n",
    "import random\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from snowballstemmer import TurkishStemmer\n",
    "warnings.filterwarnings('ignore') \n",
    "import string\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from snowballstemmer import TurkishStemmer\n",
    "\n",
    "import xlsxwriter \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "from spacy.lang.tr import Turkish\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweets','duygu']\n",
    "df = pd.read_excel(\"../dataset/kemik_pos_neg.xlsx\")\n",
    "df.columns=column\n",
    "#veri setinin gösterilmesi\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4563, 4563)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.duygu=='olumlu']),len(df[df.duygu=='olumsuz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['duygu'] == \"olumlu\", \"duygu\"] = 1\n",
    "# df.loc[df['duygu'] == \"olumsuz\", \"duygu\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from jpype import JClass, JString, getDefaultJVMPath, shutdownJVM, startJVM, java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZEMBEREK_PATH = r'C:\\Users\\asus\\Desktop\\Python\\word2vec\\zemberek-full.jar'\n",
    "startJVM(getDefaultJVMPath(), '-ea', '-Djava.class.path=%s' % (ZEMBEREK_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= Turkish()\n",
    "from zemberek import (\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishMorphology,\n",
    ")\n",
    "morphology = TurkishMorphology.create_with_defaults() \n",
    "\n",
    "normalizer = TurkishSentenceNormalizer(morphology) #kelimelerin düzgün yazımı için\n",
    "\n",
    "TurkishMorphology = JClass('zemberek.morphology.TurkishMorphology')\n",
    "morphology2 = TurkishMorphology.createWithDefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verilerde olan stop wordleri atmak için yapılan işlemler\n",
    "#veriler için 3 ayrı dataset birleştirilip sayısallaştırılmış, küçük harfe çevrilmiş ve noktalama işaretlerinden arındırılmıştır.\n",
    "workbook = xlsxwriter.Workbook('C:/Users/asus/Desktop/Python/tf-idf/preprocessing.xlsx') \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "def remove(string_input):\n",
    "    return \"\".join(string_input.split()) \n",
    "\n",
    "def remove_stopwords(df_fon):\n",
    "    i=0\n",
    "    print(df_fon['tweets'].size)\n",
    "    while i <(df_fon['tweets'].size):\n",
    "        v=\"\"\n",
    "        for token in nlp(df_fon['tweets'][i]):\n",
    "            yeniMetin=\"\"\n",
    "            #spacy kütüphanesini kullanarak noktalama işaretlerinden kurtardım\n",
    "            yeniMetin = token.text.lower() # spacy kütüphanesiyle küçük harfe çevirip token ayırdım\n",
    "            yeniMetin =remove(yeniMetin)\n",
    "            word=\"\"\n",
    "            if yeniMetin not in string.punctuation:\n",
    "                word += yeniMetin          \n",
    "            \n",
    "            if word not in ['',' ','olurmusunuz','alıyormusunuz','musunuz','biliyormusunuz','ediyormusunuz?']:\n",
    "                word = normalizer.normalize(word) #cümleleri düzgün hale getiriyor. yazım hataları giderildi\n",
    "                if word not in stopwords.words('turkish'):\n",
    "                    word = normalizer.normalize(word) #cümleleri düzgün hale getiriyor. yazım hataları giderildi\n",
    "                    analysis: java.util.ArrayList = (morphology2.analyzeAndDisambiguate(word).bestAnalysis())\n",
    "                    pos: List[str] = []\n",
    "                    for j, analysis in enumerate(analysis, start=1):\n",
    "                        pos.append(f'{str(analysis.getLemmas()[0])}')\n",
    "                    \n",
    "                    v+= f' {\"\".join(pos)}'\n",
    "        print(v)\n",
    "        \n",
    "        column = 0\n",
    "                \n",
    "        worksheet.write(i, column, v) \n",
    "\n",
    "        i += 1\n",
    "    workbook.close() \n",
    "\n",
    "remove_stopwords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
